# A Critical Review of LASSO and Its Derivatives for Variable Selection Under Dependence Among Covariates (Freijeiro-Gonzalez et al., 2022)

## Dissertation Alignment Context
The dissertation proposal uses a three-stage longitudinal pipeline: critical-range rectification of lagged signals into {-1,+1} indicators, L1-regularized logistic feature-and-lag selection, and anytime rule compression that converts sparse coefficients into compact m-of-K rules.

## Outline Summary of the Paper
1. **Purpose and scope (Introduction):** The paper critically evaluates LASSO for variable selection under covariate dependence, in both classical \(n > p\) and high-dimensional \(p > n\) settings.
2. **LASSO foundations and framing (Section 2):** It revisits sparse linear regression and positions LASSO as a convex, computationally feasible surrogate to best-subset \(L_0\)-style selection.
3. **Key limitations of LASSO (Section 2.1):** The review organizes drawbacks into four themes: estimator bias, selection-consistency requirements, early false discoveries on the LASSO path, and sensitivity to tuning-parameter selection.
4. **Theory-to-practice bridge:** It emphasizes restrictive assumptions (for example, irrepresentable-type conditions and beta-min requirements) and explains why these are often fragile under realistic dependence structures.
5. **Simulation framework (Section 3):** The authors design comparative Monte Carlo scenarios with different dependence patterns to stress-test LASSOâ€™s screening behavior, noise inclusion, and prediction performance.
6. **Observed LASSO behavior in practice (Section 3.1):** Results show that common LASSO tuning choices can overselect variables, include many false positives, and still achieve good prediction error, highlighting a selection-versus-prediction tension.
7. **Methodological evolution (Section 4):** The paper surveys major LASSO derivatives and related sparse-selection alternatives (including adaptive, relaxed, square-root/scaled, and nonconvex penalty variants), clarifying their intended fixes.
8. **Head-to-head comparative study (Section 4.1):** It benchmarks selected methods (including derivative families and an alternative distance-correlation-based approach) under the same dependence scenarios to identify robust performers.
9. **Guidance-oriented synthesis (Section 5):** The discussion distills practical recommendations by dependence regime rather than declaring a universal winner, stressing that method choice should follow data-correlation structure and objective (selection vs. prediction).
10. **Main takeaway:** LASSO is useful but not uniformly reliable for variable recovery under dependence; robust analysis should include derivative/alternative baselines and tuning strategies tailored to the data structure.

## Relevance to the Dissertation
A Critical Review of LASSO and Its Derivatives for Variable Selection Under Dependence Among Covariates (Freijeiro-Gonzalez et al., 2022) is directly relevant because it offers a sparse-selection strategy that competes with the proposal's rectification-first approach under multicollinearity.

## Elements from This Paper to Use in the Dissertation
1. Include this method as an explicit baseline on both raw lag-expanded and rectified features.
2. Track support stability, false positives, and lag attribution quality, not only AUC/F1.
3. Reuse discussion around critical, review, derivatives to motivate when penalty-only methods are sufficient.
4. Compare runtime and memory against the rectification + L1 + anytime-rule pipeline.

## Competitive Method Assessment
This paper describes a genuine competing method family. Relative to the dissertation pipeline, it can fall short when raw lag-expanded correlation is so high that support selection remains unstable or when explicit threshold/rule semantics are required. It can excel when linear signal is strong, penalty tuning is mature, and compact logical rules are not the primary requirement.


## Dissertation Citation Traceability

- Chapter: `Introduction`; Section: `Chapter context (no explicit section)`; Line: `Chapters/01_introduction.tex:13`; Relevance: Cited to support the statement that In high-dimensional longitudinal modeling, a standard strategy is to construct a lag-expanded design matrix and apply a sparse estimator. This strategy is attractive because sparse models can retain predictive performance while reducing dimensionality . However, lag expansion also introduces strong dependence among adjacent lags and among correlated channels, creating exactly the regimes where support recovery becomes unstable and model-selection assumptions can fail . Practical outcomes include arbitrary swapping among correlated predictors, sensitivity to tuning choices, and weak reproducibility of selected supports across resamples.
- Chapter: `Introduction`; Section: `Contributions`; Line: `Chapters/01_introduction.tex:39`; Relevance: Cited to support the statement that item Theory-informed analysis of correlation and selection behavior. The dissertation extends proof-of-concept arguments relating transformed representations to improved support-recovery conditions, situating these results against established lasso consistency theory and dependence-aware critiques.
- Chapter: `Background`; Section: `Support recovery and the irrepresentable condition`; Line: `Chapters/02_background.tex:17`; Relevance: Cited to support the statement that This limitation is central in lag-expanded longitudinal designs, where adjacent lags and related channels are frequently collinear. Reviews of lasso under dependence consistently report this selection-versus-prediction tension, with false discoveries and unstable supports common under strong correlation . Correlation-aware variants, including transformed/weighted and rank-based approaches, can improve robustness in specific regimes, but they do not eliminate the underlying dependence challenge in general.
- Chapter: `Related Work`; Section: `Support Recovery Under Dependence`; Line: `Chapters/03_relatedwork.tex:21`; Relevance: Cited to support the statement that This issue is acute in lag-expanded longitudinal data, where neighboring lags and related channels often have strong dependence. Recent reviews emphasize that lasso and many derivatives can produce unstable supports and elevated false positives in dependent designs, especially under common tuning choices optimized for prediction rather than exact support recovery.
- Chapter: `Related Work`; Section: `Summary of Gaps in Prior Work`; Line: `Chapters/03_relatedwork.tex:80`; Relevance: Cited to support the statement that item Sparse penalties are computationally mature and often predictive, but support consistency remains fragile under strong lag-induced dependence.
- Chapter: `Research Questions`; Section: `Chapter context (no explicit section)`; Line: `Chapters/04_resquestions.tex:5`; Relevance: Cited to support the statement that This chapter defines the core research questions that guide this work and explains why they are important. Longitudinal feature learning is targeted under three simultaneous constraints: strong dependence created by lag expansion, the need for reliable feature-lag attribution, and the need for compact human-auditable model outputs. Prior chapters established that sparse methods are attractive but not always stable under dependence, and that interpretability requirements in high-stakes settings favor inherently transparent model forms over post hoc explanation layers.
- Chapter: `Research Questions`; Section: `Why RQ1 matters`; Line: `Chapters/04_resquestions.tex:18`; Relevance: Cited to support the statement that RQ1 addresses the practical entry point of the dissertation: does representation-level rectification make sparse longitudinal selection more reliable than fitting directly on raw lag-expanded inputs? This question is important because dependence among lagged predictors is the norm in longitudinal data, and support recovery can degrade sharply in such settings even when prediction remains acceptable.
- Chapter: `Preliminary Studies and Evidence to Date for RQ1`; Section: `How RQ1 is evaluated in preliminary work`; Line: `Chapters/05_rq1.tex:18`; Relevance: Cited to support the statement that The preliminary decision criteria are practical rather than purely theoretical: discriminatory performance (for example AUC and Youden's J), sparsity and support clarity, lag-level attribution fidelity, and end-to-end computational cost. This aligns with known limitations of penalty-only sparse methods under dependence, where prediction may remain strong while support recovery becomes unstable.
- Chapter: `Preliminary Studies and Evidence to Date for RQ1`; Section: `Synthetic evidence with known ground truth`; Line: `Chapters/05_rq1.tex:22`; Relevance: Cited to support the statement that Synthetic longitudinal datasets are constructed so that events occur when a small subset of variables simultaneously enters critical ranges at specific lags. This creates a hard but controlled setting where lag expansion induces severe multicollinearity by design, closely mirroring the failure modes discussed in lasso consistency literature . In this regime, representation-level rectification is applied before sparse fitting and compared with untransformed baselines.
- Chapter: `Theoretical Analysis (RQ2)`; Section: `Chapter context (no explicit section)`; Line: `Chapters/06_rq2.tex:7`; Relevance: Cited to support the statement that The point of this chapter is not to claim a universal theorem for every thresholding scheme. Instead, it establishes a defensible mechanism: if binarization contracts dependence in the right way, the IC becomes easier to satisfy, and sparse support recovery becomes more likely. That mechanism aligns with both prior empirical evidence in this line of inquiry and broader observations that lasso-style selection can be unstable under strong dependence.
- Chapter: `Theoretical Analysis (RQ2)`; Section: `IC in computer-science terms`; Line: `Chapters/06_rq2.tex:30`; Relevance: Cited to support the statement that When this leakage margin is violated, inactive features can mimic active ones and enter the model, taking the place of true support in the model, causing feature and lag misattribution due to spurious correlation. This is a structural reason for false inclusions and support instability, consistent with dependency-focused reviews.
- Chapter: `Theoretical Analysis (RQ2)`; Section: `What this theorem does not claim`; Line: `Chapters/06_rq2.tex:185`; Relevance: Cited to support the statement that These caveats are consistent with prior reports that transformed and untransformed tradeoffs can vary by regime, with some datasets favoring raw discrimination while transformed models improve interpretability and attribution fidelity.
- Chapter: `Future Work`; Section: `Defense-Readiness Objective`; Line: `Chapters/88_futurework.tex:12`; Relevance: Cited to support the statement that item Theoretical transparency: RQ2 assumptions, scope boundaries, and failure modes are explicit, testable, and consistent with established selection-consistency theory.
- Chapter: `Future Work`; Section: `Workstream A: RQ1 Empirical Strengthening > A1. Stability-first evaluation protocol`; Line: `Chapters/88_futurework.tex:22`; Relevance: Cited to support the statement that The first required expansion is to report selection stability and lag fidelity as first-class outcomes alongside AUC, Youden's , and sparsity. This directly addresses known dependence-related fragility in sparse selection and avoids over-claiming based only on point predictive metrics.
- Chapter: `Future Work`; Section: `Workstream B: RQ2 Theoretical Completion > B2. Assumption stress testing`; Line: `Chapters/88_futurework.tex:63`; Relevance: Cited to support the statement that Each assumption in the RQ2 chapter will be paired with at least one targeted stress test. This is necessary because support-recovery claims are known to be sensitive to covariance geometry and signal-strength conditions.
- Chapter: `Future Work`; Section: `Risks and Mitigation Prior to Defense`; Line: `Chapters/88_futurework.tex:126`; Relevance: Cited to support the statement that item Risk: Overstated theoretical generality. Mitigation: explicit scope language and assumption-level counterexample tests.
- Chapter: `Conclusion`; Section: `Research Program Summary`; Line: `Chapters/89_conclusion.tex:16`; Relevance: Cited to support the statement that Together, these questions move from empirical behavior (RQ1), to theoretical plausibility (RQ2), to deployment usability (RQ3). This sequencing is intentional: interpretability claims are weak if support recovery is unstable, and practical rule compression is less meaningful without a credible upstream selection mechanism.
- Chapter: `Conclusion`; Section: `Conclusions by Research Question > RQ1 conclusion: Rectification can improve attribution reliability in target regimes`; Line: `Chapters/89_conclusion.tex:22`; Relevance: Cited to support the statement that The accumulated evidence supports a conditional positive conclusion for RQ1. In threshold-and-lag aligned settings, critical-range rectification tends to improve support concentration, lag localization, and sparse-model usability under multicollinearity stress . This finding is consistent with known dependence-related limits of penalty-only sparse selection, where prediction can remain acceptable while support identification degrades.
- Chapter: `Conclusion`; Section: `Scope Boundaries and Limitations`; Line: `Chapters/89_conclusion.tex:65`; Relevance: Cited to support the statement that These boundaries are consistent with broader evidence that no sparse-selection or interpretable-modeling method is uniformly optimal across all dependence structures and objectives.
