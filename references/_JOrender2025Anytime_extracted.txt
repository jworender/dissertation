0001 [p2] Big Data Analytics & Applications
0002 [p2] Proceedings of the First International Conference
0003 [p2] on Big Data Analytics & Applications (BDAA' 2025)
0004 [p2] 25-27 November 2025
0005 [p2] Innsbruck, Austria
0006 [p2] Edited by Sergey Y. Yurish
0007 [p3] Sergey Y. Yurish, Editor
0008 [p3] BDAA‚Äô 2025 Conference Proceedings
0009 [p3] Copyright ¬© 2025
0010 [p3] by International Frequency Sensor Association (IFSA) Publishing, S. L.
0011 [p3] E-mail (for orders and customer service enquires): ifsa.books@sensorsportal.com
0012 [p3] Visit our Home Page on http://www.sensorsportal.com
0013 [p3] All rights reserved. This work may not be translated or copied in whole or in part without the written permission
0014 [p3] of the publisher (IFSA Publishing, S. L., Barcelona, Spain).
0015 [p3] Neither the authors nor International Frequency Sensor Associat ion Publishing accept  any responsibility or
0016 [p3] liability for loss or damage occasioned to any person or property through using the material, instructions, methods
0017 [p3] or ideas contained herein, or acting or refraining from acting as a result of such use.
0018 [p3] The use in this publication of trade names, trademarks, service  marks, and similar terms, even if they are not
0019 [p3] identifying as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary
0020 [p3] rights.
0021 [p3] ISBN: 978-84-09-78845-3
0022 [p3] BN-20251120-XX
0023 [p3] BIC: GPH
0024 [p4] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0025 [p4] 25-27 November 2025, Innsbruck, Austria
0026 [p4] 3
0027 [p4] Contents
0028 [p4] Foreword ........................................................................................................................................................... 4
0029 [p4] AcademicRAG: A Knowledge Graph-enhanced Framework for Intelligent Academic
0030 [p4] Resource Discovery ........................................................................................................................................... 5
0031 [p4] Zhuchenyang Liu, Shuhua Chen, Shiva Sander Tavallaey, Fredrik Heintz and Elias Zea
0032 [p4] A Holistic Privacy-preserving Framework for the Federated  Learning Lifecycle .................................. 11
0033 [p4] Luc√≠a Mu√±oz-Solanas, Amaia Gil-Lerchundi
0034 [p4] A Guide to Feature-preserving Pseudonymization of Profile Pictures ...................................................... 14
0035 [p4] Y. Lee, H. Bothe and M. Geierhos
0036 [p4] A Microservice Based Authentication and Authorization Framework
0037 [p4] for Column Oriented Databases .................................................................................................................... 18
0038 [p4] Rafael Sebastian Castro Paredes, Andres Andrade-Cabrera and Diana Martinez-Mosquera
0039 [p4] Developing Synthetic Data or Cybersecurity Policies .................................................................................. 24
0040 [p4] G. Giacomello, O. Preka
0041 [p4] Unforgetting Educational Surveillance: Reimagining AI as a Tool  for Justice
0042 [p4] and Pedagogical Liberation ........................................................................................................................... 27
0043 [p4] G. Parker
0044 [p4] Enhancing Network Intrusion Detection Using Advanced Meta-learning Ensemble SVMs
0045 [p4] in Production Cloud Environments .............................................................................................................. 38
0046 [p4] Lokesh Karanam and Hardik Mahant
0047 [p4] ADAPTE: Multidimensional Academic Data Analytics and Student Profiling
0048 [p4] for Higher Education ...................................................................................................................................... 47
0049 [p4] D. Lima, J. Coelho
0050 [p4] Interpreting Tactical Decision-making in Transformer-based Agents ...................................................... 51
0051 [p4] K. Boeckx and X. Neyt
0052 [p4] A Selective Temporal Hamming Distance to Find Patterns in State Transition Event
0053 [p4] Timeseries, at Scale ......................................................................................................................................... 56
0054 [p4] Sylvain Mari√© and Pablo Knecht
0055 [p4] Above, On, and Below the Surface: Data Services in Large Collaborative Projects ................................ 63
0056 [p4] V. Vassilev, G. Petkov, B. Kraychev, S. Haydushki, V. Sowinski-Mydlarz, S. Nikolov, N. Shivarov,
0057 [p4] and DiverSea Project Partners
0058 [p4] Quantifying the Unstructured Narrative of Patient Care in EHR Data .................................................... 70
0059 [p4] Edward Kim, Richard Foty and Vicki Seyfert-Margolis
0060 [p4] Autonomous, Self-learning Cisco Digital Adoption Platform (CDAP)  for Personalized,
0061 [p4] Proactive Campaign Creation and Targeted  User Engagement ................................................................ 75
0062 [p4] N. Kale
0063 [p4] Anytime Rule Compression and Rectified Logistic Modeling for Longitudinal Signals .......................... 79
0064 [p4] J. Orender, J. Sun and M. Zubair
0065 [p5] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0066 [p5] 25-27 November 2025, Innsbruck, Austria
0067 [p5] 4
0068 [p5] Foreword
0069 [p5] It is my great pleasure to present the Proceedings of the First International Conference on Big Data Analytics &
0070 [p5] Applications (BDAA‚Äô 2025), held on 25‚Äì27 November 2025 in Innsbruck, Austria. This inaugural edition marks
0071 [p5] an important milestone for our community, bringing together researchers, engineers, practitioners, and innovators
0072 [p5] working across the rapidly expanding domains of big data engineering, intelligent analytics, machine learning,
0073 [p5] data privacy, high-performance systems, and domain-focused data applications.
0074 [p5] The extraordinary growth of data -driven technologies continues to reshape science, industry, government, and
0075 [p5] society. Yet this growth also brings new responsibilities‚Äîensuring trust, security, transparency, and efficiency in
0076 [p5] modern data ecosystems. BDAA‚Äô 2025 was established to provide a focused, high-quality platform for addressing
0077 [p5] these emerging challenges. Our aim is to bridge foundational advances in algorithms, models, and architectures
0078 [p5] with real-world applications in fields such as health, cybersecuri ty, education, social platforms, and large -scale
0079 [p5] scientific projects.
0080 [p5] The papers included in these proceedings reflect the diverse and multidisciplinary character of the conference.
0081 [p5] They cover topics such as knowledge-graph-enhanced academic resource discovery, privacy-preserving federated
0082 [p5] learning, face de- identification an d generative pseudonymization, secure microservice- based authorization
0083 [p5] frameworks, and advanced analytical methods for cloud environments, education, and collaborative research
0084 [p5] infrastructures. Despite their variety, all contributions share a common ambition: to advance the state of the art in
0085 [p5] extracting meaningful, reliable, and actionable insights from complex data. Each paper has undergone careful peer
0086 [p5] review to ensure scientific quality and relevance.
0087 [p5] I would like to express my sincere appreciation to all authors for their high -quality submissions, and to the
0088 [p5] members of the Program Committee and external reviewers for their dedication and rigorous evaluations. My
0089 [p5] thanks also go to our invited speakers and session chairs, whose expertise enriched the scientific discussions, and
0090 [p5] to all participants whose engagement made BDAA‚Äô 2025 a vibrant and productive event.
0091 [p5] Finally, I extend my gratitude to IFSA Publishing for their continued support and for preparing this volume, which
0092 [p5] I hope will serve as a useful resource for researchers and practitioners worldwide. I am confident that the ideas
0093 [p5] presented here will inspire further innovations and collaborations, and will contribute to shaping the future of big
0094 [p5] data analytics and its transformative applications.
0095 [p5] Prof., Dr. Sergey Y. Yurish
0096 [p5] BDAA‚Äô 2025 Chairman
0097 [p6] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0098 [p6] 25-27 November 2025, Innsbruck, Austria
0099 [p6] 5
0100 [p6] (006)
0101 [p6] AcademicRAG: A Knowledge Graph-enhanced Framework for Intelligent
0102 [p6] Academic Resource Discovery
0103 [p6] Zhuchenyang Liu 1, Shuhua Chen 2, Shiva Sander Tavallaey 3,4, Fredrik Heintz 5 and Elias Zea 4
0104 [p6] 1 Aalto University, School of Electrical Engineering, Espoo, Finland
0105 [p6] 2 Alibaba Cloud Computing Co., Ltd., Hangzhou, China
0106 [p6] 3 ABB AB Corporate Research, V√§ster√•s, Sweden
0107 [p6] 4 KTH Royal Institute of Technology, Department of Engineering Mechanics, Stockholm, Sweden
0108 [p6] 5 Link√∂ping University, Department of Computer and Information Science, Link√∂ping, Sweden
0109 [p6] Tel.: +46 079 353 5523
0110 [p6] E-mail: zhuchenyang.liu@aalto.fi
0111 [p6] Summary: Traditional academic retrieval  systems struggle to capture com plex semantic relationships; this often leads to
0112 [p6] incomplete results and missed interdisciplinary connections. We present AcademicRAG 1, a novel knowledge graph-enhanced
0113 [p6] framework that addresses these limitations through two key innovations: clue-guided keyword generation and subgraph-based
0114 [p6] retrieval. Unlike GraphRAG's expe nsive community structures and  LightRAG's limited one-hop neighbor retrieval,
0115 [p6] AcademicRAG builds complete subgr aphs while anchoring keywords in actual graph content to prevent semantic drift.
0116 [p6] Additionally, it eliminates comm unity regeneration overhead thr ough clue-guided keyword indexing, enabling efficient
0117 [p6] incremental updates. Evaluations across agriculture and computer science domains demonstrate that our approach consistently
0118 [p6] outperforms three state-of-the-art baselines. We demonstrate Ac ademicRAG‚Äôs practical versatility by powering a research
0119 [p6] literature assistant that leverages clue-guided querying and su bgraph navigation for precise, c ontext-aware paper discovery,
0120 [p6] and a course discovery system that uses dynamic subgraph analysis to generate personalized learning pathways and optimize
0121 [p6] course curricula in the acoustics domain.
0122 [p6] Keywords: Knowledge graph, Retrieval-augmented generation, Graph-based RAG, Academic resource discovery, Subgraph
0123 [p6] retrieval, Literature review, Course discovery.
0124 [p6] 1. Introduction
0125 [p6] The exponential growth of digital academic content
0126 [p6] has transformed scholarly communication, with
0127 [p6] academic databases now containing millions of papers
0128 [p6] across diverse disciplines [1]. However, this
0129 [p6] unprecedented scale creates significant challenges in
0130 [p6] knowledge discovery and syn thesis, particularly in
0131 [p6] academic contexts where understanding depends on
0132 [p6] grasping complex relationships between entities,
0133 [p6] methodologies, and concepts [2].
0134 [p6] Traditional retrieval systems demonstrate
0135 [p6] fundamental limitations in academic knowledge
0136 [p6] discovery. Sparse retrieval methods like BM25, while
0137 [p6] computationally efficient, struggle with terminology
0138 [p6] variations and fail to capture semantic relationships
0139 [p6] inherent in academic knowledge [3]. Dense retrieval
0140 [p6] methods using Transformer-based encoders improve
0141 [p6] semantic understanding but cannot preserve the
0142 [p6] intricate relational structures that define academic
0143 [p6] knowledge hierarchies, prerequisite chains, and
0144 [p6] interdisciplinary connections [4].
0145 [p6] Recent Retrieval-Augmented Generation (RAG)
0146 [p6] approaches, though promising, inherit these structural
0147 [p6] limitations. Conventional RAG treats academic
0148 [p6] documents as isolated entities with flat vector
0149 [p6] representations, failing to model the complex
0150 [p6] relationship networks essential for comprehensive
0151 [p6] 1 Code and additional implementation details are available at: https://github.com/shua-chen/academicRAG
0152 [p6] academic understanding [5]. Four main RAG
0153 [p6] paradigms have emerged ‚Äì Sequential, Branching,
0154 [p6] Conditional, and Loop RAG [6] ‚Äì but none adequately
0155 [p6] addresses the spectrum of academic information needs.
0156 [p6] Graph-based RAG architectures attempt to address
0157 [p6] these limitations but face critical trade-offs [7].
0158 [p6] GraphRAG [8] employs hierarchical community
0159 [p6] structures, achieving im provement in critical
0160 [p6] dimensions over traditional RAG, but requires high
0161 [p6] computational complexity for community generation,
0162 [p6] making incremental updates prohibitively expensive.
0163 [p6] LightRAG [9] reduces computational overhead
0164 [p6] through dual-level retrieval but limits relationship
0165 [p6] discovery to one-hop neighbors, fundamentally
0166 [p6] constraining multi-hop dependency capture crucial for
0167 [p6] academic synthesis. Other frameworks (GRAG [10],
0168 [p6] HybridRAG [11], CG-RAG [12]) face similar
0169 [p6] challenges: high computational requirements, limited
0170 [p6] multi-hop inference capabilities, and manual
0171 [p6] knowledge graph curation needs.
0172 [p6] We present AcademicRAG, a knowledge
0173 [p6] graph-enhanced RAG framework specifically
0174 [p6] designed for intelligent academic resource discovery.
0175 [p6] Our approach introduces two key technical innovations
0176 [p6] that address the fundamental limitations of existing
0177 [p6] graph-based RAG frameworks. Firstly, we develop
0178 [p6] clue-guided keyword generation that anchors keyword
0179 [p6] extraction processes in actual graph content, thereby
0180 [p7] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0181 [p7] 25-27 November 2025, Innsbruck, Austria
0182 [p7] 6
0183 [p7] preventing semantic drift and hallucination issues that
0184 [p7] commonly plague generative retrieval systems when
0185 [p7] operating without grounded constraints. Secondly, we
0186 [p7] implement subgraph-based retrieval mechanisms that
0187 [p7] construct complete relationship networks efficiently,
0188 [p7] eliminating the need for computationally expensive
0189 [p7] community structures while avoiding the restrictive
0190 [p7] single-hop neighbor limitations that constrain existing
0191 [p7] approaches.
0192 [p7] Our contributions are threefold. First, we develop a
0193 [p7] dual-flow architecture transforming unstructured
0194 [p7] academic content into quarriable knowledge graphs
0195 [p7] through iterative entity-relationship extraction.
0196 [p7] Second, we introduce effici ent algorithms for local
0197 [p7] subgraph construction and global relationship
0198 [p7] discovery that capture multi-hop dependencies while
0199 [p7] enabling incremental updates, validated through
0200 [p7] substantive evaluation. Third, we demonstrate
0201 [p7] practical versatility through two real-world
0202 [p7] applications addressing distinct academic information
0203 [p7] needs across different user groups.
0204 [p7] Comprehensive technical details, implementation
0205 [p7] specifics, and extended case studies are available in the
0206 [p7] complete documentation [13].
0207 [p7] 2. AcademicRAG Framework
0208 [p7] AcademicRAG operates through two primary
0209 [p7] flows: Index Flow for knowledge graph construction
0210 [p7] and Query Flow for information retrieval, as illustrated
0211 [p7] in Fig. 1. This dual-flow architecture transforms
0212 [p7] unstructured academic content into structured
0213 [p7] knowledge representations while enabling
0214 [p7] sophisticated query processing that captures both local
0215 [p7] detail and global context.
0216 [p7] Fig. 1. AcademicRAG Framework Flowchart.
0217 [p7] 2.1. Index Flow
0218 [p7] The Index Flow processes academic documents
0219 [p7] through a comprehensive multi-stage pipeline
0220 [p7] designed to preserve semantic relationships while
0221 [p7] enabling efficient retrieval. The process begins with
0222 [p7] document ingestion and structure-aware chunking that
0223 [p7] respects document organization, particularly important
0224 [p7] for academic content with  inherent hierarchical
0225 [p7] structure such as research papers and course syllabi.
0226 [p7] Each document chunk undergoes entity and
0227 [p7] relationship extraction using domain-adapted LLMs
0228 [p7] for academic content. The extraction process
0229 [p7] simultaneously identifies three critical components:
0230 [p7] ·à∫ùê∏
0231 [p7] ‡Øú,ùëÖ ‡Øú,ùêæ‡Øú·àª‡µå  LLM·à∫ùëê‡Øú·àª, (1)
0232 [p7] where ùëê‡Øú represents document chunks, ùê∏‡Øú and ùëÖ‡Øú a r e
0233 [p7] extracted entities and relationships, and ùêæ‡Øú are content
0234 [p7] keywords capturing global themes.
0235 [p7] Next, the framework employs a multi-pass iterative
0236 [p7] refinement mechanism that maximizes entity and
0237 [p7] relationship extraction accu racy. Unlike single-pass
0238 [p7] extraction methods, this approach performs systematic
0239 [p7] re-extraction to capture complex academic
0240 [p7] relationships that may be missed in initial processing.
0241 [p7] The extracted information is stored in a
0242 [p7] dual-database architecture: the Graph Database
0243 [p7] preserving structural relationships and the Vector
0244 [p7] Database storing semantic embeddings. This hybrid
0245 [p7] approach enables both structured traversal and
0246 [p7] similarity-based retrieval, providing comprehensive
0247 [p7] coverage for complex academic queries.
0248 [p7] 2.2. Query Flow
0249 [p7] Upon receiving a user query ùëÑ, the system
0250 [p7] implements a sophisticated  multi-stage retrieval
0251 [p7] strategy that addresses semantic drift issues common
0252 [p7] in knowledge graph querying. The process begins with
0253 [p7] clue-guided keyword generation, which anchors
0254 [p7] keyword extraction in actual database content to
0255 [p7] prevent hallucination:
0256 [p7] ùêæ
0257 [p7] ‡≠°‡≠≠‡≠¨‡≠≤‡≠£‡≠¨‡≠≤ ‡µå ·àº ùëò‚ààùêæ ‚à£‚à£ sim·à∫ùëÑ, ùëò·àª ‡µíùúè ·àΩ, (2)
0258 [p7] where ùêæ is the set of indexed content keywords, ùëÑ is
0259 [p7] the user query, and ùúè is a similarity threshold. The
0260 [p7] function sim ·à∫ùëÑ, ùëò·àª computes the embedding cosine
0261 [p7] s i m i l a r i t y  b e t w e e n  q u e r y  and keyword. These clues
0262 [p7] ùêæ‡≠°‡≠≠‡≠¨‡≠≤‡≠£‡≠¨‡≠≤, anchored in actual database content, guide
0263 [p7] the LLM to generate hierarchical keywords that avoid
0264 [p7] semantic drift by combining semantic information
0265 [p7] from the user query with natural language instructions:
0266 [p7] ·à∫ùêæ‡Øõ,ùêæ‡Øü·àª ‡µå LLM·à∫ùëÑ, ùêæ‡≠°‡≠≠‡≠¨‡≠≤‡≠£‡≠¨‡≠≤·àª,. (3)
0267 [p7] where ùêæ‡Øõrepresents high-level conceptual keywords
0268 [p7] and ùêæ‡Øü represents low-level contextual keywords.
0269 [p7] Low-level keywords drive local subgraph extraction
0270 [p7] through the structured process detailed in Fig. 2.
0271 [p7] Unlike LightRAG's [9] one-hop limitation, our
0272 [p7] approach constructs comple te subgraphs that capture
0273 [p7] multi-hop relationships between specific entities,
0274 [p7] enhancing retrieval depth and knowledge integration.
0275 [p7] High-level keywords enable global relationship
0276 [p7] discovery through the systematic process illustrated in
0277 [p8] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0278 [p8] 25-27 November 2025, Innsbruck, Austria
0279 [p8] 7
0280 [p8] Fig. 3. The framework querie s the vector database to
0281 [p8] identify edges correlating with broader conceptual
0282 [p8] frameworks, eliminating GraphRAG's [8] community
0283 [p8] structure overhead while maintaining comprehensive
0284 [p8] global knowledge discovery.
0285 [p8] Fig. 2. Local Information Extraction based on Subgraph.
0286 [p8] Fig. 3. Global Information Extraction.
0287 [p8] The final synthesis stage combines retrieved
0288 [p8] information through sophisticated contextual fusion to
0289 [p8] generate comprehensive responses. The system
0290 [p8] integrates locally extracted subgraph information with
0291 [p8] globally retrieved relationship networks, merging
0292 [p8] entities, relationships, and supporting textual evidence
0293 [p8] into a unified contextual framework. This integrated
0294 [p8] information is then embedded within a
0295 [p8] domain-specific prompt template designed for
0296 [p8] academic content processing. The large language
0297 [p8] model processes this enriched context to generate the
0298 [p8] final answer, leveraging both the granular detail from
0299 [p8] local subgraphs and the broader conceptual
0300 [p8] understanding from global edge networks. This fusion
0301 [p8] approach ensures that res ponses maintain semantic
0302 [p8] coherence while incorporating multiple levels of
0303 [p8] contextual depth, from specific entity relationships to
0304 [p8] overarching domain knowledge.
0305 [p8] 3. Evaluation and Results
0306 [p8] 3.1. Experiment Settings
0307 [p8] We evaluated AcademicRAG using a subset of the
0308 [p8] UltraDomain benchmark [14], selecting agriculture
0309 [p8] and computer science doma ins for their distinct
0310 [p8] knowledge structures and citation patterns. Following
0311 [p8] Microsoft's GraphRAG methodology [8], we
0312 [p8] generated five synthetic academic personas per domain
0313 [p8] (e.g., "PhD Student in NLP," "Organic Farming
0314 [p8] Consultant"), each assigned 25 diverse queries
0315 [p8] reflecting common academic information needs,
0316 [p8] resulting in 125 evaluation queries per domain.
0317 [p8] We compared AcademicRAG against three
0318 [p8] representative baselines: NaiveRAG [5], GraphRAG
0319 [p8] [8] and LightRAG [9]. These baselines were selected
0320 [p8] to provide comprehensive coverage of current RAG
0321 [p8] paradigms, from flat document processing to
0322 [p8] sophisticated graph-based approaches.
0323 [p8] All frameworks used identical configurations with
0324 [p8] Qwen2.5-72B [15] for both knowledge graph
0325 [p8] construction and response generation, ensuring fair
0326 [p8] comparison. Evaluation employed DeepSeek-R1 [16]
0327 [p8] as an LLM judge conducting pairwise comparisons
0328 [p8] across four dimensions:
0329 [p8] ÔÄ≠ Comprehensiveness: Coverage of relevant
0330 [p8] information and depth of analysis;
0331 [p8] ÔÄ≠ Diversity: Variety of perspectives and
0332 [p8] information sources;
0333 [p8] ÔÄ≠ Empowerment: Usefulness for decision-making
0334 [p8] and further research;
0335 [p8] ÔÄ≠ Overall: Holistic assessment integrating all
0336 [p8] dimensions for comprehensive performance.
0337 [p8] To mitigate positional bias, we alternated answer
0338 [p8] placement across three trials and computed averaged
0339 [p8] win rates. While LLM-as-Judge represents current best
0340 [p8] practice for high-level semantic evaluation, we
0341 [p8] acknowledge the need for human expert validation in
0342 [p8] future work.
0343 [p8] 3.2. Evaluation Results
0344 [p8] As shown in Table 1, AcademicRAG demonstrated
0345 [p8] consistent superiority across both domains and all
0346 [p8] evaluation dimensions. Our framework achieved
0347 [p8] overall win rates of 57.2 %, 54.8 %, and 52.4 % against
0348 [p8] NaiveRAG, LightRAG, and GraphRAG respectively
0349 [p8] in agriculture, with even more pronounced advantages
0350 [p8] in computer science (77.5 %, 56.6 %, and 53.6 %). The
0351 [p8] significant performance di sparity between domains
0352 [p8] suggests that field-specific characteristics ‚Äì including
0353 [p8] terminology standardization and conceptual hierarchy
0354 [p8] ‚Äì influence framework effectiveness, with computer
0355 [p8] science's more structured knowledge representation
0356 [p8] facilitating superior retrieval quality.
0357 [p9] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0358 [p9] 25-27 November 2025, Innsbruck, Austria
0359 [p9] 8
0360 [p9] The results validate the core technical innovations
0361 [p9] of our dual-level retrieval approach. AcademicRAG's
0362 [p9] subgraph-based retrieval enab les extraction of richer,
0363 [p9] more structured information compared to flat
0364 [p9] document approaches, while clue-guided keyword
0365 [p9] generation ensures semantic alignment with indexed
0366 [p9] content, preventing hallucination issues in keyword
0367 [p9] generation. Notably, while consistently outperforming
0368 [p9] LightRAG across all dimensions, the comparison with
0369 [p9] GraphRAG reveals that our framework excels in
0370 [p9] comprehensiveness and empowerment ‚Äì the most
0371 [p9] critical metrics for academic information discovery ‚Äì
0372 [p9] demonstrating that complete subgraph construction
0373 [p9] captures essential multi-hop relationships that
0374 [p9] community-based approaches may overlook.
0375 [p9] 3.3. Ablation Study
0376 [p9] To validate our tech nical innovations, we
0377 [p9] conducted ablation studies examining the individual
0378 [p9] contributions of clue-guided keyword generation and
0379 [p9] subgraph-based retrieval. Tab le 2 presents the results
0380 [p9] of removing each component against GraphRAG as
0381 [p9] baseline. Removing clues resulted in mixed
0382 [p9] performance changes, with d iversity scores declining
0383 [p9] from 50.8 % to 48.4 % in agriculture and from 46.8 %
0384 [p9] to 43.0 % in computer science, while surprisingly
0385 [p9] showing improvements in empowerment (54.0 % to
0386 [p9] 60.8 % in agriculture). The subgraph removal variant
0387 [p9] demonstrated similar complexity, with reduced
0388 [p9] comprehensiveness in computer science (51.2 % to
0389 [p9] 49.2 %) but improved overall performance in the same
0390 [p9] domain (53.6 % to 55.2 %).
0391 [p9] These mixed ablation results reflect the inherent
0392 [p9] complexity of graph-based RAG evaluation and the
0393 [p9] nuanced trade-offs between our technical components.
0394 [p9] The unexpected improvements in certain
0395 [p9] configurations can be attrib uted to several factors.
0396 [p9] Firstly, the subjective nature of LLM-as-Judge
0397 [p9] evaluation may lead to scenarios where simpler
0398 [p9] responses are occasionally preferred for specific query
0399 [p9] types, potentially masking the true effectiveness of
0400 [p9] more sophisticated retriev al mechanisms. Secondly,
0401 [p9] the interaction effects between components create
0402 [p9] non-linear performance relationships, wherein the
0403 [p9] removal of one component may inadvertently optimize
0404 [p9] the remaining system configuration for particular
0405 [p9] evaluation criteria. Thirdly, GraphRAG's community-
0406 [p9] based approach introduces variable noise levels that
0407 [p9] differentially affect compa risons, as the quality and
0408 [p9] coherence of generated communities can vary
0409 [p9] significantly across different knowledge domains and
0410 [p9] corpus structures.
0411 [p9] 4. Applications
0412 [p9] To demonstrate AcademicRAG's practical
0413 [p9] versatility beyond the evaluated domains, we
0414 [p9] developed two real-world applications that address
0415 [p9] distinct academic information needs across different
0416 [p9] user groups while validating the framework's
0417 [p9] adaptability to diverse academic contexts.
0418 [p9] Table 1. Comparative Win Rates (%) of AcademicRAG against Baseline Models Across Two Domains.
0419 [p9] Framework Agriculture Computer Science
0420 [p9] Comp Div Emp Overall Comp Div Emp Overall
0421 [p9] NaiveRAG 62.8 % 58.0 % 51.6 % 57.2 % 67.1 % 83.2 % 75.7 % 77.5 %
0422 [p9] LightRAG 50.0 % 55.2 % 58.4 % 54.8 % 56.2 % 57.8 % 59.8 % 56.6 %
0423 [p9] GraphRAG 52.4 % 50.8 % 54.0 % 52.4 % 51.2 % 46.8 % 55.2 % 53.6 %
0424 [p9] Note: Comp = Comprehensiveness, Div = Diversity, Emp = Empowerment. Win rates were computed based on pairwise comparisons
0425 [p9] conducted by a Large Language Model (LLM-as-Judge) over 125 domain-specific queries, following common practices in graph-based
0426 [p9] RAG framework evaluation [8, 9].
0427 [p9] Table 2. Ablation Studies on Win Rates (%) Compared with GraphRAG.
0428 [p9] Settings Agriculture Computer Science
0429 [p9] Comp Div Emp Overall Comp Div Emp Overall
0430 [p9] AcademicRAG 52.4 % 50.8 % 54.0 % 52.4 % 51.2 % 46.8 % 55.2 % 53.6 %
0431 [p9] -clues 53.6 % 48.4 % 60.8 % 57.2 % 51.0 % 43.0 % 54.6 % 51.8 %
0432 [p9] -subgraph 50.8 % 51.6 % 52.8 % 53.6 % 49.2 % 48.0 % 59.3 % 55.2 %
0433 [p9] Note: Comp = Comprehensiveness, Div = Diversity, Emp = Empowerment. "-clues" and "-subgraph" represent ablated versions removing
0434 [p9] the respective retrieval mechanisms, with "-subgraph" using one-hop retrieval only.
0435 [p9] 4.1. Course Discovery System
0436 [p9] We adapted AcademicRAG for educational
0437 [p9] content navigation using 29 acoustics-related course
0438 [p9] syllabi from KTH Royal Institute of Technology. The
0439 [p9] system required minimal framework modifications,
0440 [p9] including education-specific entity schemas for
0441 [p9] courses and prerequisites, c ourse-structure-preserving
0442 [p9] chunking strategies, and domain-tailored prompts
0443 [p9] optimized for educational content processing.
0444 [p9] The resulting knowledge graph comprised
0445 [p9] 1211 nodes and 2252 edges with strong local
0446 [p9] clustering, demonstrating effective capture of course
0447 [p9] relationships and prerequisite structures. The largest
0448 [p10] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0449 [p10] 25-27 November 2025, Innsbruck, Austria
0450 [p10] 9
0451 [p10] connected component encompassed 94.63 % of all
0452 [p10] nodes, indicating well-integrated knowledge
0453 [p10] representation across the curriculum.
0454 [p10] Case study evaluation focused on two distinct user
0455 [p10] groups with different information needs. For students,
0456 [p10] the system demonstrated s ophisticated curriculum
0457 [p10] mapping capabilities by generating logical learning
0458 [p10] progressions that respect educational hierarchies,
0459 [p10] providing precise prerequisite identification for
0460 [p10] advanced courses, and delivering multi-dimensional
0461 [p10] course recommendations balancing theoretical
0462 [p10] foundations with practical laboratory components. For
0463 [p10] faculty and administrators, the system successfully
0464 [p10] classified all courses by academic level and offering
0465 [p10] term, identified content overlaps through learning
0466 [p10] o u t c o m e  a n a l y s i s ,  a n d  g e n e rated specific integration
0467 [p10] proposals with clear implementation methodologies.
0468 [p10] These capabilities enable evidence-based curriculum
0469 [p10] optimization and resource allocation decisions that
0470 [p10] transform abstract analyses into executable
0471 [p10] administrative workflows.
0472 [p10] 4.2. Research Literature Assistant
0473 [p10] The Research Literature Assistant was developed
0474 [p10] using over 80 research papers across multiple
0475 [p10] academic domains, with framework adaptations
0476 [p10] including specialized prompts for academic content,
0477 [p10] automated title and introduction extraction methods,
0478 [p10] and structure-aware chunking strategies that preserve
0479 [p10] paper organization.
0480 [p10] We conducted comprehensive evaluation through
0481 [p10] literature review scenario testing, focusing on blind
0482 [p10] face restoration within  computer vision as a
0483 [p10] representative domain with methodological diversity.
0484 [p10] The assistant demonstrated exceptional performance
0485 [p10] across multiple dimensions: identifying major research
0486 [p10] trends and specific gaps in the field, providing
0487 [p10] contextual paper recommendations with multi-faceted
0488 [p10] contribution analysis, extracting detailed technical
0489 [p10] information typically requiring manual paper review,
0490 [p10] and organizing literature into coherent methodological
0491 [p10] categories spanning fundamental works,
0492 [p10] domain-specific applications, and hybrid approaches.
0493 [p10] User testing with graduate students revealed
0494 [p10] significant advantages over online LLM-based
0495 [p10] systems, particularly in acc ommodating larger paper
0496 [p10] corpora while maintaining higher factual accuracy.
0497 [p10] The system's grounding in indexed content minimized
0498 [p10] probability of hallucination issues common in
0499 [p10] general-purpose LLMs, ensuring responses remained
0500 [p10] anchored to actual paper content. Key strengths
0501 [p10] included effective research g ap identification, precise
0502 [p10] semantic search capabilities across multiple papers,
0503 [p10] and comprehensive paper relationship mapping that
0504 [p10] revealed hidden connections between publications.
0505 [p10] 4.3. Practical Insights and Limitations
0506 [p10] Both applications demonstrated the framework's
0507 [p10] cross-domain adaptability through its modular design
0508 [p10] and LLM-driven entity-relationship extraction with
0509 [p10] domain-specific prompt engineering. However,
0510 [p10] several practical limitations emerged that warrant
0511 [p10] acknowledgment. Firstly, the framework exhibits
0512 [p10] weaker comprehension of non-textual elements such as
0513 [p10] f i g u r e s ,  m a t h e m a t i c a l  f o r m u l a s ,  a n d  c o m p l e x
0514 [p10] diagrams, which constitute  critical components of
0515 [p10] academic content across many  disciplines. Secondly,
0516 [p10] the system demonstrates significant dependency on
0517 [p10] underlying LLM capabilities, with quality variations in
0518 [p10] the base model directly impacting system reliability
0519 [p10] and output consistency. Thirdly, our experimental
0520 [p10] validation was constrained by computational resource
0521 [p10] limitations, restricting the scale of evaluation to
0522 [p10] relatively small-scale depl oyments, which may limit
0523 [p10] the generalizability of findings to large-scale
0524 [p10] institutional applications. Despite these constraints,
0525 [p10] both applications provided substantial value for
0526 [p10] academic workflows, particularly in educational
0527 [p10] pathway planning and literature synthesis tasks,
0528 [p10] validating AcademicRAG's potential for transforming
0529 [p10] academic resource discovery across diverse
0530 [p10] institutional contexts while highlighting areas
0531 [p10] requiring future research attention.
0532 [p10] 5. Conclusions
0533 [p10] This work presents AcademicRAG, a novel
0534 [p10] knowledge graph-enhanced RAG framework that
0535 [p10] significantly advances academic resource discovery
0536 [p10] through two key technical innovations: clue-guided
0537 [p10] keyword generation and subgraph-based retrieval. By
0538 [p10] anchoring keyword extraction in actual graph content
0539 [p10] and constructing complete subgraphs, our framework
0540 [p10] addresses fundamental limitations in existing
0541 [p10] approaches while achieving superior computational
0542 [p10] efficiency compared to  GraphRAG's community-
0543 [p10] based architecture. Comprehensive evaluation across
0544 [p10] agriculture and computer science domains
0545 [p10] demonstrates consistent performance advantages over
0546 [p10] state-of-the-art baselines, with win rates exceeding
0547 [p10] 50 % across all evaluation dimensions. The
0548 [p10] framework's dual-level retrieval approach effectively
0549 [p10] balances local detail extraction with global context
0550 [p10] discovery, particularly excelling in comprehensiveness
0551 [p10] and user empowerment ‚Äì the most critical metrics for
0552 [p10] academic information discovery.
0553 [p10] The practical utility of AcademicRAG is validated
0554 [p10] through successful deploym ent of two real-world
0555 [p10] applications: a Course Discovery System enabling
0556 [p10] sophisticated curriculum an alysis, and a Research
0557 [p10] Literature Assistant providing factually grounded
0558 [p10] literature synthesis capabilities. Both applications
0559 [p10] demonstrate the framework's versatility and
0560 [p10] cross-domain adaptability through minimal
0561 [p10] modifications, successfully addressing distinct
0562 [p10] information needs for students, faculty, and
0563 [p10] researchers. The applications revealed important
0564 [p10] insights about academic workflows while highlighting
0565 [p10] the framework's ability to transform unstructured
0566 [p10] academic content into semantically rich, queryable
0567 [p11] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0568 [p11] 25-27 November 2025, Innsbruck, Austria
0569 [p11] 10
0570 [p11] knowledge representations that support
0571 [p11] evidence-based decision-making.
0572 [p11] Despite these advances, several limitations warrant
0573 [p11] acknowledgment, including significant dependency on
0574 [p11] underlying LLM capabilities, weaker comprehension
0575 [p11] of non-textual elements, and restricted experimental
0576 [p11] validation scale. Future work should prioritize
0577 [p11] multi-modal content processing, scalability
0578 [p11] optimization, and comprehensive human expert
0579 [p11] evaluation to strengthen the foundation for
0580 [p11] next-generation academic resource discovery systems.
0581 [p11] Acknowledgements
0582 [p11] The computations and data handling were enabled
0583 [p11] by resources provided by the National Academic
0584 [p11] Infrastructure for Supercomputing in Sweden
0585 [p11] (NAISS), partially funded by the Swedish Research
0586 [p11] Council through grant agreement no. 2022-06725. We
0587 [p11] specifically acknowledge the computational resources
0588 [p11] allocated through NAISS project "GraphRAG for
0589 [p11] Academic Resource Discovery: A Dual-Application
0590 [p11] Framework", which provided essential GPU
0591 [p11] computing power on the Alvis system at C3SE and
0592 [p11] storage resources on Mimer, enabling the extensive
0593 [p11] experimentation and evaluation presented in this work.
0594 [p11] Elias Zea gratefully acknowledges the financial
0595 [p11] support of the Swedish Research Council, Grant No.
0596 [p11] 2020-04668. This work was also partially supported by
0597 [p11] grants from the Excellence Center at Link√∂ping-Lund
0598 [p11] for Information Technology (ELLIIT), which we
0599 [p11] gratefully acknowledge.
0600 [p11] References
0601 [p11] [1]. W. Ammar, et al., Construction of the literature graph
0602 [p11] in semantic scholar, in Proceedings of the Conference
0603 [p11] of the North American Chapter of the Association for
0604 [p11] Computational Linguistics: Human Language
0605 [p11] Technologies, Vol. 3 (Industry Papers), 2018,
0606 [p11] pp. 84-91.
0607 [p11] [2]. S. Ji, S. Pan, E. Cambria, P. Marttinen, et al., A survey
0608 [p11] on knowledge graphs: representation, acquisition, and
0609 [p11] applications, IEEE Transactions on Neural Networks
0610 [p11] and Learning Systems , Vol. 33, Issue 2, 2022,
0611 [p11] pp. 494-514.
0612 [p11] [3]. S. Robertson, H. Zaragoza, The probabilistic relevance
0613 [p11] framework: BM25 and beyond, Foundations and
0614 [p11] Trends in Information Retrieval, Vol. 3, Issue 4, 2009,
0615 [p11] pp. 333-389.
0616 [p11] [4]. J. Wang, et al., Utilizing BERT for information
0617 [p11] retrieval: survey, applications, resources, and
0618 [p11] challenges, ACM Computing Surveys, Vol. 56, Issue 7,
0619 [p11] 2024, pp. 1-33.
0620 [p11] [5]. P. Lewis, et al., Retrieval-augmented generation for
0621 [p11] knowledge-intensive NLP tasks, Advances in Neural
0622 [p11] Information Processing Systems , Vol. 33, 2020,
0623 [p11] pp. 9459-9474.
0624 [p11] [6]. X. Li, et al., From match ing to generation: a survey on
0625 [p11] generative information retrieval, ACM Transactions on
0626 [p11] Information Systems, Vol. 43, Issue 3, 2025, 83.
0627 [p11] [7]. B. Peng, et al., Graph re trieval-augmented generation:
0628 [p11] a survey, arXiv preprint, 2024, arXiv:2408.08921.
0629 [p11] [8]. D. Edge, et al., From local to global: a graph RAG
0630 [p11] approach to query-focused summarization, arXiv
0631 [p11] preprint, 2024, arXiv:2404.16130.
0632 [p11] [9]. Z. Guo, L. Xia, Y. Yu, T. Ao, et al., LightRAG: simple
0633 [p11] and fast retrieval-augmented generation, arXiv
0634 [p11] preprint, 2024, arXiv:2410.05779.
0635 [p11] [10]. Y. Hu, Z. Lei, Z. Zhang, B. Pan, et al., GRAG: graph
0636 [p11] retrieval-augmented generation, arXiv preprint, 2024,
0637 [p11] arXiv:2405.16506.
0638 [p11] [11]. B. Sarmah, et al., HybridRAG: integrating knowledge
0639 [p11] graphs and vector retrieval augmented generation for
0640 [p11] efficient information extraction, in Proceedings of the
0641 [p11] 5th ACM International Confer ence on AI in Finance ,
0642 [p11] 2024, pp. 608-616.
0643 [p11] [12]. Y. Hu, Z. Lei, Z. Dai, A. Zhang, et al., CG-RAG:
0644 [p11] research question answering by citation graph retrieval-
0645 [p11] augmented LLMs, arXiv preprint , 2025,
0646 [p11] arXiv:2501.15067.
0647 [p11] [13]. S. Chen, Z. Liu, A cademicRAG: knowledge graph
0648 [p11] enhanced retrieval-augmented generation for academic
0649 [p11] resource discovery, Master's Thesis, KTH Royal
0650 [p11] Institute of Technology & Aalto University, 2025.
0651 [p11] [14]. H. Qian, P. Zhang, Z. Liu, K. Mao, et al., MemoRAG:
0652 [p11] moving towards next-gen RAG via memory-inspired
0653 [p11] knowledge discovery, arXiv preprint , 2024,
0654 [p11] arXiv:2409.05591.
0655 [p11] [15]. A. Yang, et al., Qwen2.5 technical report, arXiv
0656 [p11] preprint, 2024, arXiv:2412.15115.
0657 [p11] [16]. DeepSeek-AI, DeepSeek-R1: incentivizing reasoning
0658 [p11] capability in LLMs via reinforcement learning, arXiv
0659 [p11] preprint, 2025, arXiv:2501.12948.
0660 [p12] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0661 [p12] 25-27 November 2025, Innsbruck, Austria
0662 [p12] 11
0663 [p12] (007)
0664 [p12] A Holistic Privacy-preserving Framework for the Federated
0665 [p12] Learning Lifecycle
0666 [p12] Luc√≠a Mu√±oz-Solanas, Amaia Gil-Lerchundi
0667 [p12] Vicomtech, Basque Research and Technology Alliance (BRTA), San Sebastian, Spain
0668 [p12] E-mail: lmunoz@vicomtech.org, agil@vicomtech.org
0669 [p12] Summary: Federated Learning is vulnerable to privacy attacks on federated model updates. This paper introduces ASTER, a
0670 [p12] holistic, framework providing end-to-end privacy for the Federa ted Learning lifecycle. The architecture combines three
0671 [p12] cryptographic stages: an e-voting inspired mix-net for anonymous training submissions; Homomorphic Encryption for secure
0672 [p12] server-side inference; and Secret Sharing Schemes for threshold -based control over model retraining. This system prevents
0673 [p12] user-contribution linking while guaranteeing data confidentiality and model integrity, creating a robust framework for sensitive
0674 [p12] applications.
0675 [p12] Keywords: Privacy-preserving, Federated learning, E-voting, Homomorphic encryption, Secret sharing.
0676 [p12] 1. Introduction
0677 [p12] Federated Learning (FL) enhances privacy by
0678 [p12] training on decentralized data kept on user devices.
0679 [p12] However, this process remains vulnerable to privacy
0680 [p12] breaches, particularly from the central server. Such
0681 [p12] server, while correctly following the protocol, can still
0682 [p12] analyze received model parameters to infer sensitive
0683 [p12] information and link contributions back to specific
0684 [p12] users [1]. This threat is critical in sensitive domains,
0685 [p12] and this work will focus specifically on the energy
0686 [p12] sector, where building consumption patterns can reveal
0687 [p12] private user behaviors.
0688 [p12] A key limitation of many existing solutions is that
0689 [p12] they focus on protecting a single phase of the FL
0690 [p12] process rather than providing end-to-end protection.
0691 [p12] This leaves critical vulnerab ilities at different stages;
0692 [p12] during training, the link ability between a user and their
0693 [p12] update is a major risk; during inference, a client's
0694 [p12] private query data is exposed to the server; and
0695 [p12] throughout the model's lifecycle, a malicious actor or a
0696 [p12] small colluding group could unilaterally alter the
0697 [p12] model, compromising its integrity. While techniques
0698 [p12] like Differential Privacy (DP) [2] can obscure training
0699 [p12] data, they often harm model accuracy, and while
0700 [p12] Homomorphic Encryption (HE) can protect inference
0701 [p12] queries, it often introduces prohibitive computational
0702 [p12] overhead for the entire training process [3].
0703 [p12] To address these multi-faceted threats in a unified
0704 [p12] manner, this paper proposes a holistic, multi-stage
0705 [p12] privacy-preserving framewor k, developed within the
0706 [p12] ASTER project, that safeguards sensitive data across
0707 [p12] its entire lifecycle: training, inference, and
0708 [p12] aggregation. The main contributions of this work are
0709 [p12] threefold, with each component designed to counter a
0710 [p12] specific threat:
0711 [p12] ÔÇ∑ To prevent user-contribution linking during
0712 [p12] training phase , an anonymization scheme
0713 [p12] inspired by electronic voting protocol is
0714 [p12] introduced. Using a mix-ne t architecture with a
0715 [p12] hybrid ElGamal+AES encryption scheme, the
0716 [p12] central server can aggregate model parameters
0717 [p12] without linking them to the originating clients;
0718 [p12] ÔÇ∑ To protect client data during the inference
0719 [p12] phase, HE is leveraged, enabling clients to obtain
0720 [p12] predictions from the global model using their
0721 [p12] private data without ever revealing it in plaintext
0722 [p12] to the server;
0723 [p12] ÔÇ∑ To secure the retrain ing process against
0724 [p12] malicious or unilateral alterations , Secret
0725 [p12] Sharing Schemes (SSS) are employed. This
0726 [p12] mechanism ensures that the federated model can
0727 [p12] only be updated if a minimum threshold of
0728 [p12] participants collaboratively agrees, establishing a
0729 [p12] democratic and robust control over the model.
0730 [p12] 2. Related Work
0731 [p12] While the federated paradigm inherently improves
0732 [p12] privacy, it remains vulnerable to attacks such as
0733 [p12] membership inference [4] and model inversion [5]. To
0734 [p12] mitigate these risks, several Privacy-Enhancing
0735 [p12] Techniques (PETs) have been proposed, though they
0736 [p12] often focus on securing a single phase of the
0737 [p12] FL process.
0738 [p12] A foundational approach is secure aggregation,
0739 [p12] where the server computes the sum of client updates
0740 [p12] without inspecting individual contributions. This is
0741 [p12] often implemented with SSS [6]. While this effectively
0742 [p12] protects the content of the updates, it does not
0743 [p12] anonymize the participants. The server still knows
0744 [p12] which clients are participating, which can be a source
0745 [p12] of information leakage. ASTER addresses this gap
0746 [p12] directly with its e-voting inspired mix-net, which
0747 [p12] anonymizes the source of c ontributions before they
0748 [p12] reach the server.
0749 [p12] Another line of work explores HE. The application
0750 [p12] of HE to protect the inference phase in FL is a
0751 [p12] well-established research direction, with multiple
0752 [p12] studies exploring its use to allow clients to receive
0753 [p12] predictions on their private data without revealing it to
0754 [p13] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0755 [p13] 25-27 November 2025, Innsbruck, Austria
0756 [p13] 12
0757 [p13] the server [7]. However, it is widely recognized that
0758 [p13] the primary limitation of HE is its significant
0759 [p13] computational overhead, which can make it
0760 [p13] impractical for latency-sensitive applications [8].
0761 [p13] While these works provide crucial solutions for the
0762 [p13] specific problem of private inference, the contribution
0763 [p13] of ASTER is not to propose a new inference algorithm.
0764 [p13] Instead, our novelty lies in the holistic integration of a
0765 [p13] secure inference mechanism within a complete,
0766 [p13] end-to-end lifecycle framework.
0767 [p13] A complementary approach is Differential Privacy
0768 [p13] (DP), which adds calibrated noise to model updates to
0769 [p13] provide formal privacy guarantees [9]. However, DP
0770 [p13] introduces a fundamental trade-off: stronger privacy
0771 [p13] requires more noise, which  can significantly reduce
0772 [p13] model accuracy [10].
0773 [p13] Finally, while general-purpose FL platforms like
0774 [p13] FATE, OpenFL, and PySyft provide toolkits for
0775 [p13] implementing these PETs, they are not prescriptive
0776 [p13] architectural solutions. In contrast, ASTER proposes a
0777 [p13] specific, integrated architecture that combines multiple
0778 [p13] cryptographic protocols by default. Furthermore, a key
0779 [p13] contribution of ASTER, rarely addressed in other
0780 [p13] frameworks, is the democratic governance of the
0781 [p13] model lifecycle. By incorporating SSS for controlling
0782 [p13] retraining, ASTER intr oduces a mechanism for
0783 [p13] distributed, threshold-based consensus, protecting the
0784 [p13] model from unauthorized unilateral modifications.
0785 [p13] This holistic approach, combining anonymity,
0786 [p13] confidential inference, and democratic control,
0787 [p13] addresses the need for  a more robust and
0788 [p13] comprehensive solution for the entire FL lifecycle.
0789 [p13] 3. Multi-stage Privacy Framework
0790 [p13] The proposed framework comprises three
0791 [p13] interconnected stages, each designed to protect a
0792 [p13] specific phase of the FL lifecycle against privacy
0793 [p13] breaches. The architecture ensures data protection
0794 [p13] during model training, inference, and the final
0795 [p13] aggregation process.
0796 [p13] 3.1. Anonymized Training Phase
0797 [p13] The framework incorporates a mix-net architecture
0798 [p13] to address the risk of linking a user's data profile to
0799 [p13] their initial model contribution. This approach,
0800 [p13] inspired by anonymous electronic voting systems [11],
0801 [p13] decouples the user's identity from their trained model
0802 [p13] before it reaches the central server.
0803 [p13] The process begins after a client trains a model on
0804 [p13] its local dataset and employs a layered encryption
0805 [p13] s c h e m e .  F i r s t ,  t h e  c l i e n t  c r e a t e s  a  s e c u r e  p a c k a g e
0806 [p13] intended only for the final server: the model
0807 [p13] parameters are encrypted with a symmetric key ( K
0808 [p13] sym)
0809 [p13] via a cipher like AES, and this key is then separately
0810 [p13] encrypted with the central server's public key (PKServer)
0811 [p13] via a scheme like ElGamal. Second, this package is
0812 [p13] encrypted again, this time using the public key of the
0813 [p13] intermediate server ( PK
0814 [p13] Mixer), creating an outer
0815 [p13] cryptographic layer (see Fig. 1).
0816 [p13] Fig. 1. Clients send layered encrypted packages.
0817 [p13] This final double-encrypte d package is submitted
0818 [p13] to an intermediate server, the Mixer. Upon receiving a
0819 [p13] batch of packages, the Mixer uses its private key
0820 [p13] (SKMixer ) to decrypt only the outer layer, revealing the
0821 [p13] still-encrypted packages. The Mixer, therefore, has no
0822 [p13] access to the actual model parameters. It then shuffles
0823 [p13] these packages to break the relation between the
0824 [p13] incoming and outgoing order (illustrated in Fig. 2) and
0825 [p13] forwards the reordered batch to the central server.
0826 [p13] Fig. 2. Mixer decrypts and shuffles packages.
0827 [p13] Consequently, the central server receives and
0828 [p13] d e c r y p t s  a  s e t  o f  f u l l y  t r a i n e d  l o c a l  m o d e l s  b u t  i s
0829 [p13] computationally prevented from determining the
0830 [p13] source of any individual model. The server then
0831 [p13] aggregates these anonymized models to produce the
0832 [p13] federated model, having preserved user anonymity
0833 [p13] throughout the process.
0834 [p13] 3.2. Secure Inference Phase
0835 [p13] Once the federated model is established, clients
0836 [p13] require a secure method to use it for predictions in the
0837 [p13] central server without revealing their sensitive input
0838 [p13] data. The framework leverages HE to facilitate this
0839 [p13] private inference phase, with support for linear
0840 [p13] autoregressive models and tree-based models.
0841 [p13] A client encrypts its input vector, x
0842 [p13] i, with its HE
0843 [p13] public key, and sends the resulting ciphertext ci to the
0844 [p14] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0845 [p14] 25-27 November 2025, Innsbruck, Austria
0846 [p14] 13
0847 [p14] server. The server then processes this ciphertext using
0848 [p14] a homomorphic adapted global model. The server
0849 [p14] executes the inference pass directly on the encrypted
0850 [p14] data, producing an encrypted prediction, yenc. This
0851 [p14] encrypted result is returned to the client. Finally, only
0852 [p14] the client can decrypt y
0853 [p14] enc using their corresponding
0854 [p14] private key to obtain the final prediction in plaintext.
0855 [p14] This process guarantees that the server never accesses
0856 [p14] the client's input data or the final prediction, ensuring
0857 [p14] end-to-end confidentiality.
0858 [p14] 3.3. Secure Retraining Phase
0859 [p14] To prevent unauthorized modifications and ensure
0860 [p14] that federated model updates result from a broad
0861 [p14] consensus, the framework implements a conditional
0862 [p14] aggregation mechanism based on a SSS. This adds a
0863 [p14] layer of democratic and robust control over the model's
0864 [p14] lifecycle [12].
0865 [p14] A (t,n)-threshold Shamir's Secret Sharing scheme
0866 [p14] is employed, where n is the total number of clients in
0867 [p14] the federation and t is the minimum participation
0868 [p14] threshold required to authorize an update. The
0869 [p14] protected secret is a master key, K
0870 [p14] M, which enables the
0871 [p14] next aggregation round. This key is split into n unique
0872 [p14] shares, {s1,...,sn}, and each client is securely issued one
0873 [p14] share. By design, any subset of fewer than t s h a r e s
0874 [p14] reveals no information about the master key.
0875 [p14] When a new model aggregation round is proposed,
0876 [p14] clients who wish to participate must submit their shares
0877 [p14] to the server. If the number of submitted shares is
0878 [p14] greater than or equal to the threshold t, the master key
0879 [p14] K
0880 [p14] M can be successfully reconstructed. The
0881 [p14] reconstructed key is then used to authorize and execute
0882 [p14] the aggregation process. This prevents unauthorized
0883 [p14] model modifications by small coalitions and enforces
0884 [p14] distributed, fault-tolerant control over the model's
0885 [p14] evolution.
0886 [p14] 4. Conclusions and Future Work
0887 [p14] This paper introduced ASTER, a holistic
0888 [p14] framework providing end-to-end FL privacy by
0889 [p14] combining an e-voting inspired mix-net for anonymity,
0890 [p14] H E  f o r  p r i v a t e  i n f e r e n c e ,  a n d  a  S S S  f o r  c o n d i t i o n a l
0891 [p14] aggregation. The result is a system that protects user
0892 [p14] data while ensuring the integrity and democratic
0893 [p14] control of the global model's evolution.
0894 [p14] Future work will focus on two key challenges. The
0895 [p14] first is extending HE-based secure inference to Deep
0896 [p14] Learning models. This is non-trivial due to the
0897 [p14] complex substitution required for non-linear activation
0898 [p14] functions and the potential impact on model accuracy
0899 [p14] [13]. The second challenge is the significant
0900 [p14] computational latency introduced by HE operations.
0901 [p14] To address this, an alternative architecture will be
0902 [p14] explored where clients securely download the global
0903 [p14] model to perform fast, local predictions on their own
0904 [p14] devices. This hybrid approach could offer the ideal
0905 [p14] balance between the privacy of server-side
0906 [p14] computation and the low-latency performance required
0907 [p14] for real-time applications.
0908 [p14] References
0909 [p14] [1]. N. Bouacida, P. Mohapatra, Vulnerabilities in federated
0910 [p14] learning, IEEE Access, Vol. 9, 2021, pp. 63229-63249.
0911 [p14] [2]. K. Wei, J. Li, M. Ding, C. Ma, et al., Federated learning
0912 [p14] with differential privacy: algorithms and performance
0913 [p14] analysis, IEEE Transactions on Information Forensics
0914 [p14] and Security, Vol. 15, 2020, pp. 3454-3469.
0915 [p14] [3]. H. Fang, Q. Qian, Privacy preserving machine learning
0916 [p14] with homomorphic encryption and federated learning,
0917 [p14] Future Internet, Vol. 13, Issue 4, 2021, 94.
0918 [p14] [4]. R. Shokri, M. Stronati, C. Song, V. Shmatikov,
0919 [p14] Membership inference attacks against machine
0920 [p14] learning models, in Proceedings of the IEEE
0921 [p14] Symposium on Security and Privacy (SP‚Äô17) , 2017,
0922 [p14] pp. 3-18.
0923 [p14] [5]. Y. Li, Y. Zhou, A. Jolfaei, D. Yu, et al.,
0924 [p14] Privacy-preserving federated learning framework
0925 [p14] based on chained secure multiparty computing, IEEE
0926 [p14] Internet of Things Journal , Vol. 8, Issue 8, 2021,
0927 [p14] pp. 6178-6186.
0928 [p14] [6]. H. Zhu, R. S. M. Goh, W. K. Ng, Privacy-preserving
0929 [p14] weighted federated learning within the secret sharing
0930 [p14] framework, IEEE Access , Vol. 8, 2020,
0931 [p14] pp. 198275-198284.
0932 [p14] [7]. J. Ma, S. A. Naas, S. Si gg, X. Lyu, Privacy-preserving
0933 [p14] federated learning based on multi-key homomorphic
0934 [p14] encryption, International Journal of Intelligent
0935 [p14] Systems, Vol. 37, Issue 9, 2022, pp. 5880-5901.
0936 [p14] [8]. C. Zhang, S. Li, J. Xia, W. Wang, et al., {BatchCrypt}:
0937 [p14] efficient homomorphic encryption for {Cross-Silo}
0938 [p14] federated learning, in Proceedings of the USENIX
0939 [p14] Annual Technical Confer ence (USENIX ATC'20) ,
0940 [p14] 2020, pp. 493-506.
0941 [p14] [9]. A. El Ouadrhiri, A. Abdelhadi, Differential privacy for
0942 [p14] deep and federated learning: a survey, IEEE Access ,
0943 [p14] Vol. 10, 2022, pp. 22359-22380.
0944 [p14] [10]. S. Truex, L. Liu, K. H. Chow, M. E. Gursoy, et al.,
0945 [p14] LDP-Fed: federated learning with local differential
0946 [p14] privacy, in Proceedings of the Third ACM International
0947 [p14] Workshop on Edge Systems, Analytics and Networking
0948 [p14] (EdgeSys'20), 2020, pp. 61-66.
0949 [p14] [11]. Y. -X. Kho, S. -H. Heng, J. -J. Chin, A review of
0950 [p14] cryptographic electronic voting, Symmetry, Vol. 14,
0951 [p14] Issue 5, 2022, 858.
0952 [p14] [12]. K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone,
0953 [p14] et al., Practical secure aggregation for
0954 [p14] privacy-preserving machine learning, in Proceedings of
0955 [p14] the ACM SIGSAC Conference on Computer and
0956 [p14] Communications Security, 2017, pp. 1175-1191.
0957 [p14] [13]. S. Obla, X. Gong, A. Aloufi, P. Hu, et al., Effective
0958 [p14] activation functions for homomorphic evaluation of
0959 [p14] deep neural networks, IEEE Access , Vol. 8, 2020,
0960 [p14] pp. 153098-153112.
0961 [p15] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
0962 [p15] 25-27 November 2025, Innsbruck, Austria
0963 [p15] 14
0964 [p15] (011)
0965 [p15] A Guide to Feature-preserving Pseudonymization of Profile Pictures
0966 [p15] Y. Lee, H. Bothe and M. Geierhos
0967 [p15] University of the Bundeswehr Munich, RI CODE, Werner-Heisenberg-Weg 39, 85579 Munich, Germany
0968 [p15] Tel.: +498960047343
0969 [p15] E-mail: {yeongsu.lee, hendrik.bothe, michaela.geierhos}@unibw.de
0970 [p15] Summary: To address the privacy risks associated with biometric data, we propose a method of pseudonymizing social media
0971 [p15] profile pictures. Unlike existing approaches that focus on text  and structured data, profile im ages can directly identify user s.
0972 [p15] Our pipeline uses FaceNet and DeepFace to extract facial attributes, such as age, gender, and expression. It then formats these
0973 [p15] attributes as JSON and converts them to descriptive text using Mistral (7B). A multimodal model called Janus then uses this
0974 [p15] text to generate synthetic, identity-free profile images that r etain facial features. All pro cessing is done locally to ensure
0975 [p15] compliance with the GDPR and a void data exposure. These pseudon ymized images support research and machine learning
0976 [p15] tasks while protecting privacy. To evaluate image quality and privacy, we cluster the original and pseudonymized images and
0977 [p15] compare them using the Adjusted Rand Index and Normalized Mutua l Information metrics. These metrics assess semantic
0978 [p15] consistency and identity separation. Our method securely and et hically analyzes social media data by combining facial
0979 [p15] de-identification, large language models, and generative image synthesis in a unified workflow.
0980 [p15] Keywords: Privacy of profile images, Facial feature extraction, Synthetic image generation.
0981 [p15] 1. Introduction
0982 [p15] Profile pictures on social media platforms contain
0983 [p15] biometric information that can be used to directly
0984 [p15] identify individuals. Therefore, these images must be
0985 [p15] fully protected. Textual ps eudonymization alone is
0986 [p15] insufficient. Since facial images can be
0987 [p15] cross-referenced across plat forms or used for facial
0988 [p15] recognition, retaining real pro file pictures in research
0989 [p15] datasets poses significant re-identification risks.
0990 [p15] To address this issue, we are expanding the scope
0991 [p15] of conventional pseudonymization to include visual
0992 [p15] elements. Our proposed method replaces original face
0993 [p15] images with synthetic, anonymized alternatives that
0994 [p15] are semantically consisten t. These synthetic images
0995 [p15] will retain attributes such as age, gender, ethnicity, and
0996 [p15] other facial features, including emotional expression.
0997 [p15] This allows for meaningful analysis while ensuring
0998 [p15] that individuals cannot be re-identified. Our approach
0999 [p15] improves upon earlier text- and attribute-based
1000 [p15] pseudonymization techniques by integrating local
1001 [p15] image synthesis in a pri vacy-safe manner. Our
1002 [p15] implementation operates enti rely on local hardware,
1003 [p15] eliminating reliance on external APIs or cloud-based
1004 [p15] models. This reduces exposure to external threats and
1005 [p15] strengthens overall data security for sensitive research.
1006 [p15] 2. Related Work
1007 [p15] The issue of face pseudonymization has been
1008 [p15] addressed in several domains. One notable approach is
1009 [p15] DeepPrivacy, which uses conditional generative
1010 [p15] adversarial networks (GANs) to synthesize faces while
1011 [p15] preserving the scene‚Äôs context. This method allows for
1012 [p15] anonymization without cropping or blurring [1].
1013 [p15] Building on this foundation, DeepPrivacy2
1014 [p15] incorporates facial attributes such as age and gender
1015 [p15] while maintaining realism and enhancing control [2].
1016 [p15] Another approach is IdentityDP [3], which introduces
1017 [p15] privacy-preserving transformations using differential
1018 [p15] privacy. These methods inject calibrated noise into
1019 [p15] face representations, which limits the risk of
1020 [p15] re-identification, even when adversaries have
1021 [p15] more data.
1022 [p15] Recent studies have pro posed anonymization
1023 [p15] frameworks that optimize the generative model
1024 [p15] alongside identity supervision components. These
1025 [p15] frameworks use adversarial identity constraints and
1026 [p15] attribute similarity losses to balance privacy and utility
1027 [p15] [4, 5]. However, few approaches integrate large
1028 [p15] language models (LLMs) into the pipeline. Building on
1029 [p15] this research, our method uses attribute extraction and
1030 [p15] LLM-based description generation to synthesize
1031 [p15] pseudonymous images with the multimodal Janus
1032 [p15] generative model. This allows for fine-grained control
1033 [p15] over the appearance of the synthesized face and
1034 [p15] enables flexible adaptation to different demographic
1035 [p15] needs. Unlike black-box GANs, our method is
1036 [p15] interpretable, extendabl e, and capable of local
1037 [p15] execution. It provides privacy without compromising
1038 [p15] analytical usefulness.
1039 [p15] 3. Our Approach
1040 [p15] Our profile picture pseudonymization pipeline
1041 [p15] consists of five main stages from face detection to
1042 [p15] pseudonymized profile image generation.
1043 [p15] (1) The first steps in the process are face detection
1044 [p15] and cropping. We use a FaceNet-based facial detection
1045 [p15] algorithm to extract faces from profile pictures, which
1046 [p16] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1047 [p16] 25-27 November 2025, Innsbruck, Austria
1048 [p16] 15
1049 [p16] are marked by a red box that includes the detection
1050 [p16] score1. Then, we extend the detected area to include
1051 [p16] more information, such as hairstyle and accessories, as
1052 [p16] marked by the orange box in Fig. 1.
1053 [p16] Fig. 1. An example of the pseudonymization process.
1054 [p16] (2) Next, the extended images are passed to the
1055 [p16] facial attribute extraction tools. Using FaceNet [6] and
1056 [p16] DeepFace [7, 8], we identif y features such as age,
1057 [p16] gender, emotion, ethnicity, skin tone, and head pose.
1058 [p16] These attributes are then structured into a standardized
1059 [p16] JSON format. There are 52 extracted attributes,
1060 [p16] categorized into 12 feature classes. These classes range
1061 [p16] from general features, such as gender and age, to
1062 [p16] emotions, including happy, sad, angry, and neutral.
1063 [p16] (3) Then, the JSON-encoded attributes are sent as
1064 [p16] instructions to Mistral (7B), which is running locally
1065 [p16] through the Ollama interface
1066 [p16] 2. This step is required
1067 [p16] because Janus does not seem to rightly interpreted the
1068 [p16] JSON-encoded data. In our experiment, it produced an
1069 [p16] abstract image that was irrelevant to the human profile
1070 [p16] image. The model produces coherent, natural-language
1071 [p16] descriptions of the face, suc h as ‚Äúa smiling woman in
1072 [p16] her mid-30s with East Asian features and
1073 [p16] medium-length black hair‚Äù. To coherently convert the
1074 [p16] JSON-encoded attributes, they are classified according
1075 [p16] to their inherent characteristics. Thus, while some
1076 [p16] attribute classes such a s accessories including
1077 [p16] ‚Äúeyeglasses‚Äù, ‚Äúwearing hat‚Äù, ‚Äúwearing necktie‚Äù,
1078 [p16] ‚Äúwearing necklace‚Äù, or ‚Äúwearing earrings‚Äù are encoded
1079 [p16] 1 https://github.com/faustomorales/keras-facenet
1080 [p16] 2 https://ollama.com/library/mistral
1081 [p16] as Boolean values, other attributes classes such as
1082 [p16] ‚Äúoval face‚Äù or ‚Äúbig nose‚Äù are encoded as gradient
1083 [p16] values. Other classes, such as ‚Äúwearing lipstick‚Äù, are
1084 [p16] encoded as scalable values. For example, we divide the
1085 [p16] attribute class ‚Äúwearing lipstick‚Äù into five descriptive
1086 [p16] expressions according to the extracted values: no
1087 [p16] lipstick, subtle lipstick, mod erate lipstick, noticeable
1088 [p16] lipstick, and bold lipstick. Both these expressions and
1089 [p16] the JSON-encoded data are fed to Mistral for the
1090 [p16] generation of an accurate text description of the
1091 [p16] original profile picture. For all attribute classes, the
1092 [p16] threshold is set according to the statistical calculation
1093 [p16] from the analyzed data.
1094 [p16] (4) The descriptive text is input into Janus-Pro
1095 [p16] (7B)
1096 [p16] 3, a generative model that can produce realistic
1097 [p16] images of faces based on textual prompts. Janus
1098 [p16] synthesizes faces that preserve the extracted attributes
1099 [p16] while completely breaking the visual link to the
1100 [p16] original image. This output image replaces the original
1101 [p16] profile picture in the pseudonymized dataset.
1102 [p16] (5) The new synthetic image is stored with the rest
1103 [p16] o f  t h e  p s e u d o n y m i z e d  p r o f i l e  d a t a .  F i g .  1  s h o w s  a n
1104 [p16] example of the main steps.
1105 [p16] Therefore, this method replaces biometric
1106 [p16] identifiers with synthetic alternatives, protecting
1107 [p16] against facial recognition attacks and compliance
1108 [p16] violations. It allows for the use of downstream
1109 [p16] applications such as demographic studies, personality
1110 [p16] inference, and expression analysis without revealing
1111 [p16] real identities. Furthermore, the pipeline can be
1112 [p16] expanded to include other image generators,
1113 [p16] multilingual descriptions, and LLM upgrades (e.g.,
1114 [p16] Llama 4) to enhance accuracy. Additionally, the
1115 [p16] proposed pipeline can be applied repeatedly to
1116 [p16] generate further profile images as shown in Fig. 2.
1117 [p16] Fig. 2. An example of the recursive generation
1118 [p16] of pseudo-profile images.
1119 [p16] 4. Dataset and Ethical Consideration
1120 [p16] The dataset used in this study consists of profile
1121 [p16] images obtained from publicly accessible XING
1122 [p16] profiles. Data of low quality (face detection confidence
1123 [p16] score < 0.95) was excluded from both statistics and
1124 [p16] experiments. Facial represe ntations were extracted
1125 [p16] 3 https://github.com/deepseek-ai/Janus
1126 [p17] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1127 [p17] 25-27 November 2025, Innsbruck, Austria
1128 [p17] 16
1129 [p17] using two state-of-the-art frameworks: FaceNet,
1130 [p17] yielding 40 numerical features 1, and DeepFace,
1131 [p17] providing 4 high-level categories comprising of
1132 [p17] 15 detailed features in total 2. After consolidating the
1133 [p17] features from both frameworks, 52 features were
1134 [p17] categorized and used for analysis.
1135 [p17] To understand the distributional characteristics of
1136 [p17] the dataset, we conducted an analysis of demographic
1137 [p17] attributes inferred from the facial representations,
1138 [p17] including estimated age, gender, and ethnicity .
1139 [p17] These estimates were obtained via DeepFace‚Äôs
1140 [p17] pre-trained demographic classifiers. While such
1141 [p17] estimations are inherently approximate and potentially
1142 [p17] biased, they were used solely to assess diversity within
1143 [p17] the dataset, not to draw conclusions about individuals.
1144 [p17] Our demographic analysis  revealed a heterogeneous
1145 [p17] distribution of age groups and gender identities,
1146 [p17] although the dataset may exhibit platform-specific
1147 [p17] biases. No manual annotation of demographic traits
1148 [p17] was performed, and no sensitive or protected
1149 [p17] categories were directly labeled or inferred beyond
1150 [p17] algorithmic estimation.
1151 [p17] We acknowledge the ethical complexity of
1152 [p17] working with facial and demographic data, particularly
1153 [p17] regarding the risks of profiling, bias, and unintended
1154 [p17] inferences. To mitigate these risks: (1) only publicly
1155 [p17] available data was used, (2) all features were processed
1156 [p17] locally, and (3) no models were trained or evaluated
1157 [p17] for personal identity or real-world demographic
1158 [p17] classification tasks. Table 1 shows the distribution of
1159 [p17] gender and ethnicity of the used dataset based on the
1160 [p17] classification results of DeepFace. Please note that the
1161 [p17] number of genders and ethnicities is limited to the
1162 [p17] capabilities of DeepFace.
1163 [p17] Table 1. Demographic statistics of the used dataset.
1164 [p17] Men Women
1165 [p17] White 14,524 4,426
1166 [p17] Latino-Hispanic 1,002 206
1167 [p17] Middle Eastern 760 24
1168 [p17] Asian 503 145
1169 [p17] Indian 134 6
1170 [p17] Black 84 10
1171 [p17] Total 17,007 4,817
1172 [p17] 5. Discussion
1173 [p17] To evaluate the effectiveness of profile picture
1174 [p17] pseudonymization, we must analyze both privacy
1175 [p17] protection and data utility. We propose using
1176 [p17] clustering-based evaluation methods. First, a
1177 [p17] consistent face embedding model is used to generate
1178 [p17] facial embeddings for the original and pseudonymized
1179 [p17] images. Then, clustering is applied to both sets. We
1180 [p17] assess the similarity of the clustering structures using
1181 [p17] the adjusted rand index (ARI) and the normalized
1182 [p17] 1 https://tinyurl.com/26qp7jem
1183 [p17] mutual information (NMI). High NMI and ARI values
1184 [p17] suggest that key semantic attributes, such as gender or
1185 [p17] age, are preserved. Conversely, a low identity match
1186 [p17] across clusters confirms successful anonymization.
1187 [p17] Additional validation can be conducted using
1188 [p17] face-matching algorithms to confirm that no identity
1189 [p17] overlap remains. Human evaluation can also be used to
1190 [p17] assess realism and anonymity. Other metrics, such as
1191 [p17] Fr√©chet inception distance (FID), can be used to
1192 [p17] measure perceptual realis m. However, limitations
1193 [p17] include biases in attribute extraction, generation
1194 [p17] artifacts, and ambiguity in prompt interpretation.
1195 [p17] Future work should include automated bias detection
1196 [p17] and adversarial robustness testing.
1197 [p17] 6. Conclusion
1198 [p17] This work expands the scope of pseudonymization
1199 [p17] to include visual content, specifically profile pictures,
1200 [p17] in addition to structured and textual data. Our method
1201 [p17] achieves privacy-preserving replacement of facial
1202 [p17] identity by extracting facial attributes, transforming
1203 [p17] t h e m  v i a  L L M - g e n e r a t e d  t e x t ,  a n d  s y n t h e s i z i n g  n e w
1204 [p17] images with Janus. Evaluation via clustering and
1205 [p17] identity metrics ensures that the resulting images are
1206 [p17] both anonymized and analytically useful. This pipeline
1207 [p17] adheres to privacy-by-design principles and can be
1208 [p17] fully executed locally to minimize data leakage risks.
1209 [p17] Acknowledgements
1210 [p17] We thank dtec.bw ‚Äì Digitalization and Technology
1211 [p17] Research Center of the Bundeswehr. dtec.bw is funded
1212 [p17] by the European Union ‚Äì NextGenerationEU.
1213 [p17] References
1214 [p17] [1]. H. Hukkel√•s, R. Mester, F. Lindseth, DeepPrivacy: a
1215 [p17] generative adversarial network for face anonymization,
1216 [p17] in Advances in Visual Com puting (G. Bebis, et al.,
1217 [p17] Eds.), Springer, 2019, pp. 565-578.
1218 [p17] [2]. H. Hukkel√•s, F. Lindseth, DeepPrivacy2: towards
1219 [p17] realistic full body anonymization, in Proceedings of the
1220 [p17] IEEE/CVF Winter Conferen ce on Applications of
1221 [p17] Computer Vision (WACV‚Äô23), 2023, pp. 1329-1338.
1222 [p17] [3]. Y. Wen, B. Liu, M. Ding, R. Xie, et al., IdentityDP:
1223 [p17] differential private identification protection for face
1224 [p17] images, Neurocomputing, Vol. 501, 2022, pp. 433-447.
1225 [p17] [4]. M. Maximov, I. Elezi,  L. Leal-Taix√©, CIA-GAN:
1226 [p17] conditional identity anonymization generative
1227 [p17] adversarial networks, in Proceedings of the IEEE/CVF
1228 [p17] Conference on Computer Vision and Pattern
1229 [p17] Recognition (CVPR‚Äô20), 2020, pp. 5446-5455.
1230 [p17] [5]. S. Barattin, C. Tzelepis, I. Patras, N. Sebe, Attribute
1231 [p17] preserving face dataset anon ymization via latent code
1232 [p17] optimization, in Proceedings of the IEEE/CVF
1233 [p17] 2 https://github.com/serengil/deepface
1234 [p18] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1235 [p18] 25-27 November 2025, Innsbruck, Austria
1236 [p18] 17
1237 [p18] Conference on Computer Vision and Pattern
1238 [p18] Recognition (CVPR‚Äô23), 2023, pp. 8316-8326.
1239 [p18] [6]. F. Schroff, D. Kalenichenko, J. Philbin, FaceNet: a
1240 [p18] unified embedding for face recognition and clustering,
1241 [p18] in Proceedings of the IEEE Conference on Computer
1242 [p18] Vision and Pattern Recognition (CVPR‚Äô15) , 2015,
1243 [p18] pp. 815-823.
1244 [p18] [7]. Y. Taigman, M. Yang, M. Ranzato, L. Wolf, DeepFace:
1245 [p18] closing the gap to human-level performance in face
1246 [p18] verification, in Proceedings of the IEEE Conference on
1247 [p18] Computer Vision and Pattern Recognition (CVPR‚Äô14),
1248 [p18] 2014, pp. 1701-1708.
1249 [p18] [8]. S. Serengil, A. Ozpinar, A benchmark of facial
1250 [p18] recognition pipelines and co-usability performances of
1251 [p18] modules, Journal of Information Technologies ,
1252 [p18] Vol. 17, Issue 2, 2024, pp. 95-107.
1253 [p19] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1254 [p19] 25-27 November 2025, Innsbruck, Austria
1255 [p19] 18
1256 [p19] (012)
1257 [p19] A Microservice Based Authentication and Authorization Framework
1258 [p19] for Column Oriented Databases
1259 [p19] Rafael Sebastian Castro Paredes, Andres Andrade-Cabrera and Diana Martinez-Mosquera
1260 [p19] 1 Escuela Polit√©cnica Nacional, Department of Informatics and Computer Science, Quito, Ecuador
1261 [p19] E-mail: {rafael.castro, luis.andrade03, diana.martinez}@epn.edu.ec
1262 [p19] Summary: Modern systems often combine transactional and analytical databases, forming polyglot persistence architectures
1263 [p19] that pose serious challenges for authentication and access cont rol. NoSQL databases, like Apache Cassandra, dominate in
1264 [p19] analytical use cases but lack native security features. A commo n workaround is to rely on separate relational databases for
1265 [p19] authentication, which creates bottlenecks and complexity. This paper presents a microservice-based security framework
1266 [p19] designed specifically for column- oriented NoSQL environments. I t includes dedicated microservices for user registration,
1267 [p19] secure credential validation using Bcrypt, and issuing JSON Web Tokens (JWT) for authentication. Authorization is enforced
1268 [p19] via a separate service implementing fine-grained, role-based access control (RBAC). The system is implemented using NestJS
1269 [p19] (backend), React (frontend), and Cassandra as the unified datas tore for users and permissions. All components are
1270 [p19] containerized with Docker for scalability and deployment ease. Experimental results show that the framework improves
1271 [p19] security separation, enhances flexibility, and facilitates secure adoption of NoSQL in distributed systems.
1272 [p19] Keywords: Access control, Authentication, Cassandra, Microservices, NoSQL, Security framework.
1273 [p19] 1. Introduction
1274 [p19] In the era of rapid data growth, organizations are
1275 [p19] moving away from relying on a single database
1276 [p19] solution, embracing polyglot persistence environments
1277 [p19] instead [1]. This approach leverages different types of
1278 [p19] databases such as SQL, NoSQL, and NewSQL [10] to
1279 [p19] meet the specific requirements of various components
1280 [p19] within a company. Among NoSQL options,
1281 [p19] column-oriented databases are widely adopted due to
1282 [p19] their high availability and excellent scalability, making
1283 [p19] them ideal for processing large volumes of data [1].
1284 [p19] However, column-oriented databases were not
1285 [p19] designed with built-in authentication and authorization
1286 [p19] mechanisms [11, 12], which poses challenges for
1287 [p19] developers and database administrators. Centralized
1288 [p19] security models are poorly suited to the distributed
1289 [p19] nature of modern applications. This research addresses
1290 [p19] the design of a flexible and secure authentication and
1291 [p19] authorization system tailored for column-oriented
1292 [p19] databases. The proposed system must reliably verify
1293 [p19] user identities and enforce fine-grained access control,
1294 [p19] ensuring that users can only perform actions they are
1295 [p19] explicitly authorized to execute.
1296 [p19] This paper contributes a few key things. First, we
1297 [p19] propose a decoupled security architecture made of
1298 [p19] specialized microservices for authentication and
1299 [p19] permissions. This proposal improves how modular and
1300 [p19] scalable the system is. Second, this study details a
1301 [p19] secure authentication process using
1302 [p19] JSON Web Tokens
1303 [p19] (JWT) [13] for session management and Bcrypt [14]
1304 [p19] for password hashing. Third, we present a dynamic
1305 [p19] model for access control based on roles. This approach
1306 [p19] lets administrators manage user permissions for
1307 [p19] database operations in real time.
1308 [p19] The rest of this paper is structured to explain our
1309 [p19] work. Section 2 looks at the related research. Section 3
1310 [p19] describes the system‚Äôs architecture. Section 4 explains
1311 [p19] the implementation details of the proposal. Section 5
1312 [p19] shows the evaluation results. Finally, Section 6
1313 [p19] concludes the paper with thoughts on future work.
1314 [p19] 2. Related Work
1315 [p19] Security is very important in distributed systems.
1316 [p19] Actually, the microservices architectural pattern [2, 3]
1317 [p19] is a standard way to build scalable applications. The
1318 [p19] main idea of this pattern is breaking up responsibilities,
1319 [p19] which includes security. Building authentication and
1320 [p19] authorization as a dedicated microservice is a
1321 [p19] best-established practice. This approach prevents
1322 [p19] concentrating all security  responsibilities within a
1323 [p19] single Application Programming Interface (API)
1324 [p19] gateway, while enabling security logic to be
1325 [p19] developed, maintained, and scaled independently.
1326 [p19] Securing column-oriented databases requires a
1327 [p19] combination of traditional access control, privilege
1328 [p19] management, and innovative techniques like shuffling
1329 [p19] and encryption. As data models become more
1330 [p19] complex, authorization frameworks must evolve to
1331 [p19] ensure both security and usability without
1332 [p19] compromising performance [4].
1333 [p19] Unlike other works [5-9], which introduces a
1334 [p19] theoretical authorization model for object-oriented and
1335 [p19] semantic databases with a focus on implicit
1336 [p19] authorization, our proposal addresses the practical
1337 [p19] challenges of securing polyglot persistence
1338 [p19] environment, specifically column-oriented NoSQL
1339 [p19] databases. While their approach extends traditional
1340 [p19] models conceptually within single-system
1341 [p19] architectures [5-9], our framework provides a modular,
1342 [p19] microservice-based solution for both authentication
1343 [p19] and fine-grained authorization, using modern tools
1344 [p19] such as JWT, Bcrypt, and Docker [15]. This makes our
1345 [p19] system suitable for real-world, distributed applications
1346 [p20] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1347 [p20] 25-27 November 2025, Innsbruck, Austria
1348 [p20] 19
1349 [p20] that require scalable and flexible access control
1350 [p20] mechanisms.
1351 [p20] 3. Methodology
1352 [p20] The proposed architecture is based on a
1353 [p20] microservice-based security  layer and introduces a
1354 [p20] modular framework designed specifically for a
1355 [p20] well-known column-oriented NoSQL database, such
1356 [p20] as Apache Cassandra [16].  This solution aimed at
1357 [p20] managing authentication, authorization, and query
1358 [p20] mediation.
1359 [p20] Fig. 1 depicts the overall structure of the system,
1360 [p20] including the main components and how they are
1361 [p20] connected. The architecture includes a frontend client
1362 [p20] built with React, three backend microservices built
1363 [p20] with NestJS: (1) Translation Microservice,
1364 [p20] (2) Authentication Microser vice, and (3) Permissions
1365 [p20] Microservice; and a Cassandra database cluster
1366 [p20] running in Docker.
1367 [p20] Fig. 1. Microservice Security Architecture for Cassandra.
1368 [p20] The Translation Microservice is the main engine
1369 [p20] that translates SQL quer ies to Cassandra Query
1370 [p20] Language (CQL) and runs them after checking
1371 [p20] permissions. Authentication Microservice is the main
1372 [p20] gatekeeper that handles user registration, login, and
1373 [p20] password management. The Permissions Microservice
1374 [p20] manages all authorization rules and defines what
1375 [p20] actions a user can take.
1376 [p20] The frontend is a single page application, which
1377 [p20] provides the user interface  for login, registration,
1378 [p20] queries, and admin tasks. Cassandra fulfills two roles:
1379 [p20] (1) it serves as the target database for user queries, and
1380 [p20] (2) it stores the application's internal data, such as user
1381 [p20] credentials, roles, and permission within a special auth
1382 [p20] keyspace.
1383 [p20] 3.1. Backend Microservices
1384 [p20] 3.1.1. Translation Microservice
1385 [p20] We have incorporated a module of Translation that
1386 [p20] enables seamless interaction between applications
1387 [p20] using SQL and the Cassandra database. Its primary
1388 [p20] role is to translate incoming SQL queries into their
1389 [p20] equivalent Cassandra Query Language (CQL)
1390 [p20] statements. This approach provides two
1391 [p20] major benefits:
1392 [p20] 1. Compatibility: Applications or users accustomed
1393 [p20] to SQL can interact with Cassandra without
1394 [p20] needing to learn CQL syntax directly;
1395 [p20] 2. Abstraction: Developers can focus on business
1396 [p20] logic rather than query translation details,
1397 [p20] improving productivity and reducing errors.
1398 [p20] 3.1.2. Authentication Microservice
1399 [p20] This service confirms a user‚Äôs identity. Its main
1400 [p20] functions are user registration, login, password
1401 [p20] recovery, and other security mechanisms. User
1402 [p20] registration creates new accounts. It hashes passwords
1403 [p20] with Bcrypt to avoid storing them in plain text. When
1404 [p20] a user registers, the system generates a unique PIN for
1405 [p20] password recovery.
1406 [p20] Login validates user credentials, if they are correct,
1407 [p20] it generates a signed JWT with the user‚Äôs ID and role,
1408 [p20] like USER or ADMIN. Password recovery gives users
1409 [p20] a secure way to reset their password. Users can use
1410 [p20] their original PIN or a temporary one from an
1411 [p20] administrator. Security measures include rate limiting,
1412 [p20] which mitigates brute-force attacks by temporarily
1413 [p20] blocking login attempts after a predefined number
1414 [p20] of failures.
1415 [p20] 3.1.3. Permissions Microservice and Role-based
1416 [p20] Access Control Model
1417 [p20] The Permissions Microservice handles
1418 [p20] authorization and uses a model for access control
1419 [p20] named Role-Based Access Control (RBAC). This
1420 [p20] model defines two main roles:
1421 [p20] 1. User: A regular account with permission to run
1422 [p20] defined CQL queries on authorized Cassandra
1423 [p20] keyspaces;
1424 [p20] 2. Admin: A privileged account with full access to
1425 [p20] all translation functions and can manage
1426 [p20] the system.
1427 [p20] Admin tasks include managing user roles,
1428 [p20] assigning access to keyspace s, granting permissions
1429 [p20] for specific operations, generating temporary PINs,
1430 [p20] and deleting users or keyspaces. Permission data is
1431 [p20] stored directly in Cassandra, enabling dynamic and
1432 [p20] persistent control over user actions.
1433 [p20] 3.2. Authentication and Authorization Flow
1434 [p20] A user first logs in through the frontend by sending
1435 [p20] their credentials to Authentication Microservice. The
1436 [p20] service checks the credentials and, if they are correct,
1437 [p20] sends back a JWT. The frontend saves this JWT and
1438 [p20] adds it to the header of all future requests. When the
1439 [p20] user tries to run a query, a JwtAuthGuard checks the
1440 [p20] JWT‚Äôs signature and expiration date.
1441 [p20] Before running the query, the Translation
1442 [p20] Microservice asks the Permissions Microservice if the
1443 [p21] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1444 [p21] 25-27 November 2025, Innsbruck, Austria
1445 [p21] 20
1446 [p21] user is allowed to perform that action on that keyspace.
1447 [p21] The Permissions Microservice checks its database and
1448 [p21] responds with approval or denial. The Translation
1449 [p21] Microservice will only proceed if it gets approval.
1450 [p21] Fig. 2 illustrates the step-by-step process of how a
1451 [p21] user is authenticated and authorized to perform actions
1452 [p21] within the system.
1453 [p21] Fig. 2. Authentication and Authorization Flow.
1454 [p21] 3.3. Implementation
1455 [p21] Fig. 3 depicts the implementation of the backend
1456 [p21] and frontend. The backend was built with NestJS. This
1457 [p21] is a Node.js framework for building scalable
1458 [p21] server-side applications. Its modular design was a good
1459 [p21] fit for our microservice appr oach. It is containerized
1460 [p21] with Docker for simple deployment and consistency.
1461 [p21] The complete source code and deployment instructions
1462 [p21] are publicly available on GitHub to facilitate
1463 [p21] reproducibility [17].
1464 [p21] Fig. 3. Implementation of the Architecture
1465 [p21] for Authentication and Authorization.
1466 [p21] The frontend was built with React and Vite, this
1467 [p21] one created a fast and responsive user interface. For
1468 [p21] security, we used the jsonwebtoken library to create
1469 [p21] and check JWTs. We used Bcrypt for one way hashing
1470 [p21] of passwords. We also used @nestjs/passport and
1471 [p21] passportjwt to integrate JWT validation into the
1472 [p21] application‚Äôs request process using custom Guards.
1473 [p21] The Authentication Microservice provides REST
1474 [p21] endpoints for login, registration, and password
1475 [p21] changes. The Permissions Microservice provides
1476 [p21] admin endpoints for updating user permissions and
1477 [p21] keyspaces. All sensitive endpo ints are protected by a
1478 [p21] JwtAuthGuard that checks the token and a RolesGuard
1479 [p21] that checks if the user has the required role to access
1480 [p21] the resource. The services communicate with each
1481 [p21] other using standard HTTP requests.
1482 [p21] 3.4. Performance Evaluation
1483 [p21] To validate the scalability and robustness of the
1484 [p21] proposed framework, a series of performance tests
1485 [p21] were conducted. These tests move beyond the initial
1486 [p21] functional validation to provide empirical benchmarks
1487 [p21] for latency, throughput, and system resilience under
1488 [p21] significant load, addressing the future work outlined in
1489 [p21] our initial draft.
1490 [p21] The evaluation was performed across two distinct
1491 [p21] environments to isolate and accurately measure the
1492 [p21] performance of the microservice architecture:
1493 [p21] 1. Environment A (Local Development): Initial
1494 [p21] baseline tests were conducted on a developer
1495 [p21] laptop equipped with a multi-core processor
1496 [p21] and 16GB of RAM. This environment was used
1497 [p21] for iterative functional testing and to establish a
1498 [p21] preliminary performance baseline under light
1499 [p21] load (1-10 concurrent users);
1500 [p21] 2. Environment B (Dedicated Server): The formal
1501 [p21] scalability and stress tests were executed on a
1502 [p21] dedicated Linux server featuring a 64-core
1503 [p21] processor and 32GB of RAM. This powerful
1504 [p21] environment ensured that test results reflect the
1505 [p21] true performance of the application
1506 [p21] architecture, free from potential bottlenecks of
1507 [p21] a local machine.
1508 [p21] Furthermore, we utilized the open-source tool k6 to
1509 [p21] simulate concurrent user traffic and measure key
1510 [p21] performance indicators. Two primary scenarios
1511 [p21] were designed:
1512 [p21] 1. Scalability Test: This test measured the
1513 [p21] system's ability to handle a linearly increasing
1514 [p21] load. The number of virtual users (VUs) was
1515 [p21] r a m p e d  u p  i n  s t a g e s  f r o m  1  t o  2 0 0  o v e r  a
1516 [p21] 16-minute period. The primary metrics were
1517 [p21] requesting throughput (requests/second),
1518 [p21] P95 latency, and the error rate;
1519 [p21] 2. Stress Test: This test was designed to determine
1520 [p21] the system's stability and breaking point under
1521 [p21] extreme load. The number of VUs was
1522 [p21] aggressively ramped up to 500 over an
1523 [p21] 11-minute period to saturate the services and
1524 [p21] observe their behavior under maximum stress.
1525 [p21] 4. Results and Discussion
1526 [p21] The system was tested with a series of functional
1527 [p21] tests. These tests covered all important security and
1528 [p22] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1529 [p22] 25-27 November 2025, Innsbruck, Austria
1530 [p22] 21
1531 [p22] administrative workflows. The results confirmed that
1532 [p22] the framework was implemented correctly.
1533 [p22] The authentication tests showed that the login
1534 [p22] interface successfully logged in users with valid
1535 [p22] credentials and blocked invalid ones. The user
1536 [p22] registration process correctly created new users and
1537 [p22] gave them a unique PIN for recovery.
1538 [p22] The authorization tests showed that the admin
1539 [p22] panel for permissions allowed an admin to enable or
1540 [p22] disable specific SQL operations for a user. The
1541 [p22] backend logs confirmed these changes were saved to
1542 [p22] the database and sent to the translation service to
1543 [p22] update its cache.
1544 [p22] The role management te sts showed the system
1545 [p22] correctly handled promoting a user to an admin. The
1546 [p22] backend log showed the successful role update. After
1547 [p22] the promotion, the user could access the administrative
1548 [p22] dashboard.
1549 [p22] The password recovery tests were also successful.
1550 [p22] Both the initial PIN and a temporary admin generated
1551 [p22] PIN worked to reset passwo rds through the interface.
1552 [p22] These results show that architecture based on
1553 [p22] microservices provides a solid and functional security
1554 [p22] layer for the Cassandra database.
1555 [p22] Furthermore, the system's performance remained
1556 [p22] stable, and all queries were executed successfully
1557 [p22] without errors or noticeable delays.
1558 [p22] 4.1. Graphical User Interface
1559 [p22] Fig. 4 depicts a login interface for Cassandra
1560 [p22] NoSQL database. On the left side of the image is the
1561 [p22] login form, which includes fields for Username,
1562 [p22] ID/Code, and Password, along with options to Register
1563 [p22] or Recover a forgotten password. CASSQL is a
1564 [p22] platform that allows users to authenticate and interact
1565 [p22] with Cassandra using SQL-like inputs, offering a
1566 [p22] user-friendly interface for data access and translation.
1567 [p22] Fig. 4. Authentication GUI.
1568 [p22] At the top, there are input fields to search users by
1569 [p22] ID, and assign or view their Name, ID/Code, and
1570 [p22] Role. Below, a grid of permissions is displayed,
1571 [p22] allowing fine-grained control over actions like:
1572 [p22] ÔÇ∑ Schema-level operations : Create Table, Drop
1573 [p22] Table, Alter Table (Add, Drop, Rename), Create
1574 [p22] Keyspace, Drop Keyspace;
1575 [p22] ÔÇ∑ Data-level operations : Select, Insert, Update,
1576 [p22] Delete, Truncate;
1577 [p22] ÔÇ∑ Metadata operations : Describe Table(s),
1578 [p22] Create/Drop Index, Alter Keyspace.
1579 [p22] Fig. 5 shows the "Permissions Configuration"
1580 [p22] interface of the CASSQL platform. This module
1581 [p22] allows an administrator to manage user access rights
1582 [p22] for operations in a Cassandra-based environment. At
1583 [p22] the top, there are input fields to search users by ID, and
1584 [p22] assign or view their Name, ID/Code, and Role. Below,
1585 [p22] a grid of permissions is displayed, allowing
1586 [p22] fine-grained control over actions like:
1587 [p22] 1. Schema-level operations: Create Table, Drop
1588 [p22] Table, Alter Table (Add, Drop, Rename),
1589 [p22] Create Keyspace, Drop Keyspace;
1590 [p22] 2. Data-level operations: Select, Insert, Update,
1591 [p22] Delete, Truncate;
1592 [p22] 3. Metadata operations: Describe Table(s),
1593 [p22] Create/Drop Index, Alter Keyspace;
1594 [p22] 4. Access control: Use (general access).
1595 [p22] Fig. 5. Authorization GUI.
1596 [p22] Each permission can be toggled on or off using a
1597 [p22] switch. Once the desired permissions are configured,
1598 [p22] the ‚ÄúSave‚Äù button at the bottom right applies
1599 [p22] the changes.
1600 [p22] The left sidebar includes navigation options such as
1601 [p22] Translator, Generate PIN, Delete User, Assign
1602 [p22] Databases, and Configure Permissions, making it a
1603 [p22] full-featured role and access management interface for
1604 [p22] Cassandra.
1605 [p22] 4.2. Performance
1606 [p22] The results from the performance evaluation were
1607 [p22] exceptionally positive, demonstrating that the
1608 [p22] microservice architecture is both highly scalable
1609 [p22] and resilient.
1610 [p22] 4.2.1. Scalability
1611 [p22] Under the scaling load of 200 concurrent users, the
1612 [p22] system stabilized at a high throughput of
1613 [p22] 141.6 requests per second. The 95
1614 [p22] th percentile (p95)
1615 [p22] latency for database operations remained low, with
1616 [p23] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1617 [p23] 25-27 November 2025, Innsbruck, Austria
1618 [p23] 22
1619 [p23] INSERT operations at 335 ms and SELECT operations
1620 [p23] at 369 ms. Critically, the system maintained a 0.00 %
1621 [p23] error rate throughout the entire test.
1622 [p23] As shown in Fig. 6, the P95 latency for both
1623 [p23] INSERT and SELECT operations increases linearly
1624 [p23] and predictably as the number of concurrent users
1625 [p23] scales to 200. This controlled rise in latency, coupled
1626 [p23] with the 0 % error rate, is indicative of a healthy and
1627 [p23] scalable system that gracefully handles increasing
1628 [p23] demand without becoming unstable.
1629 [p23] Fig. 6. P95 Latency during Scalability Test.
1630 [p23] 4.2.2. Stress Resilience
1631 [p23] During the stress test with 500 concurrent users, the
1632 [p23] system demonstrated remarkable stability. It processed
1633 [p23] a peak throughput of 338.2 requests per second. While
1634 [p23] p95 latency increased to approximately 778 ms under
1635 [p23] this extreme load, the system never failed. The error
1636 [p23] rate remained at 0.00 %, proving that the architecture
1637 [p23] is resilient and does not buckle under pressure that far
1638 [p23] exceeds typical operational loads.
1639 [p23] Fig. 7 provides a clear comparison of the average
1640 [p23] and 95
1641 [p23] th percentile latency during the peak of the stress
1642 [p23] test. While the P95 latency is notably higher than the
1643 [p23] average, as expected under  heavy load, both metrics
1644 [p23] remain within reasonable bounds for a system under
1645 [p23] such extreme conditions. This reinforces the finding
1646 [p23] that the system is resilient and does not exhibit
1647 [p23] uncontrolled latency spikes, even when pushed far
1648 [p23] beyond its expected operational capacity.
1649 [p23] Fig. 7. Latency Comparison under Peak Stress Test.
1650 [p23] These empirical results validate that the chosen
1651 [p23] microservice-based design, which decouples
1652 [p23] authentication, permissions, and translation, does not
1653 [p23] introduce performance bottlenecks. Instead, it provides
1654 [p23] a robust foundation capable of serving high-traffic,
1655 [p23] production-level environments.
1656 [p23] 5. Conclusions
1657 [p23] This paper presented a comprehensive
1658 [p23] authentication and authorization framework tailored
1659 [p23] for column-oriented databases such as Cassandra. By
1660 [p23] leveraging microservices architecture, security
1661 [p23] concerns are clearly separated from core database
1662 [p23] operations. This separation enables the system to be
1663 [p23] highly scalable, maintainable, and resilient, while
1664 [p23] reducing complexity in both development and
1665 [p23] deployment.
1666 [p23] The adoption of modern security standards,
1667 [p23] including JWT for secure session management and
1668 [p23] Bcrypt for one-way password hashing, ensures robust
1669 [p23] protection against common attack vectors.
1670 [p23] Furthermore, the integration of RBAC model
1671 [p23] introduces flexible and fine-grained control over data
1672 [p23] access, strengthening both user-level and resource-
1673 [p23] level security.
1674 [p23] The successful design, implementation, and testing
1675 [p23] of this framework demonstrate its viability as a reliable
1676 [p23] solution for securing complex NoSQL database
1677 [p23] systems. By lowering the security barrier, it also makes
1678 [p23] powerful distributed technologies such as Cassandra
1679 [p23] more accessible to developers, encouraging safer
1680 [p23] adoption in enterprise and research environments.
1681 [p23] Performance evaluation confirms the robustness of
1682 [p23] the proposed system. It maintained high throughput,
1683 [p23] l o w  l a t e n c y ,  a n d  a  0  %  e r r o r  r a t e  u n d e r  n o r m a l  a n d
1684 [p23] stress conditions. Even with 500 concurrent users, the
1685 [p23] system remained stable and resilient, showing
1686 [p23] predictable performance without failures or
1687 [p23] uncontrolled spikes.
1688 [p23] Looking forward, several future enhancements
1689 [p23] could strengthen and extend this framework. First,
1690 [p23] incorporating multi-factor authentication (MFA)
1691 [p23] would significantly enhance login security by adding
1692 [p23] an additional verification layer. Second, integrating
1693 [p23] support for widely used identity and federation
1694 [p23] protocols, such as OAuth 2.0 and OpenID Connect,
1695 [p23] would enable seamless authentication with trusted
1696 [p23] third-party providers. Finally, conducting a more
1697 [p23] in-depth security threat ana lysis, covering scenarios
1698 [p23] such as token hijacking, replay attacks, or privilege
1699 [p23] escalation, would allow further refinement of the
1700 [p23] framework and proactive mitigation of emerging
1701 [p23] threats.
1702 [p23] References
1703 [p23] [1]. J. Carpenter, E. Hewitt, Cassandra: The Definitive
1704 [p23] Guide, 2nd Ed., O‚ÄôReilly Media, 2016.
1705 [p23] [2]. IBM, Microservices, h ttps://www.ibm.com/es-es/
1706 [p23] topics/microservices
1707 [p24] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1708 [p24] 25-27 November 2025, Innsbruck, Austria
1709 [p24] 23
1710 [p24] [3]. E. Wolff, Microservices : Architecture and Design,
1711 [p24] Addison-Wesley, 2016.
1712 [p24] [4]. T. Geng, C. -T. Huang, C. Farkas, SCORD: shuffling
1713 [p24] column-oriented relational database to enhance
1714 [p24] security, in Proceedings of Ubiquitous Security
1715 [p24] (UbiSec‚Äô23), 2023, pp. 163-176.
1716 [p24] [5]. F. Rabitti, E. Bertino, W. Kim, D. Woelk, A model of
1717 [p24] authorization for next-generation database systems,
1718 [p24] ACM Transactions on Database Systems , Vol. 16,
1719 [p24] Issue 1, 1991, pp. 88-131.
1720 [p24] [6]. A. Mohamed, D. Auer, D. Hofer, J. K√ºng, A systematic
1721 [p24] literature review of authorization and access control
1722 [p24] requirements and current state of the art for different
1723 [p24] database models, International Journal of Web
1724 [p24] Information Systems, Vol. 20, 2024, pp. 1-23.
1725 [p24] [7]. S. Chaudhuri, T. Dutta, S. Sudarshan, Fine grained
1726 [p24] authorization through predicated grants, in Proceedings
1727 [p24] of the IEEE 23 rd International Conference on Data
1728 [p24] Engineering, 2007, pp. 1174-1183.
1729 [p24] [8]. G. Deep, R. Mohana, A. Nayyar, S. Padmanaban, et al.,
1730 [p24] Authentication protocol f or cloud databases using
1731 [p24] blockchain mechanism, Sensors, Vol. 19, 2019, 4444.
1732 [p24] [9]. M. Jiang, S. Liu, S. Ha n, D. Gu, Biometric-based
1733 [p24] two-factor authentication scheme under database
1734 [p24] leakage, Theoretical Computer Science , Vol. 1000,
1735 [p24] 2024, 114552.
1736 [p24] [10]. T. Khasawneh, M. Al-Sahlee, A. Safia, SQL, NewSQL,
1737 [p24] and NoSQL databases: a comparative survey, in
1738 [p24] Proceedings of the 11 th International Conference on
1739 [p24] Information and Communication Systems (ICICS‚Äô20) ,
1740 [p24] 2020, pp. 13-21.
1741 [p24] [11]. D. Abadi, P. Boncz, S. Harizopoulos, Column oriented
1742 [p24] database systems, Proceedings of the VLDB
1743 [p24] Endowment, Vol. 2, Issue 2, 2009, pp. 1664-1665.
1744 [p24] [12]. I. Solsol, H. Vargas, G. D√≠az, Security mechanisms in
1745 [p24] NoSQL DBMS‚Äôs: a technical review, in Advances in
1746 [p24] Intelligent Systems and Computing, Vol. 1362,
1747 [p24] Springer, 2021, pp. 215-228.
1748 [p24] [13]. M. Jones, J. Bradley, N . Sakimura, JSON web token
1749 [p24] (JWT), RFC 7519, IETF, 2015, pp. 1-30.
1750 [p24] [14]. C. Skanda, B. Srivatsa, B. Premananda, Secure hashing
1751 [p24] using BCrypt for cryptographic applications, in
1752 [p24] Proceedings of the IEEE North Karnataka Subsection
1753 [p24] Flagship International Conference (NKCon‚Äô22), 2022,
1754 [p24] pp. 1-5.
1755 [p24] [15]. M. Yasir, A review on introduction to Docker and its
1756 [p24] features, International Journal of Advanced Research
1757 [p24] in Computer Science and Software Engineering, Vol. 8,
1758 [p24] Issue 6, 2018, pp. 104-108.
1759 [p24] [16]. H. Tu, Cassandra vs. MongoDB: a systematic review of
1760 [p24] two NoSQL data stores in their industry uses, in
1761 [p24] Proceedings of the IEEE 7 th International Conference
1762 [p24] on Big Data and Artificial Intelligence (BDAI‚Äô24) ,
1763 [p24] 2024, pp. 81-86.
1764 [p24] [17]. R. Castro, Middlewar e-NoSQL/SQL-to-CQL, GitHub
1765 [p24] Repository, https://github.com/Middleware-NoSQL/
1766 [p24] SQL-to-CQL
1767 [p25] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1768 [p25] 25-27 November 2025, Innsbruck, Austria
1769 [p25] 24
1770 [p25] (013)
1771 [p25] Developing Synthetic Data or Cybersecurity Policies
1772 [p25] G. Giacomello and O. Preka
1773 [p25] Center for Computational Social Science, DSPS, University of Bologna, Strada Maggiore 45, Bologna, Italy
1774 [p25] Email: giampiero.giacomello@unibo.it
1775 [p25] Summary: Data scarcity ‚Äì driven by under-detection and under-reporting of incidents, legal and competitive disincentives to
1776 [p25] share, and vendors‚Äô reluctance to expose product weaknesses ‚Äì impedes the development of data-driven cybersecurity policies.
1777 [p25] We investigate large language mode l (LLM)‚Äìbased synthetic tabul ar data generation as a pragmatic remedy. Our approach
1778 [p25] follows a GReaT-style pipeline: (i) text-based serialization of  heterogeneous tables to preserve schema semantics; and
1779 [p25] (ii) fine-tuning a pretrained decoder LLM (Unsloth/Llama-3.2-1B) on 3388 publicly reported cyber-attack records. Preliminary
1780 [p25] results that LLM-generated synthetic data can approximate the statistical and structural properties of scarce cybersecurity data
1781 [p25] without exposing sensitive information, thereby enabling data a ugmentation and supporting the design of data-driven
1782 [p25] cyber policies.
1783 [p25] Keywords: Synthetic data, Cybersecurity, Tabular data generation.
1784 [p25] 1. Research Problem
1785 [p25] The development of data- driven cybersecurity
1786 [p25] policies and defensive mechanisms is critically
1787 [p25] hampered by a persistent, multifaceted challenge: data
1788 [p25] scarcity. In an era where threats are increasingly
1789 [p25] sophisticated, the reliance on comprehensive datasets
1790 [p25] for training intrusion det ection systems, analysing
1791 [p25] malware behaviour, and modelling threat landscapes
1792 [p25] has never been greater. However, data availability is
1793 [p25] extremely scarce for several reasons. Key factors
1794 [p25] include the small fraction of cyber-attacks being
1795 [p25] detected and even less reported. Existing datasets
1796 [p25] suffer from incompleteness and inconsistency, thus
1797 [p25] raising significant concerns regarding their reliability
1798 [p25] and validity.
1799 [p25] This data scarcity is not accidental but systemic,
1800 [p25] stemming from several factors. First, the very nature of
1801 [p25] cyber-attacks involves malicious actors who actively
1802 [p25] conceal their identity and methods, making data
1803 [p25] collection inherently difficult. Second, organizations
1804 [p25] are reluctant to share incident data due to legitimate
1805 [p25] fears of exposing unpatched vulnerabilities, incurring
1806 [p25] substantial reputational damage, and creating
1807 [p25] competitive disadvantages. This hesitation is further
1808 [p25] compounded by a complex web of legal and regulatory
1809 [p25] implications surrounding data privacy and breach
1810 [p25] notifications. Finally, technology vendors and
1811 [p25] software companies are often constrained by market
1812 [p25] pressures, making them hesitant to reveal product
1813 [p25] weaknesses that could be inferred from detailed attack
1814 [p25] data. These constraints create a critical bottleneck that
1815 [p25] impedes the research and development of data-driven
1816 [p25] cybersecurity solutions.
1817 [p25] 2. Methodological Approach: Synthetic Data
1818 [p25] Generation with LLMs
1819 [p25] To address these significant challenges, we explore
1820 [p25] the potential of synthetic data generation, specifically
1821 [p25] through the application of Large Language Models
1822 [p25] (LLMs) as a novel solution. Synthetic data, defined as
1823 [p25] algorithmically generated i nformation that resembles
1824 [p25] the statistical properties and structural characteristics
1825 [p25] of a source dataset, offer s a powerful paradigm for
1826 [p25] overcoming data access barriers. Its utility has been
1827 [p25] demonstrated in various domains for tasks such as data
1828 [p25] anonymization to protect privacy in sensitive sectors
1829 [p25] like healthcare, data augmen tation to enrich sparse
1830 [p25] datasets, and bias mitigation in machine
1831 [p25] learning models.
1832 [p25] LLMs, trained on vast quantities of text, code, and
1833 [p25] other data types, have shown advanced generative
1834 [p25] capabilities and versatile problem-solving skills that
1835 [p25] extend well beyond traditional Natural Language
1836 [p25] Processing
1837 [p25] [1]. Their abilities such as in-context
1838 [p25] learning and instruction following can be leveraged via
1839 [p25] sophisticated prompt engineering techniques
1840 [p25] [2]. This
1841 [p25] has opened up opportunities for new applications of
1842 [p25] LLMs, including the generation of tabular data. While
1843 [p25] the application of LLMs to generate structured tabular
1844 [p25] data is a nascent field, recent advancements have
1845 [p25] shown promising results in areas such as imputing
1846 [p25] missing values
1847 [p25] [3], augmenting sparse data [4], and
1848 [p25] rebalancing imbalanced classes [5], laying the
1849 [p25] foundational for our investigation into synthetic data
1850 [p25] generation
1851 [p25] [6].
1852 [p25] 3. Methodology and Experimental Design
1853 [p25] Our methodology leverages state-of-the-art
1854 [p25] LLM-based frameworks for tabular data generation.
1855 [p25] Recognising the inherent challenges of tabular data ‚Äì
1856 [p25] which includes heterogeneous feature types (e.g.,
1857 [p25] categorical, numerical), class imbalance across
1858 [p25] categories
1859 [p25] [5], and complex context-based
1860 [p25] interconnections [7] ‚Äì we begin with a key
1861 [p25] preprocessing step: text-based serialization. This
1862 [p25] process converts structured tabular data into a linear
1863 [p25] textual representation that can be processed by an
1864 [p26] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1865 [p26] 25-27 November 2025, Innsbruck, Austria
1866 [p26] 25
1867 [p26] LLM, translating the table's schema and values into a
1868 [p26] coherent sequence while preserving semantic
1869 [p26] knowledge from column names [8].
1870 [p26] We then use prompt engineering to steer the
1871 [p26] generative process. This includes clear task
1872 [p26] instructions, utilizing in-context learning with
1873 [p26] few-shot examples for format and schema adherence,
1874 [p26] and step-by-step reasoning with Chain-of-Thought
1875 [p26] (CoT) prompts
1876 [p26] [9] where appropriate.
1877 [p26] Current state-of-the-art m ethods for tabular data
1878 [p26] generation with large language models generally
1879 [p26] follow the same approach, though with some
1880 [p26] variations. GReaT
1881 [p26] [10] fine-runes a pretrained GPT-2
1882 [p26] model on the original data, and employs random
1883 [p26] permutations of feature order to reduce dependence on
1884 [p26] column sequences. For more complex
1885 [p26] scenarios, ReaLTabFormer
1886 [p26] [11] is noted for its
1887 [p26] enhanced performance on relational databases. Other
1888 [p26] prominent methods include TAPTAP [12], which
1889 [p26] pretrains GPT-2 on a vast collection of public tables to
1890 [p26] build foundational knowledge, and Tabula
1891 [p26] [13], which
1892 [p26] accelerates training by starting from a randomly
1893 [p26] initialized model.
1894 [p26] Our experimental work focuses on the
1895 [p26] implementation of the GReaT approach, due to its
1896 [p26] advantages compared to other modes consisting
1897 [p26] mainly in a straightforward implementation without
1898 [p26] significant data processing. We apply the Great
1899 [p26] method on a collection of several publicly available
1900 [p26] reported cyber attacks, with the final dataset containing
1901 [p26] 3388 cases. We focus parti cularly on the technical
1902 [p26] characteristic (i.e., source name, target ID and target
1903 [p26] name), and free-text descriptions.
1904 [p26] After an 80/20 train-test split, Unloth/Llama-3.2-
1905 [p26] 1B, a pretrained transformers-decoder LLM
1906 [p26] [14] i s
1907 [p26] fine-tuned on the train data set.
1908 [p26] The evaluation of this method focuses both on
1909 [p26] fidelity and privacy of synthetic data: how close
1910 [p26] generated data is compared to unseen record from the
1911 [p26] original dataset, still without memorizing them as a
1912 [p26] result of overfitting. The most appropriate measure for
1913 [p26] this purpose is the Distance to Closest Record (DCR)
1914 [p26] measure
1915 [p26] [15]. For each data point, it calculates the
1916 [p26] distance to its nearest neighbor. Fig. 1 displays the
1917 [p26] distribution of minimal distances between data sets,
1918 [p26] showing that the generated data are close to the test
1919 [p26] data set, yet not exactly the same.
1920 [p26] Fig. 1.  DCR distributions computed with standardized
1921 [p26] numerical features and L2-normalized LM embeddings,
1922 [p26] using Euclidean (cosine-equivalent) distance. ‚ÄúTrain vs
1923 [p26] Test‚Äù shows the DCR distance between training and test data
1924 [p26] set, while ‚ÄúSyntheti c vs Test‚Äù shows the distance between
1925 [p26] synthetic data and test data. The synthetic distribution is
1926 [p26] slightly right-shifted (larg er DCRs), indicating fewer
1927 [p26] near-duplicates of test data while maintaining comparable
1928 [p26] realism through overlapping ranges.
1929 [p26] 4. Conclusion
1930 [p26] We demonstrate the feasibility of generating
1931 [p26] synthetic tabular data in the cybersecurity domain with
1932 [p26] an LLM-based approach adapted from GReaT and
1933 [p26] fine-tuned on a categorical -heavy corpus of nearly
1934 [p26] 3400 incidents.
1935 [p26] Preliminary empirical results show that this method
1936 [p26] can approximate key statistical and structural
1937 [p26] properties of scarce cybersecurity datasets. This
1938 [p26] suggests that synthetic data may help mitigate data
1939 [p26] scarcity, and thereby be a v alid support for research
1940 [p26] focusing on the development of data-driven policies in
1941 [p26] the cybersecurity sector. Moreover, building on these
1942 [p26] promising results, future research can go a step further
1943 [p26] by leveraging the contextual knowledge of LLMs
1944 [p26] specialised for cyber-security applications, such as
1945 [p26] Foundation-Sec-8B.
1946 [p26] References
1947 [p26] [1]. T. Khot, H. Trivedi, et a l., Decomposed prompting: a
1948 [p26] modular approach for solving complex tasks, arXiv
1949 [p26] preprint, 2022, arXiv:2210.02406.
1950 [p26] [2]. P. Liu, W. Yuan, et al., Pre-train, prompt, and predict:
1951 [p26] a systematic survey of pro mpting methods in natural
1952 [p26] language processing, arXiv preprint , 2021,
1953 [p26] arXiv:2107.13586.
1954 [p26] [3]. A. Jolicoeur-Martineau, et al., Generating and imputing
1955 [p26] tabular data via diffusion and flow-based gradient-
1956 [p26] boosted trees, in Proceedings of the 27 th International
1957 [p26] Conference on Artificial Intelligence and Statistics
1958 [p26] (AISTATS‚Äô24), 2024, pp. 1288-1296.
1959 [p26] [4]. S. Onishi, S. Meguro, Rethinking data augmentation
1960 [p26] for tabular data in deep learning, arXiv preprint, 2023,
1961 [p26] arXiv:2305.10308.
1962 [p26] [5]. R. Sauber-Cole, T. M. Khoshgoftaar, The use of
1963 [p26] generative adversarial netw orks to alleviate class
1964 [p26] imbalance in tabular data: a survey, Journal of Big
1965 [p26] Data, Vol. 9, Issue 1, 2022, 62.
1966 [p26] [6]. X. Fang, W. Xu, et al., Large language models (LLMs)
1967 [p26] on tabular data: prediction, generation, and
1968 [p26] understanding ‚Äì a survey, arXiv preprint , 2024,
1969 [p26] arXiv:2402.17944.
1970 [p26] [7]. T. Liu, Z. Qian, et al., G oggle: generative modelling for
1971 [p26] tabular data by learning relational structure, in
1972 [p26] Proceedings of The Eleventh International Conference
1973 [p26] on Learning Representations (ICLR‚Äô23), 2023.
1974 [p26] [8]. Y. Sui, T. Wu, et al., Self-supervised representation
1975 [p26] learning from random data projectors, arXiv preprint,
1976 [p26] 2023, arXiv:2310.07756.
1977 [p26] [9]. J. Wei, X. Wang, et al., Chain-of-thought prompting
1978 [p26] elicits reasoning in large language models, Advances in
1979 [p26] Neural Information Processing Systems, Vol. 35, 2022,
1980 [p26] pp. 24824-24837.
1981 [p26] [10]. V. Borisov, K. Se√üler, et al., Language models are
1982 [p26] realistic tabular data generators, arXiv preprint, 2022,
1983 [p26] arXiv:2210.06280.
1984 [p26] [11]. A. V. Solatorio, O. Dupriez, Realtabformer: generating
1985 [p26] realistic relational and tabular data using transformers,
1986 [p26] arXiv preprint, 2023 arXiv:2302.02041.
1987 [p26] [12]. T. Zhang, S. Wang, et al., Generative table pre-training
1988 [p26] empowers models for t abular prediction, arXiv
1989 [p26] preprint, 2023, arXiv:2305.09696.
1990 [p27] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
1991 [p27] 25-27 November 2025, Innsbruck, Austria
1992 [p27] 26
1993 [p27] [ 1 3 ] .  Z .  Z h a o ,  R .  B i r k e ,  L .  Y .  C h e n ,  T a b u l a :  h a r n e s s i n g
1994 [p27] language models for tabular data synthesis, in
1995 [p27] Proceedings of the Pacific-Asia Conference on
1996 [p27] Knowledge Discovery and Data Mining (PAKDD‚Äô25),
1997 [p27] 2025, pp. 247-259.
1998 [p27] [14]. Unsloth AI, unsloth/Llama-3.2-1B, Computer
1999 [p27] software, Hugging Face, 2025.
2000 [p27] https://huggingface.co/unsloth/Llama-3.2-1B
2001 [p27] [15]. N. Park, M. Mohammadi, et al., Data synthesis based
2002 [p27] on generative adversarial networks, Proceedings of the
2003 [p27] VLDB Endowment , Vol. 11, Issue 10, 2018,
2004 [p27] pp. 1071-1083.
2005 [p28] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2006 [p28] 25-27 November 2025, Innsbruck, Austria
2007 [p28] 27
2008 [p28] (015)
2009 [p28] Unforgetting Educational Surveillance: Reimagining AI as a Tool
2010 [p28] for Justice and Pedagogical Liberation
2011 [p28] G. Parker
2012 [p28] University Canada West, Leadership and People Management Department, 626 W Pender St #100,
2013 [p28] Vancouver, BC V6B 1V9
2014 [p28] Tel.: +1 236.259.1821
2015 [p28] E-mail: gifty.parker@ucanwest.ca
2016 [p28] Summary: This study critically investigates how institutional policies and pedagogical practices in Canadian higher education
2017 [p28] construct, regulate, and resist t he integration of generative A I. Drawing on Critical Discourse  Analysis [1], and narrative
2018 [p28] inquiry, the paper analyzes policy documents from select universities and centers the lived experiences of graduate students ‚Äì
2019 [p28] particularly international and multilingual learners. The resea rch foregrounds how AI governanc e intersects with academic
2020 [p28] surveillance, linguistic hierarchies, and digital equity. Throu gh participatory practices such as AI journaling and policy
2021 [p28] prototyping, the study advances ethical, justice-oriented approaches that challenge exclusionary norms embedded in dominant
2022 [p28] AI discourses. Findings highlight  that current frameworks often  reproduce epistemic inequities under the guise of academic
2023 [p28] integrity. By interrogating the sociocultural and ecological di mensions of AI infrastructure, t his work contributes to debates
2024 [p28] on ethical data governance, explainability, and student agency. The study proposes a reimagining of AI policy as participatory,
2025 [p28] inclusive, and aligned with decolonial and critical pedagogical principles.
2026 [p28] Keywords: Generative AI, Critical pedagogy, Epistemic justice, Curriculu m studies, Educational policy, AI Governance in
2027 [p28] education, Data ethics in higher education.
2028 [p28] 1. Introduction
2029 [p28] This paper investigates how generative AI is being
2030 [p28] governed in higher education through restrictive policy
2031 [p28] frameworks that mirror long-standing traditions of
2032 [p28] educational surveillance. As universities scramble to
2033 [p28] a d d r e s s  A I ‚Äô s  i m p l i c a t i o n s  f o r  s t u d e n t  w o r k ,  t h e
2034 [p28] resulting regulations often position AI as a threat to
2035 [p28] authenticity and learning, reinforcing assumptions
2036 [p28] about authorship and academic integrity that reflect
2037 [p28] deeper anxieties about automation, labor, and
2038 [p28] knowledge production. Drawing on Critical Discourse
2039 [p28] Analysis [2, 3], and narrative inquiry, the study
2040 [p28] analyzes policy texts from multiple institutions
2041 [p28] alongside reflective accounts  from faculty navigating
2042 [p28] new AI rules in their classrooms.
2043 [p28] The findings suggest that dominant institutional
2044 [p28] responses to generative AI, echoing insights from [4]
2045 [p28] and [5], rely on control-based models of teaching, in
2046 [p28] which educators and students are positioned as
2047 [p28] potential violators rather than co-creators. Selwyn
2048 [p28] cautions that the deployment of AI in education often
2049 [p28] reinforces hierarchical structures and managerial
2050 [p28] logics, sidelining democratic and relational
2051 [p28] pedagogies. Watters, tracing  the history of teaching
2052 [p28] machines, similarly illustrates how educational
2053 [p28] technologies have historically been used to regulate
2054 [p28] behavior and enforce standardization rather than
2055 [p28] support emancipatory learning. These frameworks are
2056 [p28] deeply entangled with the  broader datafication
2057 [p28] 1 o f
2058 [p28] education, as described by [6], where automated
2059 [p28] 1 Datafication refers to the transformation of social action
2060 [p28] into quantified data for analysis and decision-making.
2061 [p28] decision-making and surveillance logics increasingly
2062 [p28] shape pedagogical practi ces. By foregrounding
2063 [p28] narratives from the classroom, this study draws
2064 [p28] attention to how such policies marginalize alternative
2065 [p28] epistemologies, reinforcing the kinds of racialized and
2066 [p28] classed exclusions highlighted by [7-9] in their
2067 [p28] critiques of algorithmic injustice and institutional
2068 [p28] gatekeeping.
2069 [p28] Rather than proposing AI as an uncritical solution
2070 [p28] or a pedagogical threat, the paper frames it as a
2071 [p28] contested site of meaning-making, one that can either
2072 [p28] reproduce dominant power structures or serve as a
2073 [p28] catalyst for critical, inclusive, and participatory forms
2074 [p28] of knowledge. In response, the paper advocates for
2075 [p28] data-informed, justice-oriented pedagogical
2076 [p28] frameworks that foreground epistemic diversity and
2077 [p28] critical data literacies, challenging the binary of ‚ÄúAI
2078 [p28] misuse‚Äù versus ‚Äúproper use‚Äù that dominates policy
2079 [p28] discourse. Ultimately, it calls for a reimagination of
2080 [p28] AI‚Äôs role in education ‚Äì not as a system to be policed,
2081 [p28] but as a tool to rethink authorship, agency, and learning
2082 [p28] in data-driven times.
2083 [p28] As [10] provocatively asserts, constructing
2084 [p28] radically different futures necessitates redistributing
2085 [p28] power and agency to those historically marginalized
2086 [p28] and excluded from institutional educational systems.
2087 [p28] This assertion fundamentally unsettles the prevailing
2088 [p28] logics shaping higher education‚Äôs reaction to
2089 [p28] generative artificial inte lligence (AI). Across
2090 [p28] numerous institutions, including those that position
2091 [p28] themselves as progressive ‚Äì AI integration is not
2092 [p29] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2093 [p29] 25-27 November 2025, Innsbruck, Austria
2094 [p29] 28
2095 [p29] embraced as a transformative pedagogical opportunity
2096 [p29] but is instead rigidly contained within restrictive policy
2097 [p29] frameworks, quantitative quotas, and intensified
2098 [p29] surveillance mechanisms. These strategies are not
2099 [p29] neutral but rather perpetuate a legacy of control and
2100 [p29] disciplinary governance within education. For
2101 [p29] instance, some universities impose a 20 % cap on
2102 [p29] AI-generated content in student submissions. Yet, the
2103 [p29] questions of who arbitrates this threshold and why AI
2104 [p29] use must be relegated to such margins remain
2105 [p29] unaddressed. This paper critiques these arbitrary limits
2106 [p29] as symptomatic of broader institutional imperatives
2107 [p29] designed to police epistemic boundaries and uphold
2108 [p29] entrenched hierarchies. Such practices betray an
2109 [p29] educational system grappling with profound
2110 [p29] epistemological ruptures: What does learn, authorship,
2111 [p29] and knowledge production mean when the distinction
2112 [p29] between human and machine agency is destabilized?
2113 [p29] Generative AI platforms like ChatGPT and DALLÍûèE
2114 [p29] do not merely assist students ‚Äì they challenge deeply
2115 [p29] ingrained assumptions of originality, voice, and
2116 [p29] assessment that are rooted in Western academic
2117 [p29] traditions and sustained through systematic exclusion
2118 [p29] [11].
2119 [p29] Dominant academic norms have long marginalized
2120 [p29] students for whom English functions as an additional
2121 [p29] or second language, as well as those who engage in
2122 [p29] culturally situated and non-normative epistemologies.
2123 [p29] The deployment of AI detection technologies ‚Äì
2124 [p29] purportedly to identify ‚Äúnon-authentic‚Äù or machine-
2125 [p29] generated writing, frequently misclassifies
2126 [p29] multilingual and unconventional linguistic expressions
2127 [p29] as fraudulent. This misrecognition is far from a benign
2128 [p29] technical flaw; it constitutes a form of linguistic
2129 [p29] erasure that disproportionately punishes those already
2130 [p29] navigating colonial and exclusionary educational
2131 [p29] structures. What is exposed here is not AI as an
2132 [p29] inherent threat to academic integrity but rather the
2133 [p29] institutional apparatus that wields AI tools as
2134 [p29] instruments of gatekeeping, policing who is authorized
2135 [p29] to speak, how they are allowed to speak, and which
2136 [p29] modes of knowledge are legitimated. Such practices
2137 [p29] reinforce colonial legacies
2138 [p29] 1 of epistemic violence and
2139 [p29] perpetuate exclusion through technological means.
2140 [p29] 2. Research Questions and Participant
2141 [p29] Justification
2142 [p29] This study‚Äôs research que stions are critically
2143 [p29] designed to interrogate the ways institutional power,
2144 [p29] knowledge production, and identity are reconfigured in
2145 [p29] response to the integration of generative AI within
2146 [p29] higher education. By centering policy discourse and
2147 [p29] the lived educational expe riences of students and
2148 [p29] educators, these questions illuminate the mechanisms
2149 [p29] 1 Colonial legacies of epistemic violence‚Äù refers to historical
2150 [p29] and ongoing practices through which dominant knowledge
2151 [p29] systems marginalize, silence, or devalue the ways of
2152 [p29] knowing of colonized or minoritized groups [19, 20]. In the
2153 [p29] through which AI governance simultaneously
2154 [p29] reinscribes and challenges entrenched epistemic
2155 [p29] hierarchies, particularly t hose shaped by linguistic,
2156 [p29] cultural, racial, and migratory inequities.
2157 [p29] The first question critically examines institutional
2158 [p29] AI policies as discursive sites where power relations
2159 [p29] and ideological constructs converge to regulate
2160 [p29] academic integrity and authorship. Drawing on the
2161 [p29] foundational framework of Critical Discourse Analysis
2162 [p29] articulated by [1], these policies are understood not as
2163 [p29] neutral administrative documents but as strategic texts
2164 [p29] that enact surveillance, control, and normative
2165 [p29] discipline. This surveillance disproportionately
2166 [p29] privileges dominant Western, monolingual
2167 [p29] conceptions of knowledge, authority, and academic
2168 [p29] legitimacy [6], thereby perpetuating exclusionary
2169 [p29] academic norms as highlighted in scholarship on the
2170 [p29] datafication of education [6, 4]. Through this lens, the
2171 [p29] study reveals how generative AI is embedded within
2172 [p29] broader institutional regimes that marginalize
2173 [p29] alternative epistemologies, reinforcing patterns of
2174 [p29] epistemic injustice.
2175 [p29] The second and third questions engage directly
2176 [p29] with the complex lived realities of educators and
2177 [p29] students ‚Äì particularly those who identify as
2178 [p29] international, multilingual, and from historically
2179 [p29] marginalized backgrounds. The critical pedagogical
2180 [p29] tradition underscore s the necessity of centering
2181 [p29] marginalized voices to challenge and dismantle
2182 [p29] hegemonic academic cultures [12, 13]. Many
2183 [p29] international students, who often settle domestically
2184 [p29] after migration, navigate complex identity negotiations
2185 [p29] and epistemic tensions that frequently clash with
2186 [p29] prevailing Western academ ic norms privileging
2187 [p29] specific modes of authorship and linguistic expression
2188 [p29] [14, 15]. By exploring their experiences with AI tools
2189 [p29] in educational settings, this inquiry highlights how
2190 [p29] institutional policies translat e into practice, affecting
2191 [p29] student agency, trust, and equitable access. An
2192 [p29] intersectional framework further informs this analysis,
2193 [p29] attending to how race, language, and migration status
2194 [p29] intersect to shape layered educational inequities
2195 [p29] [16, 7].
2196 [p29] The fourth research question foregrounds
2197 [p29] participatory and justi ce-oriented pedagogies as
2198 [p29] essential interventions to reimagine AI governance
2199 [p29] within academia. Informed by decolonial and feminist
2200 [p29] epistemologies, this inquiry advances the imperative
2201 [p29] that students must be active co-creators of knowledge
2202 [p29] and governance frameworks to resist the disciplinary
2203 [p29] and surveillance logics embedded within AI systems
2204 [p29] [17, 18]. Participatory methods such as AI journaling
2205 [p29] and policy prototyping foster critical reflexivity and
2206 [p29] collective agency, enabling disruptions to punitive,
2207 [p29] top-down governance models and promoting epistemic
2208 [p29] context of AI-mediated assessment, these legacies are
2209 [p29] reflected in technologies and policies that disproportionately
2210 [p29] disadvantage multilingual or culturally diverse students.
2211 [p30] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2212 [p30] 25-27 November 2025, Innsbruck, Austria
2213 [p30] 29
2214 [p30] sovereignty1 [19, 20], here understood as students‚Äô
2215 [p30] capacity to exercise control over knowledge
2216 [p30] construction and evaluation. These approaches are
2217 [p30] especially vital for recenteri ng the voices of students
2218 [p30] from diverse linguistic and cultural backgrounds who
2219 [p30] have been historically marginalized within dominant
2220 [p30] academic paradigms.
2221 [p30] Lastly, this study situates AI governance within
2222 [p30] broader ecological and sociocultural frameworks,
2223 [p30] responding to urgent calls for critical environmental
2224 [p30] pedagogy that foregrounds the interconnections
2225 [p30] between social justice and environmental
2226 [p30] sustainability [4, 21]. Drawing on [21]‚Äôs emphasis on
2227 [p30] decolonial and place-based approaches, this holistic
2228 [p30] perspective acknowledges  t h a t  A I ‚Äô s  m a t e r i a l
2229 [p30] infrastructures ‚Äì such as data centers, energy
2230 [p30] consumption, and algorithmic systems are not abstract
2231 [p30] or neutral but are deeply e ntangled with systemic
2232 [p30] inequalities, including colonial legacies,
2233 [p30] environmental degradation, and marginalized
2234 [p30] communities‚Äô dispossession. Consequently, ethical AI
2235 [p30] governance must engage intersectional and
2236 [p30] justice-oriented responses that attend simultaneously
2237 [p30] to the sociocultural and ecological dimensions of
2238 [p30] technological development. This approach challenges
2239 [p30] reductive, purely technical solutions and advocates for
2240 [p30] integrated frameworks that  prioritize both ecological
2241 [p30] sustainability and epistemic equity.
2242 [p30] The deliberate focus on graduate students and
2243 [p30] educators in Canadian universities ‚Äì particularly those
2244 [p30] who are international and multilingual but have settled
2245 [p30] domestically ‚Äì reflects the complex intersections of
2246 [p30] global mobility, linguistic diversity, and institutional
2247 [p30] power structures. This participant group provides
2248 [p30] essential insights into how AI policies and pedagogical
2249 [p30] practices are experienced amidst conflicting academic
2250 [p30] expectations and cultural norms, offering fertile
2251 [p30] ground for co-constructing equitable and
2252 [p30] justice-centered AI governance models [26, 14]. These
2253 [p30] research questions and participant choices embody a
2254 [p30] critical commitment to unveiling and challenging the
2255 [p30] socio-political dimensions of generative AI integration
2256 [p30] in higher education. They advance a justice-centered
2257 [p30] research agenda that not only critiques dominant
2258 [p30] power structures but also imagines transformative
2259 [p30] pedagogical futures grounded in equity, participation,
2260 [p30] and decolonial praxis, contributing meaningfully to
2261 [p30] ongoing debates on privacy, fairness, ethical
2262 [p30] accountability, and particip atory governance in the
2263 [p30] evolving landscape of AI and big data in education.
2264 [p30] 1 The term ‚Äòepistemic sovereignty‚Äô originates from
2265 [p30] decolonial scholarship [19, 20], where it refers to the control
2266 [p30] Indigenous peoples have over their knowledge systems. In
2267 [p30] this paper, it is adapted to describe students‚Äô capacity to
2268 [p30] exercise agency and critical  control over knowledge in
2269 [p30] AI-mediated learning environments.
2270 [p30] 2 The term ‚Äúepistemic policing‚Äù is used here as an original
2271 [p30] analytic concept to describe how institutions or dominant
2272 [p30] 3. Methodology and Reflexivity
2273 [p30] This study employs a hybrid methodological
2274 [p30] framework integrating Critical Discourse Analysis
2275 [p30] (CDA) with narrative inquiry, explicitly grounded in
2276 [p30] researcher positionality. Institutional AI policies and
2277 [p30] pedagogical practices are analyzed as discursive texts
2278 [p30] ‚Äì dynamic sites where power relations, language, and
2279 [p30] ideology intersect to construct prevailing definitions of
2280 [p30] learning, authorship, and academic legitimacy.
2281 [p30] Drawing on [1] and [3] critical discourse frameworks,
2282 [p30] this approach reveals how su ch texts covertly encode
2283 [p30] mechanisms of control, exclusion, and epistemic
2284 [p30] policing
2285 [p30] 2. Complementing this, I foreground my lived
2286 [p30] experience as an educator navigating the complexities
2287 [p30] and contradictions inherent in AI integration within
2288 [p30] higher education. Informed by feminist, decolonial,
2289 [p30] and poststructuralist epistemologies, this
2290 [p30] methodological stance reframes narrative inquiry as a
2291 [p30] rigorous form of critical knowledge production rather
2292 [p30] than anecdotal reflection. T o enhance analytic depth
2293 [p30] and writing clarity, generative AI tools (specifically
2294 [p30] ChatGPT) were employed selectively during initial
2295 [p30] idea generation and iterative text refinement. These
2296 [p30] AI-generated outputs were c ritically evaluated and
2297 [p30] carefully integrated to mai ntain alignment with the
2298 [p30] study‚Äôs epistemological commitments and reflexive
2299 [p30] approach. This framework thus provides a lens to
2300 [p30] interrogate how entrenched histories of surveillance
2301 [p30] and linguistic marginalizatio n are rearticulated in
2302 [p30] AI-related institutional policies while simultaneously
2303 [p30] envisioning alternative pedagogical futures rooted in
2304 [p30] justice and equity.
2305 [p30] 3.1. Data Sources and Sampling
2306 [p30] This study investigates how institutional AI policies
2307 [p30] and pedagogical practices shape the integration of
2308 [p30] generative AI in higher education. The primary data
2309 [p30] corpus includes policy documents from seven
2310 [p30] universities across North America and Europe,
2311 [p30] selected for their accessibility, relevance, and diversity
2312 [p30] of approaches to AI in teaching and assessment.
2313 [p30] Complementary pedagogical materials such as course
2314 [p30] guidelines, assignment rubrics, and faculty
2315 [p30] communications will be examined to understand how
2316 [p30] policies are interpreted and operationalized within
2317 [p30] academic contexts. Document selection prioritizes
2318 [p30] those published or updated within the past two years,
2319 [p30] reflecting recent shifts in generative AI capabilities
2320 [p30] and institutional responses. At the time of writing,
2321 [p30] knowledge systems regulate who is recognized as a
2322 [p30] legitimate knower, what count s as valid knowledge, and
2323 [p30] which forms of expression are authorized. In the context of
2324 [p30] AI and higher education, this includes policies, assessments,
2325 [p30] or technologies that dispro portionately constrain or
2326 [p30] marginalize students with non-normative linguistic, cultural,
2327 [p30] or epistemic practices
2328 [p31] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2329 [p31] 25-27 November 2025, Innsbruck, Austria
2330 [p31] 30
2331 [p31] initial sampling is underway. Data are being sourced
2332 [p31] from publicly accessible ins titutional repositories and
2333 [p31] websites, supplemented by direct communication with
2334 [p31] faculty and administrative sta ff to request internal or
2335 [p31] unpublished materials. While some limitations may
2336 [p31] arise due to institutional transparency, the corpus aims
2337 [p31] to provide a robust cross-section of current policy
2338 [p31] landscapes. Ethical protocols guide data access,
2339 [p31] consent, and confidentia lity in accordance with
2340 [p31] institutional research standards.
2341 [p31] 3.2. Analytical Framework and Procedures
2342 [p31] The study employs a hybrid analytical approach
2343 [p31] that integrates Critical Discourse Analysis (CDA) and
2344 [p31] Narrative Inquiry, situating the work within a broader
2345 [p31] decolonial and critical pedagogical tradition.
2346 [p31] Institutional documents were examined using CDA to
2347 [p31] surface the latent ideologies, power dynamics, and
2348 [p31] normative assumptions embedded in policy language.
2349 [p31] This method is particularly suited for unpacking how
2350 [p31] AI governance reproduces dominant academic values
2351 [p31] ‚Äì such as Western, monolingual, and individualistic
2352 [p31] conceptions of knowledge, authorship, and
2353 [p31] surveillance under the guise of academic integrity.
2354 [p31] Complementing this, Narrative Inquiry was used to
2355 [p31] explore the lived pedagogical tensions and
2356 [p31] contradictions encountered in real-time AI integration.
2357 [p31] Researcher reflections as an active member of an
2358 [p31] Academic Integrity Committee served as a site of
2359 [p31] situated knowledge production. These reflections
2360 [p31] illuminated how institutional policies play out in
2361 [p31] practice, particularly in cases of improper AI use by
2362 [p31] students, and how these tensions reveal both the
2363 [p31] necessity of AI regulation and the opportunity for
2364 [p31] transformative pedagogical design. Data coding and
2365 [p31] thematic development are being conducted using
2366 [p31] qualitative software tools such as NVivo, allowing for
2367 [p31] iterative, reflexive coding across both institutional
2368 [p31] documents and narrative data. This methodological
2369 [p31] integration supports a dee p understanding of how
2370 [p31] policy and pedagogy intersect, and how AI governance
2371 [p31] can move toward more just, inclusive, and
2372 [p31] pedagogically sound approaches.
2373 [p31] 3.3. Participatory Practices in Progress
2374 [p31] To deepen the critical and praxis-oriented
2375 [p31] dimensions of the study, participatory initiatives are
2376 [p31] currently in early devel opment. These emerging
2377 [p31] practices seek to engage students not merely as
2378 [p31] research subjects but as co-constructors of knowledge,
2379 [p31] aligning with decolonial and justice-centered research
2380 [p31] ethics. These include: (1) reflective AI journaling,
2381 [p31] where graduate students engage in structured
2382 [p31] journaling exercises that document their interactions
2383 [p31] with AI tools, emphasizing metacognitive awareness
2384 [p31] and uncovering hidden power dynamics (e.g., reliance,
2385 [p31] trust, error interpretation). This fosters ethical
2386 [p31] discernment and agency in AI use; (2) peer-review
2387 [p31] dialogues, where graduate students participate in
2388 [p31] dialogic critique exercises collaboratively evaluating
2389 [p31] human- and AI-generated texts. These sessions
2390 [p31] challenge dominant narratives of authorship and assess
2391 [p31] how authority is constructed and contested in academic
2392 [p31] writing; and (3) participat ory policy prototyping,
2393 [p31] where graduate student groups co-design draft AI
2394 [p31] usage policies, drawing on their linguistic, cultural,
2395 [p31] and educational experiences. These co-created policies
2396 [p31] offer alternatives to punitive models, promoting
2397 [p31] equity-based governance fra meworks that recognize
2398 [p31] the diversity of international student experiences.
2399 [p31] These participatory practices are being designed
2400 [p31] with particular attention to international student
2401 [p31] populations and their diverse linguistic and epistemic
2402 [p31] backgrounds. They aim to challenge hegemonic
2403 [p31] academic standards and promote a more inclusive AI
2404 [p31] governance paradigm. Together, these methodologies
2405 [p31] reflect critical pedagogical commitments ‚Äì uncovering
2406 [p31] institutional power in AI policy language,
2407 [p31] foregrounding the lived realities of educational actors
2408 [p31] navigating generative AI, and building toward
2409 [p31] participatory, justice-orient ed alternatives that resist
2410 [p31] reductive, punitive approaches to academic integrity.
2411 [p31] Data coding and thematic development were
2412 [p31] conducted using qualitative software tools to support
2413 [p31] systematic and reflexive engagement. The iterative
2414 [p31] analysis process drew connections across institutional
2415 [p31] discourse, student practices, and researcher
2416 [p31] positionality, allowing for a multi-layered
2417 [p31] understanding of how generative AI is framed,
2418 [p31] governed, and negotiated in higher education. By
2419 [p31] combining institutional critique with participatory
2420 [p31] pedagogies, this methodology not only analyzes
2421 [p31] existing systems but also contributes to imagining
2422 [p31] more just, inclusive, and dialogic futures for AI
2423 [p31] governance in global academic contexts.
2424 [p31] 4. Critical Examination of AI Policies
2425 [p31] and Pedagogy
2426 [p31] Estes‚Äôs assertion that ‚Äúthere is no separation
2427 [p31] between past and present, meaning that an alternative
2428 [p31] future is also determined by our understanding of our
2429 [p31] past‚Äù offers a crucial lens through which to interrogate
2430 [p31] the integration of generative AI in education [11].
2431 [p31] Contemporary institutional responses largely
2432 [p31] characterized by detection, punitive policy
2433 [p31] enforcement, and restrictive frameworks echo historic
2434 [p31] modalities of educational surveillance. These range
2435 [p31] from invasive proctoring technologies to linguistic
2436 [p31] gatekeeping and racially coded behavioral controls,
2437 [p31] reproducing longstanding inequities under the guise of
2438 [p31] academic integrity. Far from advancing transformative
2439 [p31] academic integrity, these surveillance measures
2440 [p31] entrench exclusionary practices and deepen mistrust,
2441 [p31] disproportionately impacting marginalized groups
2442 [p31] such as neurodivergent students and those who use
2443 [p31] non-standard English.
2444 [p31] As Estes argues [11], compels a rigorous
2445 [p31] interrogation of how these enduring structures of
2446 [p31] educational control persist and evolve within current
2447 [p32] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2448 [p32] 25-27 November 2025, Innsbruck, Austria
2449 [p32] 31
2450 [p32] AI debates. The widespread reliance on detection
2451 [p32] tools, punitive disciplinar y policies, and narrowly
2452 [p32] defined academic honesty protocols mirrors earlier
2453 [p32] practices of surveillance that disproportionately impact
2454 [p32] marginalized groups, including neurodivergent
2455 [p32] students and non-standard English speakers.
2456 [p32] Classroom management techniques, too, remain
2457 [p32] steeped in racialized disciplinary logics. Despite their
2458 [p32] technological veneer, these systems sustain what Paulo
2459 [p32] Freire termed a ‚Äúpedagogy of suspicion‚Äù ‚Äì a critical
2460 [p32] stance that challenges power by scrutinizing hidden
2461 [p32] ideologies and inequities in educational practices [13].
2462 [p32] This pedagogy reveals how students are presumed
2463 [p32] untrustworthy, and learning is policed rather
2464 [p32] than nurtured.
2465 [p32] Drawing on Krawec‚Äôs concept of unforgetting, this
2466 [p32] paper calls for a critical remembering of educational
2467 [p32] histories marked by surveillance, exclusion, and
2468 [p32] epistemic violence [23]. Unforgetting here is not a
2469 [p32] passive recollection; it is a political and pedagogical
2470 [p32] practice centered on relationality, historical
2471 [p32] accountability, and an active refusal of colonial
2472 [p32] erasure. In the context of AI governance in universities
2473 [p32] ‚Äì particularly those serving diverse international
2474 [p32] student populations ‚Äì this means interrogating how
2475 [p32] dominant policies reproduce hegemonic academic
2476 [p32] standards that privilege Western, monolingual, and
2477 [p32] individualistic ideas of authorship, knowledge, and
2478 [p32] language. Such standards disproportionately
2479 [p32] marginalize students who write in non-standard
2480 [p32] English, draw from alternative epistemologies, or
2481 [p32] come from collectivist educational traditions.
2482 [p32] Rather than supporting learning, punitive AI
2483 [p32] detection measures replicate patterns of linguistic and
2484 [p32] racial surveillance, cloaked in discourses of academic
2485 [p32] integrity. Unforgetting demands that institutions refuse
2486 [p32] to normalize these inequities and instead reimagine AI
2487 [p32] governance as part of a justice-oriented pedagogy ‚Äì
2488 [p32] one that embraces multimodality, ethical co-creation,
2489 [p32] and knowledge sovereignty. This perspective is
2490 [p32] deepened by Gloria Anzald√∫a‚Äôs Borderlands/La
2491 [p32] Frontera, which critically examines how colonial and
2492 [p32] linguistic borders shape identity, knowledge, and
2493 [p32] power [24]. Anzald√∫a‚Äôs work highlights the lived
2494 [p32] experience of navigating multiple languages and
2495 [p32] cultures, challenging hegemonic, monolingual
2496 [p32] academic norms that AI governance often reinforces.
2497 [p32] Her insights call for educational policies that validate
2498 [p32] multilingualism and hybrid epistemologies rather than
2499 [p32] policing conformity. Additionally, the political
2500 [p32] urgency emphasized by Tuck and Yang [19, 20] in
2501 [p32] Decolonization is Not a Metaphor reinforces that
2502 [p32] addressing AI governance requires more than symbolic
2503 [p32] reform [20]. They argue that genuine decolonization
2504 [p32] must confront and dismantle entrenched colonial
2505 [p32] power structures, rather than merely repurpose them.
2506 [p32] This demands that universities move beyond
2507 [p32] 1 Epistemic agency refers to the learner‚Äôs capacity to take
2508 [p32] responsibility for, and actively shape, the processes of
2509 [p32] knowledge building and validation [35, 36].
2510 [p32] superficial diversity initiatives and critically reimagine
2511 [p32] AI‚Äôs role in perpetuating or resisting systemic
2512 [p32] inequities.
2513 [p32] 4.1. AI-integrated Assessment in Practice
2514 [p32] While empirical research on student engagement
2515 [p32] with generative AI is growing [32-34], this study
2516 [p32] draws on a different form of empirical evidence: policy
2517 [p32] documents, course guidelines, assignment rubrics, and
2518 [p32] faculty communications (see Fig. 1). This document-
2519 [p32] centered analysis complements broader empirical
2520 [p32] studies that focus on student experiences, providing a
2521 [p32] lens to interrogate institutional power, epistemic
2522 [p32] authority, and pedagogical governance. A close
2523 [p32] reading of the AI-integrated personality assessment
2524 [p32] assignment exposes the tension between pedagogical
2525 [p32] innovation and control. Students are invited to explore
2526 [p32] multiple AI tools and reflect critically, however, the
2527 [p32] instructions simultaneously enforce compliance:
2528 [p32] ‚ÄúKindly ensure not to copy-paste the AI answers
2529 [p32] directly.‚Äù From a CDA perspective, such directives
2530 [p32] position students as objects of governance, encoding
2531 [p32] hierarchical power relatio ns and framing AI not as a
2532 [p32] co-creative partner but as a monitored instrument.
2533 [p32] Group structures, submission protocols, and reflective
2534 [p32] prompts further mediate collaboration through
2535 [p32] oversight, subtly shaping both participation and
2536 [p32] epistemic legitimacy.
2537 [p32] Still within these constraints lie latent possibilities
2538 [p32] for critical engagement. Reflection and collaborative
2539 [p32] synthesis offer sites where students might negotiate
2540 [p32] meaning, contest institutional assumptions, and
2541 [p32] exercise epistemic agency
2542 [p32] 1. The assignment thus
2543 [p32] emerges as a site of discursive tension: simultaneously
2544 [p32] a mechanism of control and a potential avenue for
2545 [p32] emancipation. This prompts a critical question: how
2546 [p32] might institutional discourses be rearticulated to
2547 [p32] reposition AI from a compliance tool to a catalyst for
2548 [p32] justice-oriented pedagogy, equitable knowledge
2549 [p32] creation, and student-led experimentation? By
2550 [p32] foregrounding these document-based insights, the
2551 [p32] study begins to bridge the gap between theoretical
2552 [p32] critique and practical intervention. The CDA approach
2553 [p32] uncovers subtle mechanisms through which language
2554 [p32] and policy mediate learning experiences, providing a
2555 [p32] foundation for proposing assessment strategies that are
2556 [p32] both justice-oriented and p edagogically liberatory.
2557 [p32] While further data collection and participatory insights
2558 [p32] would deepen the empirical grounding, these
2559 [p32] preliminary analyses offer a tangible illustration of the
2560 [p32] tensions and possibilities inherent in ethically and
2561 [p32] critically integrating AI within higher education.
2562 [p32] Extending from this document-centered insight,
2563 [p32] institutional alignment emerges as a key consideration.
2564 [p32] Inconsistent expectations across courses, even within
2565 [p33] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2566 [p33] 25-27 November 2025, Innsbruck, Austria
2567 [p33] 32
2568 [p33] the same program, create discursive conditions that
2569 [p33] constrain student agency and produce epistemic
2570 [p33] uncertainty, particularly for multilingual or
2571 [p33] international learners. From a CDA lens, such
2572 [p33] inconsistencies are not neutral; they actively construct
2573 [p33] hierarchies of authority , privileging institutional
2574 [p33] interpretation over student reasoning. Participatory
2575 [p33] governance frameworks offer a potential corrective: by
2576 [p33] involving students and faculty in co-creating AI-use
2577 [p33] policies, institutions can clarify expectations while
2578 [p33] preserving spaces for critical  experimentation. In this
2579 [p33] approach, reflection, documentation, and collaborative
2580 [p33] synthesis are both pedagogical strategies and
2581 [p33] mechanisms through which students negotiate
2582 [p33] meaning and exercise agency within institutional
2583 [p33] structures.
2584 [p33] Fig. 1.  Example of AI-integrate d personality assessment
2585 [p33] assignment in a higher educat ion course shell. Note: Using
2586 [p33] Critical Discourse Analysis, this assignment reflects tensions
2587 [p33] between pedagogical innovation and institutional control.
2588 [p33] Language emphasizing docume ntation, reflection,
2589 [p33] and prohibition of copy-pasting positions students as subjects
2590 [p33] of oversight while simultane ously encouraging engagement
2591 [p33] with AI tools. The structure d individual and group tasks
2592 [p33] reveal underlying power relatio ns and epistemic authority,
2593 [p33] highlighting opportunities to reframe AI use as a co-creative,
2594 [p33] justice-oriented learning practice. Source: Anonymized
2595 [p33] course materials.
2596 [p33] Moreover, the discursive framing of AI across
2597 [p33] programs must be coherent an d transparent. Policies,
2598 [p33] rubrics, and directives should consistently
2599 [p33] communicate rights and responsibilities while
2600 [p33] integrating reflection and participatory feedback. CDA
2601 [p33] highlights that the language used in these texts
2602 [p33] mediates power and shapes perceptions of legitimacy;
2603 [p33] transparent, participatory approaches help expose and
2604 [p33] reconfigure these dynamics. By focusing on critical
2605 [p33] reflection, ethical reasoning, and student-led
2606 [p33] documentation of AI engagement, governance
2607 [p33] structures can transform AI from a monitored tool into
2608 [p33] a co-creative partner in knowledge production.
2609 [p33] Ultimately, a justice-oriented perspective extends to
2610 [p33] broader epistemic and ethical considerations.
2611 [p33] Decisions about AI use influence whose intellectual
2612 [p33] contributions are recognized and whose labor is
2613 [p33] rendered invisible. CDA underscores that knowledge
2614 [p33] production is always situated within power-laden
2615 [p33] discourses. Integrating structured reflection,
2616 [p33] participatory policy-making, and institution-wide
2617 [p33] guidance allows AI to scaffo ld equitable, critically
2618 [p33] engaged learning rather than serve as an instrument of
2619 [p33] surveillance. In this way, tensions between oversight
2620 [p33] and innovation become productive sites for critical
2621 [p33] engagement, positioning AI as a catalyst for
2622 [p33] emancipatory pedagogy and a vehicle for student
2623 [p33] agency and epistemic justice.
2624 [p33] 5. Critical Tensions and Contradictions
2625 [p33] in AI Governance
2626 [p33] Institutional governance of AI in graduate
2627 [p33] education remains inconsistent, producing a
2628 [p33] patchwork of rules and surveillance mechanisms that
2629 [p33] students must navigate. Some courses encourage AI as
2630 [p33] a reflective, co-creative tool, while others rely on
2631 [p33] automated detection systems, rigid prohibitions, or
2632 [p33] arbitrary thresholds (e.g., flagging submissions with
2633 [p33] l e s s  t h a n  2 0  %  A I - g e n e r a t e d  c o n t e n t ) .  F r o m  a  C D A
2634 [p33] perspective [1, 3], these divergent practices are not
2635 [p33] neutral; they actively construct hierarchies of
2636 [p33] knowledge and authority, shaping who can claim
2637 [p33] epistemic legitimacy. International students, already
2638 [p33] negotiating linguistic and cultural marginality [27, 28],
2639 [p33] are disproportionately affected, as they must interpret
2640 [p33] conflicting institutional rules while avoiding
2641 [p33] disciplinary sanction.
2642 [p33] Policing AI, even with ostensibly minor thresholds,
2643 [p33] enacts a subtle but powerfu l disciplinary logic. The
2644 [p33] emphasis on compliance ‚Äì articulated in directives like
2645 [p33] ‚Äúdo not copy-paste AI answers‚Äù positions students as
2646 [p33] subjects to be monitored rather than active knowledge
2647 [p33] producers. CDA highlights how such institutional
2648 [p33] language discursively enforc es control, transforming
2649 [p33] assignments from sites of inquiry into instruments of
2650 [p33] governance. Classes without AI oversight, by contrast,
2651 [p33] may permit exploration but also leave students without
2652 [p33] clear epistemic guidance, risking confusion about what
2653 [p33] counts as legitimate knowledge. In both cases, the
2654 [p33] institutional framing privileges surveillance over
2655 [p33] critical engagement, raising the question: is the
2656 [p33] academy more invested in policing behavior than
2657 [p33] fostering reflective, equitable learning? Moreover, the
2658 [p33] focus on detection and restriction obscures AI‚Äôs
2659 [p33] potential as a pedagogical too l. Generative AI, when
2660 [p34] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2661 [p34] 25-27 November 2025, Innsbruck, Austria
2662 [p34] 33
2663 [p34] scaffolded appropriately, can extend coverage, support
2664 [p34] reasoning, and provide alternative modes of
2665 [p34] understanding ‚Äì resources particularly valuable for
2666 [p34] students unfamiliar with dominant academic norms.
2667 [p34] Yet institutional discourses that foreground risk, rather
2668 [p34] than opportunity, effectively ‚Äúdumb down‚Äù  A I ,
2669 [p34] constraining its capacity to enhance learning. CDA
2670 [p34] exposes this tension: the technology is not inherently
2671 [p34] disempowering, but institutional practices render it so.
2672 [p34] Students internalize compliance as epistemic virtue,
2673 [p34] rather than critical exploration, reinforcing inequities
2674 [p34] and curtailing agency.
2675 [p34] The critical implications are stark. Should graduate
2676 [p34] programs maintain frag mented, class-specific
2677 [p34] approaches, or establish coherent, program-wide AI
2678 [p34] policies that clearly define both rights and
2679 [p34] responsibilities? Does the act of policing AI genuinely
2680 [p34] enhance learning, or does it perpetuate systemic
2681 [p34] inequities and anxiety, especially among international
2682 [p34] students? How might institutions reframe AI not as a
2683 [p34] threat to authorship, but as a conduit for reflective,
2684 [p34] co-creative, and justice-or i e n t e d  p e d a g o g y ?  A  t r u l y
2685 [p34] critical approach would disrupt the logic of
2686 [p34] surveillance, redistribute epistemic authority, and
2687 [p34] reconceptualize AI as a scaffold for equitable learning.
2688 [p34] Without such a reframing, AI governance risks
2689 [p34] reinforcing the very hierarchies it purports to manage,
2690 [p34] privileging institutional control over student agency,
2691 [p34] and compliance over critical inquiry.
2692 [p34] 5.1. Surveillance, Contradiction, and the Politics
2693 [p34] of AI-integrated Assessment
2694 [p34] The coexistence of divergent practices within the
2695 [p34] s a m e  M B A  p r o g r a m  ‚Äì  o n e  a s s i g n m e n t  e n c o u r a g i n g
2696 [p34] students to experiment with multiple AI tools, another
2697 [p34] submission flagged at 95 % AI-generated, alongside a
2698 [p34] different assignment flagged at 44 % (As shown in
2699 [p34] Fig. 2 and Fig. 3) ‚Äì illustrates the fractured and often
2700 [p34] contradictory discourses that govern AI in higher
2701 [p34] education. In one space, AI is constructed as an
2702 [p34] instrument of pedagogical innovation: students are
2703 [p34] asked to explore, reflect, and collaborate using tools
2704 [p34] like ChatGPT, Gemini, or Claude. In another, AI is
2705 [p34] framed as a threat to academic integrity, with
2706 [p34] algorithmic detection systems legitimating punitive
2707 [p34] responses. Turnitin‚Äôs AI writing assessment comes
2708 [p34] with a disclaimer (see Fig. 2 and Fig. 3) noting that
2709 [p34] results may be inaccurate and should not be used as the
2710 [p34] sole basis for disciplinary action. From a CDA
2711 [p34] perspective, this language is telling: it signals
2712 [p34] institutional caution while still asserting algorithmic
2713 [p34] authority, positioning students under surveillance even
2714 [p34] as the tool admits uncertainty.
2715 [p34] For international and multilingual students, these
2716 [p34] contradictions take on heightened significance.
2717 [p34] Assignments that encourage experimentation with AI
2718 [p34] may offer new pathways for support ‚Äì scaffolding
2719 [p34] language learning, expanding access to resources, or
2720 [p34] providing avenues for self-directed exploration [27].
2721 [p34] Yet the threat of being flagged by AI-detection tools
2722 [p34] places these same students under heightened scrutiny.
2723 [p34] As [29] and [30] argue, language and authorship in
2724 [p34] academic contexts are never neutral; they are
2725 [p34] structured by racialized a nd colonial assumptions
2726 [p34] about what counts as ‚Äúauthentic‚Äù knowledge. AI
2727 [p34] detection technologies extend these assumptions by
2728 [p34] treating writing that deviates from standardized
2729 [p34] linguistic norms as suspect, thereby reinscribing
2730 [p34] epistemic hierarchies under the guise of technological
2731 [p34] neutrality.
2732 [p34] This contradiction raises a central question: whose
2733 [p34] knowledge is privileged when AI use is policed, and
2734 [p34] whose knowledge is erased when it is celebrated?
2735 [p34] When AI-detection algorithms flag a submission at
2736 [p34] 95 %, does this erase the student‚Äôs intellectual labor of
2737 [p34] prompt design, synthesis, and reflection? Conversely,
2738 [p34] when AI use is sanctioned in another assignment, is it
2739 [p34] truly emancipatory, or does it remain bounded by
2740 [p34] institutional directives that reduce students to
2741 [p34] compliant users rather than co-creators of knowledge?
2742 [p34] Here, CDA allows us to see that the question is not
2743 [p34] simply whether AI use should be permitted or
2744 [p34] prohibited. Rather, it is about how institutional
2745 [p34] discourses frame AI in ways that reproduce existing
2746 [p34] regimes of power. Left unpoliced, AI risks becoming a
2747 [p34] tool of epistemic outsourcing, where students rely
2748 [p34] uncritically on machine-generated outputs.
2749 [p34] Over-policed, it becomes a site of disciplinary
2750 [p34] surveillance that punishes the very students most likely
2751 [p34] to benefit from critical engagement with these tools.
2752 [p34] Both extremes risk undermining the emancipatory
2753 [p34] potential of AI in education.
2754 [p34] A justice-oriented altern ative requires reframing
2755 [p34] the role of AI in assessment. Instead of positioning AI
2756 [p34] as either a forbidden crutch or a celebrated novelty,
2757 [p34] institutions could adopt participatory frameworks
2758 [p34] where students and faculty c o-create guidelines for
2759 [p34] ethical and critical AI use [31]. Reflective AI journals,
2760 [p34] for instance, could require students to document not
2761 [p34] just AI outputs but the reasoning behind their use ‚Äì
2762 [p34] shifting the focus from product to process, from
2763 [p34] compliance to critical engagement. Similarly, policy
2764 [p34] prototyping exercises could invite students to
2765 [p34] collaboratively reimagine institutional AI policies,
2766 [p34] positioning students not as passive subjects of
2767 [p34] surveillance but as active contributors to the
2768 [p34] governance of their own learning. Ultimately, what is
2769 [p34] at stake is not only the question of AI in the classroom
2770 [p34] but the broader struggle over epistemic authority in
2771 [p34] higher education. If institutions continue to oscillate
2772 [p34] between uncritical celebration and punitive policing,
2773 [p34] they risk reproducing a system where students ‚Äì
2774 [p34] especially those from marginalized linguistic and
2775 [p34] cultural backgrounds ‚Äì remain caught in the paradox
2776 [p34] of being simultaneously invited and distrusted. To
2777 [p34] move beyond this impasse, AI must be reimagined not
2778 [p34] as a compliance tool but as a catalyst for
2779 [p34] justice-oriented pedagogy: one that foregrounds
2780 [p34] student agency, values diverse epistemologies, and
2781 [p34] resists the expansion of educational surveillance into
2782 [p34] every corner of academic life.
2783 [p35] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2784 [p35] 25-27 November 2025, Innsbruck, Austria
2785 [p35] 34
2786 [p35] Fig. 2. Turnitin AI-generated content report (95 %). An anonymized example illustrating the detection of high AI-generated
2787 [p35] content in a student submission.
2788 [p35] Fig. 3. Turnitin AI-generated content report (44 %). An anonymized example illustrating the detection of moderate AI-
2789 [p35] generated content in a student submission.
2790 [p35] 5.2. Toward a Critical Reconceptualization of AI
2791 [p35] Governance
2792 [p35] The institutional imperative to govern AI use in
2793 [p35] universities often centers on preventing academic
2794 [p35] dishonesty ‚Äì a necessity grounded in concerns over the
2795 [p35] improper deployment of generative AI in student work.
2796 [p35] Drawing on my experience within the university‚Äôs
2797 [p35] Academic Integrity Committee, this paper recognizes
2798 [p35] the practical need for detection and enforcement
2799 [p35] mechanisms to uphold academic standards. Cases of
2800 [p35] undisclosed AI-generated content and superficial
2801 [p35] engagement with AI tools reveal tangible threats to
2802 [p35] academic integrity that cannot be ignored.
2803 [p35] Yet, this dominant framing ‚Äì AI as a threat to be
2804 [p35] policed ‚Äì functions as a form of disciplinary power that
2805 [p35] risks reproducing exclusionary logics. Surveillance-
2806 [p35] based policies disproportionately impact marginalized
2807 [p35] groups, including international students whose
2808 [p35] linguistic and epistemological practices diverge from
2809 [p35] hegemonic academic norms. This punitive orientation
2810 [p35] often neglects the complex realities of AI‚Äôs
2811 [p35] pervasiveness and potential within learning contexts.
2812 [p35] Critically, governance that privileges control over
2813 [p35] critical engagement forecloses opportunities for
2814 [p35] students to develop meaningful literacies around AI.
2815 [p35] Rather than positioning AI merely as a site of risk,
2816 [p35] universities must reconceptualize AI governance as a
2817 [p35] pedagogical intervention ‚Äì one that cultivates ethical,
2818 [p35] reflective, and justice-oriented uses of AI. This entails
2819 [p35] moving beyond reductive detection toward pedagogies
2820 [p35] that integrate AI literacy, support multimodal
2821 [p36] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2822 [p36] 25-27 November 2025, Innsbruck, Austria
2823 [p36] 35
2824 [p36] expression, and foster dialogic critique of
2825 [p36] AI-generated knowledge. Su ch an approach demands
2826 [p36] institutional humility and responsiveness: governance
2827 [p36] must be co-constructed with students, particularly
2828 [p36] those from marginalized and international
2829 [p36] backgrounds, acknowledging and validating their
2830 [p36] linguistic and cultural diversity. As Garcia and Nichols
2831 [p36] [22] argue, pedagogies of code-switching exemplify
2832 [p36] how students can critically  navigate AI-generated
2833 [p36] norms without forfeiting their expressive agency.
2834 [p36] Ultimately, effective AI governance in higher
2835 [p36] education cannot be reduced to binary oppositions of
2836 [p36] policing versus permissiveness. Instead, it must
2837 [p36] grapple with the contradictions inherent in AI‚Äôs
2838 [p36] integration ‚Äì recognizing its potential both to reinforce
2839 [p36] inequities and to serve as a tool for critical,
2840 [p36] emancipatory learning. Only through such a nuanced,
2841 [p36] justice-centered lens can AI governance transcend
2842 [p36] surveillance and exclusion to become a catalyst for
2843 [p36] transformative educational futures.
2844 [p36] 5.3. Multi-layered Institutional Interactions
2845 [p36] Institutional texts, policies, and assignment designs
2846 [p36] surrounding AI in higher education operate as sites
2847 [p36] where power, epistemic authority, and compliance are
2848 [p36] materially and symbolically  enacted. Students are
2849 [p36] simultaneously invited to integrate generative AI into
2850 [p36] academic writing and constrained by prescriptive
2851 [p36] language emphasizing surveillance, risk mitigation,
2852 [p36] and adherence to narrow expectations. For ESL and
2853 [p36] international students, this dual framing intensifies
2854 [p36] inequities: navigating linguistic, cultural, and
2855 [p36] algorithmic norms, they are positioned as both learners
2856 [p36] and potential violators of institutional standards.
2857 [p36] Empirical work illustrates that students view AI as a
2858 [p36] versatile collaborator ‚Äì supporting brainstorming,
2859 [p36] drafting, reflection, and revision ‚Äì yet institutional
2860 [p36] directives frequently fail to  recognize these practices
2861 [p36] as legitimate forms of learning [34]. Language such as
2862 [p36] ‚Äúensure not to copy-paste AI outputs‚Äù (as shown in
2863 [p36] Fig. 1) discursively positions students as objects of
2864 [p36] governance, valorizing compliance while
2865 [p36] marginalizing exploration. This produces a discursive
2866 [p36] double-bind: students are rhetorically encouraged to
2867 [p36] engage critically with AI while simultaneously
2868 [p36] constrained by structures that limit autonomy,
2869 [p36] experimentation, and epistemic agency.
2870 [p36] Fig. 4 operationalizes these dynamics through a
2871 [p36] multi-layered mapping of institutional and student
2872 [p36] interactions where power and agency continually
2873 [p36] interact. At the top layer, institutional and assignment
2874 [p36] factors encode risk, integrity, and prescriptive AI
2875 [p36] engagement. Compliance-oriented language and
2876 [p36] structured tasks shape reflective capacity, while
2877 [p36] surveillance emphasis discourages epistemic
2878 [p36] risk-taking, especially for students with lower prior
2879 [p36] knowledge. Reflection and collaboration components,
2880 [p36] though embedded in assignments, are circumscribed
2881 [p36] by broader constraints, pro ducing latent tensions
2882 [p36] between innovation and control.
2883 [p36] Institutional factors (e.g., risk and prescriptive AI
2884 [p36] policies) exert control, but their effects are mediated
2885 [p36] by student capitals (cultural, social, epistemic),
2886 [p36] producing tensions in Layer 3 where constraints and
2887 [p36] capacities collide. These ‚Äúcross-layer tensions‚Äù both
2888 [p36] reveal inequities ‚Äì such as superficial compliance
2889 [p36] when cultural or epistemic capital is low ‚Äì and create
2890 [p36] leverage points for more critical engagement when
2891 [p36] capital is high. In the second layer, student contextual
2892 [p36] factors, highlights cultural capital, social capital, and
2893 [p36] epistemic awareness. Students with higher capital
2894 [p36] navigate institutional constraints more strategically,
2895 [p36] engaging critically with AI tools and reflective tasks.
2896 [p36] Those with lower capital often comply superficially,
2897 [p36] limiting critical engagement and reinforcing inequities
2898 [p36] in participation and learni ng outcomes. Interaction
2899 [p36] effects form the third layer, revealing how institutional
2900 [p36] constraints and student capitals converge to shape
2901 [p36] engagement quality. High-capital students can
2902 [p36] leverage structured assignments to produce detailed
2903 [p36] outputs, whereas low-capital students experience
2904 [p36] constrained epistemic agency. Collaborative structures
2905 [p36] can either amplify these disparities or mitigate them
2906 [p36] when scaffolded effectively.
2907 [p36] Finally, the flowchart identifies pedagogical
2908 [p36] opportunities and strategic interventions. Assignments
2909 [p36] can be scaffolded according to student capital,
2910 [p36] balancing oversight with c o-creative freedom. Peer
2911 [p36] mentoring and social learning can leverage social
2912 [p36] capital, while reflective prompts enhance epistemic
2913 [p36] awareness. These measures redistribute epistemic
2914 [p36] authority and create pathways for equitable
2915 [p36] engagement, transforming AI from a monitored
2916 [p36] instrument into a scaffold for justice-oriented,
2917 [p36] critically engaged learning. The analysis demonstrates
2918 [p36] that inequities, tensions, and opportunities in
2919 [p36] AI-integrated assessment are discursively produced:
2920 [p36] they emerge from the interaction of institutional
2921 [p36] discourse, assignment design, and individual student
2922 [p36] capacities, rather than from the technology itself.
2923 [p36] 6. Conclusion and Limitations
2924 [p36] This paper advocates for  a fundamental shift in
2925 [p36] framing AI integration within higher education ‚Äì from
2926 [p36] the limiting question of How much AI use is too much?
2927 [p36] to the more expansive and generative inquiry: What
2928 [p36] does learning look like when AI is an ever-present
2929 [p36] cognitive partner? Such reframing demands
2930 [p36] pedagogies grounded not in surveillance, suspicion, or
2931 [p36] fear, but in trust, collabora tion, and critical inquiry ‚Äì
2932 [p36] foregrounding historically marginalized voices and
2933 [p36] epistemologies. Drawing on Ng≈©gƒ©wa Thiong‚Äôo‚Äôs call
2934 [p36] to ‚Äúreclaim the imagination‚Äù from colonial logics [25],
2935 [p36] this paper contends that AI must be repositioned not as
2936 [p36] a disciplinary tool but as a co-participant in the
2937 [p36] struggle for pedagogical liberation. Educational AI
2938 [p36] governance, if uncritically implemented, risks
2939 [p36] replicating the colonial structures of epistemic
2940 [p36] exclusion, linguistic policing, and learner mistrust. To
2941 [p36] resist this, institutions must imagine AI frameworks
2942 [p37] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
2943 [p37] 25-27 November 2025, Innsbruck, Austria
2944 [p37] 36
2945 [p37] that affirm multilingualism, epistemic plurality, and
2946 [p37] student agency. Crucially, as Selwyn reminds us, the
2947 [p37] material costs of AI, its environmental extraction,
2948 [p37] infrastructural demands, and embedded inequalities ‚Äì
2949 [p37] must not be treated as peripheral [4]. Sustainability is
2950 [p37] integral to educational justice. Ethical AI governance
2951 [p37] must therefore account for  both its sociopolitical and
2952 [p37] ecological dimensions.
2953 [p37] Fig. 4. Multi-Layered Flow of Institutional Constraints, Student Capit als, Interaction Effects, and Pedagogical Opportunities
2954 [p37] in AI-Integrated Learning. Note:  Conceptual work and all ideas represented in this figure are original to Gifty Parker, PhD.
2955 [p37] The visual diagram was executed by Yaprak Deniz Yurt, PhD purel y as a rendering of the conceptual design. The figure
2956 [p37] demonstrates how institutional policies, student contexts, cross-layer tensions, and pedagogical interventions interact to shape
2957 [p37] AI engagement, reflection, and equitable outcomes.
2958 [p37] Moreover, critical engagement requires
2959 [p37] unforgetting the rich digital literacies cultivated by
2960 [p37] Indigenous, Black, and multilingual communities ‚Äì
2961 [p37] practices often marginalized in mainstream AI
2962 [p37] discourse but essential for epistemic sovereignty and
2963 [p37] cultural survival [7, 8]. I ntegrating these legacies
2964 [p37] challenges hegemonic academic norms and opens
2965 [p37] pedagogical possibilities for ethically scaffolded
2966 [p37] learning, including ‚Äúpedagogies of code-switching‚Äù
2967 [p37] [22] that support students in navigating the boundaries
2968 [p37] between human and AI-generated expression with
2969 [p37] critical awareness and ethical care. Despite these
2970 [p37] contributions, this study has limitations. It draws
2971 [p37] primarily on document analysis and narrative inquiry
2972 [p37] from a purposive sample of institutions, which may not
2973 [p37] fully reflect the global diversity of AI practices or
2974 [p37] institutional responses. While reflexivity helps
2975 [p37] mitigate interpretive bias, the subjective positioning of
2976 [p37] the researcher inevitably shapes the analysis. Future
2977 [p37] research must expand to include broader, direct
2978 [p37] engagement with students and educators, particularly
2979 [p37] those from marginalized bac kgrounds to co-create AI
2980 [p37] governance models that reflect lived realities and
2981 [p37] prioritize justice. In closing, this work contributes
2982 [p37] foundational insights for reconceptualizing AI not as a
2983 [p37] threat to academic integrity, but as a contested terrain
2984 [p37] where equity, power, and imagination must be
2985 [p37] negotiated. Reclaiming AI‚Äôs potential for liberatory
2986 [p37] pedagogy demands sustained critical vigilance,
2987 [p37] participatory research, a nd ethical commitment. Only
2988 [p37] then can educational institutions foster AI futures that
2989 [p37] are not merely technologica lly advanced, but socially
2990 [p37] just, ecologically responsible, and pedagogically
2991 [p37] transformative.
2992 [p37] References
2993 [p37] [1]. N. Fairclough, R. Wodak, Critical discourse analysis,
2994 [p37] in Discourse Studies: A Multidisciplinary Introduction,
2995 [p37] (T. van Dijk, Ed.), Vol. 2, Sage, 1997, pp. 258-284.
2996 [p37] [2]. T. Van Leeuwen, Discourse and Practice: New Tools
2997 [p37] for Critical Discourse Analysis, Oxford University
2998 [p37] Press, 2008.
2999 [p37] [3]. T. A. van Dijk, Principles of critical discourse analysis,
3000 [p37] Discourse & Society, Vol. 4, Issue 2, 1993,
3001 [p37] pp. 249-283.
3002 [p37] [4]. N. Selwyn, On the limits of artificial intelligence (AI)
3003 [p37] in education, Nordisk Tidsskrift for Pedagogikk &
3004 [p37] Kritikk, Vol. 10, Issue 1, 2024.
3005 [p37] [5]. A. Watters, Teaching Machines: The History of
3006 [p37] Personalized Learning, The MIT Press, 2021.
3007 [p37] [6]. B. Williamson, Big Data in Education: The Digital
3008 [p37] Future of Learning, Policy and Practice, 1 st Ed., SAGE
3009 [p37] Publications, 2017.
3010 [p38] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3011 [p38] 25-27 November 2025, Innsbruck, Austria
3012 [p38] 37
3013 [p38] [7]. R. Benjamin, Race Aft er Technology: Abolitionist
3014 [p38] Tools for the New Jim Code, Polity Press, 2019.
3015 [p38] [8]. S. U. Noble, Algorithms of Oppression: How Search
3016 [p38] Engines Reinforce Racism, New York University Press,
3017 [p38] 2018.
3018 [p38] [ 9 ] .  T .  M .  C o t t o m ,  L o w e r  E d :  T h e  T r o u b l i n g  R i s e  o f
3019 [p38] For-Profit Colleges in the New Economy, The New
3020 [p38] Press, 2017.
3021 [p38] [10]. P. Bisht, Decolonizing futures: exploring storytelling as
3022 [p38] a tool for inclusion in for esight, Master‚Äôs Thesis,
3023 [p38] OCAD University, 2017.
3024 [p38] [11]. N. Estes, Our History Is the Future: Standing Rock
3025 [p38] Versus the Dakota Access Pipeline, and the Long
3026 [p38] Tradition of Indigenous Resistance, Verso Books, 2019.
3027 [p38] [12]. b. hooks, Teaching to Tra nsgress: Education as the
3028 [p38] Practice of Freedom, Routledge, 1994.
3029 [p38] [13]. P. Freire, Pedagogy of the oppressed, in Toward a Just
3030 [p38] World Order, Vol. 1, Routledge, 2019, pp. 47-54.
3031 [p38] [14]. S. Canagarajah, Translingual Practice: Global
3032 [p38] Englishes and Cosmopolitan Relations, Routledge,
3033 [p38] 2012.
3034 [p38] [15]. O. Garcia, L. Wei,  Translanguaging: Language,
3035 [p38] Bilingualism and Education, 1 st E d . ,  Palgrave
3036 [p38] Macmillan, 2014.
3037 [p38] [16]. K. Crenshaw, Mapping the margins: intersectionality,
3038 [p38] identity politics, and violence against women of color,
3039 [p38] Stanford Law Review , Vol. 43, Issue 6, 1991,
3040 [p38] pp. 1241-1299.
3041 [p38] [17]. W. D. Mignolo, The Darker Side of Western
3042 [p38] Modernity: Global Futures, Decolonial Options, Duke
3043 [p38] University Press, 2011.
3044 [p38] [18]. M. Lugones, Heterosexualism and the colonial/modern
3045 [p38] gender system, Hypatia, Vol. 22, Issue 1, 2007,
3046 [p38] pp. 186-209.
3047 [p38] [19]. L. T. Smith, Decolonizing Methodologies: Research
3048 [p38] and Indigenous Peoples, 3rd Ed., Zed Books, 2021.
3049 [p38] [20]. E. Tuck, K. W. Yang, Decolonization is not a metaphor,
3050 [p38] Decolonization: Indigeneity, Education & Society ,
3051 [p38] Vol. 1, Issue 1, 2012, pp. 1-40.
3052 [p38] [21]. E. Tuck, M. McKenzie, Place in Research: Theory,
3053 [p38] Methodology, and Methods, Routledge, 2015.
3054 [p38] [22]. A. E. Garcia Quintana, C. A. Nichols, Code switching
3055 [p38] and the Hispanic consumer: the effects of acculturation
3056 [p38] on the language of advertising among Hispanics,
3057 [p38] Hispanic Journal of Behavioral Sciences , Vol. 38,
3058 [p38] Issue 2, 2016, pp. 222-242.
3059 [p38] [23]. P. Krawec, Becoming Ki n: An Indigenous Call to
3060 [p38] Unforgetting the Past and Reimagining Our Future,
3061 [p38] Broadleaf Books, 2022.
3062 [p38] [24]. G. Anzald√∫a, Borderlands = La Frontera: The New
3063 [p38] Mestiza, Critical ed. (R. F. Vivancos-P√©rez,
3064 [p38] N. E. Cant√∫, Eds.), Aunt Lute Books, 2021.
3065 [p38] [25]. N. wa Thiong'o, Something Torn and New: An African
3066 [p38] Renaissance, 1st Ed., BasicCivitas Books, 2009.
3067 [p38] [26]. G. J. S. Dei, Reframing Blackness and Black
3068 [p38] Solidarities Through Anti-Co lonial and Decolonial
3069 [p38] Prisms, Springer, 2017.
3070 [p38] [27]. A. S. Canagarajah, Tea cher development in a global
3071 [p38] profession: an autoethnography, TESOL Quarterly ,
3072 [p38] Vol. 46, Issue 2, 2012, pp. 258-279.
3073 [p38] [28]. D. Dippold, M. Heron,  K. Gravett, International
3074 [p38] students‚Äô linguistic transitions into disciplinary studies:
3075 [p38] a rhizomatic perspective, Higher Education, Vol. 83,
3076 [p38] Issue 3, 2022, pp. 527-545.
3077 [p38] [29]. G. Pennycook, Z. Epstein, M. Mosleh, A. A. Arechar,
3078 [p38] et al., Shifting attention to accuracy can reduce
3079 [p38] misinformation online, Nature, Vol. 592, 2021,
3080 [p38] pp. 590-595.
3081 [p38] [ 3 0 ] .  N .  F l o r e s ,  J .  R o s a ,  Undoing appropriateness:
3082 [p38] raciolinguistic ideologies a nd language diversity in
3083 [p38] education, Harvard Educational Review , Vol. 85,
3084 [p38] Issue 2, 2015, pp. 149-171.
3085 [p38] [31]. E. Sporrong, C. McGrath, T. Cerratto Pargman,
3086 [p38] Situating AI in assessment ‚Äì an exploration of
3087 [p38] university teachers‚Äô valuing practices, AI & ETHICS ,
3088 [p38] Vol. 5, Issue 3, 2025, pp. 2381-2394.
3089 [p38] [32]. F. Guo, L. Zhang, T. Shi, H. Coates, Whether and when
3090 [p38] could generative AI improve  college student learning
3091 [p38] engagement?, Behavioral Sciences ,  V o l .  1 5 ,  I s s u e  8 ,
3092 [p38] 2025, 1011.
3093 [p38] [33]. M. Liu, Y. Ren, L. M. Nyagoga, F. Stonier, et al.,
3094 [p38] Future of education in the era of generative artificial
3095 [p38] intelligence: consensus am ong Chinese scholars on
3096 [p38] applications of ChatGPT in schools, Future in
3097 [p38] Educational Research , Vol. 1, Issue 1, 2023,
3098 [p38] pp. 72-101.
3099 [p38] [34]. J. Kim, S. Yu, R. Detric k, N. Li, Exploring students‚Äô
3100 [p38] perspectives on generative AI-assisted academic
3101 [p38] writing, Education and Information Technologies ,
3102 [p38] Vol. 30, Issue 1, 2025, pp. 1265-1300.
3103 [p38] [35]. M. Scardamalia, Collective cognitive responsibility for
3104 [p38] the advancement of knowledge, in Liberal Education in
3105 [p38] a Knowledge Society (B. Smith, Ed.), Open Court
3106 [p38] ,
3107 [p38] 2002, pp. 67-98.
3108 [p38] [36]. C. I. Dam≈üa, P. A. Kirschner, J. E. B. Andriessen,
3109 [p38] G. Erkens, et al., Shared epistemic agency: an empirical
3110 [p38] study of an emergent construct, The Journal of the
3111 [p38] Learning Sciences, Vol. 19, Issue 2, 2010, pp. 143-186.
3112 [p39] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3113 [p39] 25-27 November 2025, Innsbruck, Austria
3114 [p39] 38
3115 [p39] (016)
3116 [p39] Enhancing Network Intrusion Detection Using Advanced Meta-learning
3117 [p39] Ensemble SVMs in Production Cloud Environments
3118 [p39] Lokesh Karanam 1 and Hardik Mahant 2
3119 [p39] 1 Independent Researcher, Austin, Texas, USA
3120 [p39] 2 Independent Researcher, San Jose, California, USA
3121 [p39] E-mail: lokeshkaranam3@gmail.com, hardik.s.mahant@gmail.com
3122 [p39] Summary: This paper offers an in-depth study of meta-learning ensemble Support Vector Machine (SVM) models orientated
3123 [p39] towards resolving the persistent problem of class imbalance in network intrusion detection systems. Modern intrusion detection
3124 [p39] systems face grave class imbalance problems in terms of detection for sophisticated, relatively scarce attacks like Remote-to-
3125 [p39] Local (R2L) and User-to-Root (U2R) which constitute less than o ne percent of network traffic, but wreak disproportionate
3126 [p39] havoc. To address the challenges posed by the detection of the minority class while keeping the computational cost manageable
3127 [p39] for real-world applications, we implemented and analyzed eight meta-learning ensemble SVM models: OneVsOne, Pairwise
3128 [p39] Meta, Enhanced Meta, Balanced Meta, and Focused Minority. Using  the NSL- KDD dataset which contains 125973 training
3129 [p39] samples and 22544 test samples, we were able to perform extensi ve experiments and our Focus ed Minority SVM ensemble
3130 [p39] outperformed other models achieving 77.52 % accuracy, an improv ement of 3.5 % over traditional OneVsOne SVMs. With
3131 [p39] these models, we were able to achieve detection rates ranging f rom 0.5 % to 10.3 % for R2L and 9 % to 14.9 % for U2R
3132 [p39] attacks. The study offers new meta- learning frameworks incorpo rating class imbalance adaptive strategies, weighted binary
3133 [p39] classifiers, and probabilistic feature enhancement and ensemble  voting mechanisms optimized for real-time production
3134 [p39] deployment, enabling security operations centers to maintain effective intrusion detection with manageable false positive rates
3135 [p39] in high-traffic enterprise networks.
3136 [p39] Keywords: Intrusion detection, Support vector machines, Meta-learning, Ensemble methods, Class imbalance, Cybersecurity.
3137 [p39] 1. Introduction
3138 [p39] The weaponization of artificial intelligence and the
3139 [p39] growing interconnectedness of digital ecosystems have
3140 [p39] led to an unprecedented evolution in cyberattacks.
3141 [p39] With AI-generated phishing emails achieving a 78 %
3142 [p39] open rate and a 202 % increase in phishing email
3143 [p39] messages, modern threat actors are using generative AI
3144 [p39] technologies to craft more convincing phishing
3145 [p39] campaigns [1]. Ransomware threat landscape has
3146 [p39] grown dramatically, with attacks rising by 11 % in
3147 [p39] 2024 to 5414 reported incidents globally [2]. Supply
3148 [p39] chain attacks have become a particularly destructive
3149 [p39] attack vector, increasing by 431 % between 2021 and
3150 [p39] 2023. The post-pandemic digital transformation has
3151 [p39] further exacerbated this escalating threat environment,
3152 [p39] with 80 % of organizations worldwide experiencing
3153 [p39] cloud security breaches and cyberattacks more than
3154 [p39] doubling in frequency [3]. Financial institutions are
3155 [p39] especially vulnerable, acco unting for 45 % of attacks
3156 [p39] on critical infrastructure and paying an average of
3157 [p39] $4.4 million for data breaches.
3158 [p39] Traditional intrusion detection systems are
3159 [p39] seriously flawed, with only 17 % prevention rates
3160 [p39] against sophisticated r ansomware threats and
3161 [p39] inadequate detection of minority class attacks. Class
3162 [p39] imbalance problems in network traffic data further
3163 [p39] complicate the problem. Conventional machine
3164 [p39] learning techniques, such as standard Support Vector
3165 [p39] Machines, encounter challenges in defining precise
3166 [p39] decision boundaries for these sparsely represented
3167 [p39] attack categories, leading to elevated false negative
3168 [p39] rates for significant threats. This study addresses
3169 [p39] significant constraints by proposing and evaluating
3170 [p39] advanced meta-learning ensemble SVM frameworks
3171 [p39] specifically designed for minority class detection
3172 [p39] within real-time production cloud systems [5] that
3173 [p39] incorporate multiple specialized models utilizing
3174 [p39] diverse kernels, adaptive class weighting techniques,
3175 [p39] and probabilistic feature augmentation strategies. This
3176 [p39] approach establishes a ne twork of specialized
3177 [p39] classifiers that engage in knowledge exchange via
3178 [p39] ensemble voting mechanisms, leveraging the
3179 [p39] collaborative potential of multiple SVM models to
3180 [p39] identify attack patterns overlooked by traditional
3181 [p39] single-model methodologies.
3182 [p39] 2. Literature Review
3183 [p39] 2.1. Traditional Machine Learning Approaches
3184 [p39] in Intrusion Detection
3185 [p39] Over the past decade, there has been significant
3186 [p39] progress in the use of machine learning techniques for
3187 [p39] network intrusion detection [6], with Support Vector
3188 [p39] Machines being identified as  a particularly successful
3189 [p39] approach for binary and multiclass classification
3190 [p39] problems. The study by Chowdhury et al [7]
3191 [p39] demonstrated the effectiveness of SVM-based
3192 [p39] techniques using randomly generated feature sets,
3193 [p39] achieving acceptable results  on known datasets and
3194 [p39] highlighting the critical function of feature selection in
3195 [p39] intrusion detection. However, their approach had
3196 [p39] limitations when dealing with issues of class
3197 [p39] imbalance, particularly when it came to determining
3198 [p40] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3199 [p40] 25-27 November 2025, Innsbruck, Austria
3200 [p40] 39
3201 [p40] which advanced minority class attacks presented the
3202 [p40] biggest security threats in operational environments.
3203 [p40] Scholars have studied a variety of dimensionality
3204 [p40] reduction techniques to im prove classifier efficacy in
3205 [p40] order to address the fundamental problem of feature
3206 [p40] selection in intrusion detection [8]. In their study,
3207 [p40] Alijawarneh et al [9] presented hybrid models that
3208 [p40] combine Decision Trees, Naive Bayes, and other
3209 [p40] traditional approaches, demonstrating the
3210 [p40] effectiveness of ensemble approaches and reducing the
3211 [p40] number of features from 41 to 8. Despite these
3212 [p40] developments, traditional approaches continue to
3213 [p40] encounter difficulties with the large class imbalance in
3214 [p40] real-world network traffic data, where minority attack
3215 [p40] types are routinely underrepresented in training
3216 [p40] datasets. Automated Machine Learning (AutoML)
3217 [p40] techniques have demonstrat ed potential for lowering
3218 [p40] manual overhead while attaining better performance.
3219 [p40] Gyimah et al. showed that AutoML-driven stacked
3220 [p40] ensemble models outperformed individual models
3221 [p40] such as Random Forest and conventional boosting
3222 [p40] techniques, achieving 90  % accuracy and 89 % F1
3223 [p40] score on the NSL-KDD dataset [10].
3224 [p40] In intrusion detection syst ems, the preprocessing
3225 [p40] stage is acknowledged as a crucial component that
3226 [p40] affects the system‚Äôs overall performance. Traditional
3227 [p40] approaches tend to focus on feature normalization,
3228 [p40] categorical encoding, and simple sampling, but they do
3229 [p40] not address the fundamental issues of minority class
3230 [p40] detection. Recent studies [11] have highlighted the
3231 [p40] limitations of conventional preprocessing methods
3232 [p40] when dealing with extremely unbalanced datasets,
3233 [p40] especially when minority classes such as R2L and U2R
3234 [p40] attacks require customized  strategies to achieve
3235 [p40] acceptable detection rates.
3236 [p40] 2.2. Deep Learning and Neural Network
3237 [p40] Approaches
3238 [p40] The advent of deep learning techniques has opened
3239 [p40] up novel avenues for intrusion detection, with
3240 [p40] Convolutional Neural Networks (CNNs) and Long
3241 [p40] Short-Term Memory (LSTM) networks demonstrating
3242 [p40] encouraging outcomes across a range of cybersecurity
3243 [p40] applications. The work by Karanam et al [12]
3244 [p40] introduced a hybrid architecture combining CNN and
3245 [p40] LSTM, which attained a training accuracy of 99.6 %
3246 [p40] and a testing accuracy of 89.23 % on the NSL-KDD
3247 [p40] dataset, thereby illustrating the efficacy of deep
3248 [p40] learning methodologies in the domain of intrusion
3249 [p40] detection. Their methodology focused on enhancing
3250 [p40] computational efficiency through the conversion of
3251 [p40] feature vectors into matrix representations that are
3252 [p40] appropriate for convolutional processing, thereby
3253 [p40] significantly decreasing bo th parameter count and
3254 [p40] training duration. Recent methods like TG-LSTM [13]
3255 [p40] leverages temporal prediction and customized deep
3256 [p40] learning architectures to improve minority event
3257 [p40] detection accuracy in imbalanced datasets. Recent
3258 [p40] studies have demonstrated that GNN-based
3259 [p40] approaches achieve 98 % accuracy for binary
3260 [p40] classification and 99.20 % for multi-class
3261 [p40] classification by modeling network flows as graph
3262 [p40] structures [14]. GNNs are an emerging paradigm that
3263 [p40] captures structural relationships in network data. With
3264 [p40] attention mechanisms that successfully capture
3265 [p40] temporal dependencies in network traffic patterns,
3266 [p40] transformer architectures  derived from natural
3267 [p40] language processing have shown remarkable ability in
3268 [p40] sequence modeling for cybe rsecurity applications,
3269 [p40] attaining 96 % accuracy in zero-day threat
3270 [p40] detection [15].
3271 [p40] Nonetheless, deep learning methods [16] encounter
3272 [p40] numerous significant constraints when implemented in
3273 [p40] production settings for intrusion detection. The
3274 [p40] computational complexity associated with training and
3275 [p40] inference operations frequently surpasses the real-time
3276 [p40] demands of production systems, where response times
3277 [p40] under 100 milliseconds are critical for effective threat
3278 [p40] mitigation. Furthermore, deep learning models
3279 [p40] generally necessitate a substantial amount of training
3280 [p40] data to attain peak performance, which may be lacking
3281 [p40] for minority attack classes in practical situations.
3282 [p40] One significant limitation of deep learning
3283 [p40] approaches in the fiel d of cybersecurity is
3284 [p40] interpretability. Particularly in crucial circumstances
3285 [p40] involving possible security incidents, production
3286 [p40] security systems require transparent decision-making
3287 [p40] procedures that enable security analysts to understand
3288 [p40] and validate detection results. This requirement is
3289 [p40] complicated by the opaque  nature of deep neural
3290 [p40] networks, which makes it difficult for security teams
3291 [p40] to respond to and trust automated detection results.
3292 [p40] 2.3. Ensemble Methods and Meta-learning
3293 [p40] in Cybersecurity
3294 [p40] Ensemble learning techniques, which combine
3295 [p40] multiple specialized models, have gained attention in
3296 [p40] cybersecurity research for improving detection
3297 [p40] effectiveness. Traditional ensemble methods, like
3298 [p40] bagging, boosting, and stacking, have been used to
3299 [p40] address class imbalance pr oblems, but most focus on
3300 [p40] homogeneous base learners. Meta-learning, or
3301 [p40] "learning to learn," is a revolutionary departure from
3302 [p40] traditional machine learni ng techniques, allowing
3303 [p40] systems to adapt their learning strategies based on past
3304 [p40] experiences. It can address inadequate training data for
3305 [p40] minority attack classes in intrusion detection. Recent
3306 [p40] studies [17] have shown improved performance in
3307 [p40] few-shot learning scenarios where traditional
3308 [p40] approaches face data s carcity. Combining
3309 [p40] meta-learning concepts with ensemble approaches can
3310 [p40] create robust detection systems that learn from a small
3311 [p40] number of examples while maintaining high accuracy.
3312 [p40] 2.4. Class Imbalance and Minority Class Detection
3313 [p40] Class imbalance in machin e learning applications
3314 [p40] in cybersecurity is a significant issue. Traditional
3315 [p40] methods like cost sensitiv e learning frameworks,
3316 [p41] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3317 [p41] 25-27 November 2025, Innsbruck, Austria
3318 [p41] 40
3319 [p41] undersampling techniques, and SMOTE struggle to
3320 [p41] address complex, dynamic  p a t t e r n s  i n  i n t r u s i o n
3321 [p41] detection environments. SMOTE can increase recall
3322 [p41] rates but introduces noise and overfitting issues.
3323 [p41] Cost-sensitive learning app roaches distribute higher
3324 [p41] misclassification costs to minority classes during
3325 [p41] training, showing promise in cybersecurity. However,
3326 [p41] finding the best cost matrices is challenging in
3327 [p41] dynamic environments with varying attack patterns.
3328 [p41] 2.5. Research Gap and Motivation
3329 [p41] Despite extensive research into machine learning
3330 [p41] methods for intrusion detection, there are still
3331 [p41] significant challenges in minority class detection.
3332 [p41] Traditional single-model or homogeneous ensemble
3333 [p41] approaches fail to leverag e the unique advantages of
3334 [p41] different classifier architectures. Real-time production
3335 [p41] environments require response times of less than
3336 [p41] 100 milliseconds for effective threat mitigation.
3337 [p41] Current research has mainly focused on static
3338 [p41] benchmark datasets, neglecting the dynamic nature of
3339 [p41] network environments. To overcome these limitations,
3340 [p41] meta-learning concepts can be combined with
3341 [p41] specialized ensemble arch itectures, but careful
3342 [p41] planning and evaluation are needed. Advanced
3343 [p41] meta-learning ensemble SVM frameworks are being
3344 [p41] developed to address these gaps.
3345 [p41] 2.6. Traditional SVM and Ensemble Methods
3346 [p41] SVMs excel at binary and multi-class classification
3347 [p41] [18, 7], but challenge in multiclass, imbalanced data.
3348 [p41] Prior works include a hierarchical SVM ensemble for
3349 [p41] image classification [19], and hybrid models for
3350 [p41] network security [9].
3351 [p41] Deep learning (CNN-LSTM hybrids) improves
3352 [p41] detection but incurs high computational cost and lacks
3353 [p41] explainability [12]. Meta-learning, combining multiple
3354 [p41] specialized models, is emerging for rare-class
3355 [p41] detection and incrementa l adaptation [20]. Recent
3356 [p41] ensemble SVMs outperform single SVMs for both
3357 [p41] tabular and structured data tasks [19].
3358 [p41] 2.7. Class Imbalance Techniques
3359 [p41] Imbalanced learning handles rare events by
3360 [p41] balancing training samples or weighting classes [21].
3361 [p41] Methods include SMOTE oversampling, cost-sensitive
3362 [p41] loss, and ensemble stacking. Recent research optimizes
3363 [p41] SVM hyperparameters and feature sets hierarchically
3364 [p41] for minority class gain [19].
3365 [p41] 3. Methodology
3366 [p41] 3.1. Dataset Description and Preprocessing
3367 [p41] The NSL-KDD [4, 22] dataset, an improved
3368 [p41] version of the KDD Cup 1999 dataset, was used in an
3369 [p41] experimental evaluation to overcome the drawbacks of
3370 [p41] earlier intrusion detection benchmarks. The dataset
3371 [p41] provides a more balanced depiction of network traffic
3372 [p41] patterns, eliminating redundant records and dividing
3373 [p41] each connection record into traffic-based,
3374 [p41] content-based, and basic features. The dataset
3375 [p41] comprises 22544 testing samples and 125973 training
3376 [p41] samples. The dataset's stark class imbalance reflects
3377 [p41] real network traffic distributions, with malicious
3378 [p41] activity frequency significantly lower than normal
3379 [p41] connections. The training dataset includes
3380 [p41] 45927 Denial of Service (DoS) attacks (36.46 %) and
3381 [p41] 67343 normal connections (53.46 %). The significant
3382 [p41] difference between R2L and U2R attack categories
3383 [p41] presents challenges for traditional machine learning
3384 [p41] methods and emphasizes the need for customized
3385 [p41] ensemble approaches [23]. A comprehensive
3386 [p41] methodology for feature engineering and data
3387 [p41] standardization was used in the preprocessing pipeline,
3388 [p41] ensuring consistency between training and testing
3389 [p41] datasets. StandardScaler normalization was used to
3390 [p41] standardize features, improving the convergence
3391 [p41] characteristics of Support Vector Machine-based
3392 [p41] classifiers. Normal traffic was classified as class 0,
3393 [p41] DoS attacks as class 1, probe attacks as class 2, R2L
3394 [p41] attacks as class 3, and U2R attacks as class 4.
3395 [p41] 3.2. Meta-learning Ensemble Architecture Design
3396 [p41] The proposed meta-learni ng ensemble framework
3397 [p41] (Fig. 1) integrates several specialized binary
3398 [p41] classifiers, which are ama lgamated through advanced
3399 [p41] voting mechanisms to tackle the challenges associated
3400 [p41] with minority class detection. The architecture is
3401 [p41] composed of three fundamental components: the
3402 [p41] generation of specialized binary classifiers, the
3403 [p41] enhancement of probabilistic features, and the fusion
3404 [p41] of ensemble decisions. This hierarchical methodology
3405 [p41] facilitates the system‚Äôs ability to discern optimal
3406 [p41] decision boundaries for succ essive class pairs, while
3407 [p41] utilizing meta-learned features to enhance overall
3408 [p41] classification accuracy.
3409 [p41] The process of developing binary classifiers
3410 [p41] (Fig. 2) entails building customized support vector
3411 [p41] machine models that are trained on various class
3412 [p41] combinations. Several kernel functions are used in this
3413 [p41] procedure, and hyperparameter configurations
3414 [p41] customized for each distinct  classification task are
3415 [p41] optimized. Depending on the complexity of the
3416 [p41] decision boundary required to differentiate the specific
3417 [p41] class combination, a binary SVM classifier is
3418 [p41] constructed using RBF, polynomial, or linear kernels
3419 [p41] for each successive class pair (i, j). The rationale
3420 [p41] behind this approach stems from the understanding
3421 [p41] that different kinds of attacks exhibit distinct feature
3422 [p41] patterns that might be better captured by specialized
3423 [p41] classifiers rather than depending on a single
3424 [p41] multi-class model.
3425 [p41] The probabilistic feature enhancement component
3426 [p41] utilizes the outputs of decision functions from binary
3427 [p41] classifiers to create supple mentary features for the
3428 [p41] ultimate ensemble classifier. For every binary
3429 [p42] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3430 [p42] 25-27 November 2025, Innsbruck, Austria
3431 [p42] 41
3432 [p42] classifier developed for the class pair (i, j),
3433 [p42] probabilistic estimates are derived through the
3434 [p42] application of the sigmoid function to the decision
3435 [p42] function values, thereby offering confidence measures
3436 [p42] regarding class membership predictions. The
3437 [p42] probabilistic features are integrated with the original
3438 [p42] feature vectors to form improved representations that
3439 [p42] encompass both fundamental network statistics and
3440 [p42] derived classification confidence measures.
3441 [p42] Fig. 1. Detailed Architecture of Meta SVM.
3442 [p42] 3.3. Adaptive Class Weighting Mechanisms
3443 [p42] The suggested framework uses adaptive class
3444 [p42] weighting mechanisms that give minority classes more
3445 [p42] weight during training in order to address the notable
3446 [p42] class imbalance seen in intrusion detection datasets.
3447 [p42] Inverse frequency weighting and additional penalties
3448 [p42] for critical minority classes are incorporated into the
3449 [p42] weighting strategy to ensure that the learning
3450 [p42] algorithm gives underrepre sented attack categories
3451 [p43] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3452 [p43] 25-27 November 2025, Innsbruck, Austria
3453 [p43] 42
3454 [p43] enough attention. The calculation of class weight
3455 [p43] adheres to the established formula:
3456 [p43] classes i
3457 [p43] i
3458 [p43] tt a l
3459 [p43] i
3460 [p43] o
3461 [p43] w nn
3462 [p43] n ÔÅ°ÔÄΩÔÇ¥ ÔÇ¥
3463 [p43] The adaptive weighting mechanism integrates
3464 [p43] specialized knowledge regar ding the significance of
3465 [p43] various attack types within production environments.
3466 [p43] R2L and U2R attacks, although infrequent, are
3467 [p43] assigned considerably greater weights ( Œ± = 25.0) in
3468 [p43] comparison to normal traffic and more prevalent attack
3469 [p43] types (Œ± = 1.0). This weighting strategy illustrates the
3470 [p43] significant influence of advanced attacks on
3471 [p43] organizational security and guarantees that the
3472 [p43] ensemble system emphasizes the precise identification
3473 [p43] of essential threats.
3474 [p43] (a) Two-class SVMs                             (b) SVM ensemble training
3475 [p43] (c) SVM ensemble testing
3476 [p43] Fig. 2. Training and Testing Algorithm for the proposed SVM ensemble for intrusion detection.
3477 [p43] 3.4. Specialized Ensemble Configurations
3478 [p43] In order to address different aspects of the minority
3479 [p43] class detection problem, this paper investigates eight
3480 [p43] distinct ensemble configurations. Using pairwise
3481 [p43] binary classifiers, the OneVsOne baseline setup uses
3482 [p43] traditional multi-class SVM without any meta-learning
3483 [p43] improvements.
3484 [p43] By training binary classifiers on successive class
3485 [p43] pairs and then using their outputs as additional features
3486 [p43] for the final classifier, the Pairwise Meta configuration
3487 [p43] uses a probabilistic approach to feature enhancement.
3488 [p43] The Balanced Meta configuration ensures equal
3489 [p43] significance for each class  in binary classifiers,
3490 [p43] regardless of their commonness in the training dataset.
3491 [p43] The Enhanced Meta configuration applies customized
3492 [p44] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3493 [p44] 25-27 November 2025, Innsbruck, Austria
3494 [p44] 43
3495 [p44] hyperparameter settings for minority classes, using
3496 [p44] polynomial kernels and higher regularization
3497 [p44] parameters. The Focused Minority configuration
3498 [p44] focuses on detecting R2L and U2R attacks. The
3499 [p44] Advanced Minority configuration integrates targeted
3500 [p44] feature engineering, kernel functions, and optimized
3501 [p44] weighted voting mechanisms for minority class
3502 [p44] detection. The Cost-Sensitive setup adds additional
3503 [p44] penalties for minority classes to adaptive class weights.
3504 [p44] The Hybrid Ensemble configuration combines
3505 [p44] multiple specialized classifi ers using different kernel
3506 [p44] functions and training techniques.
3507 [p44] 3.5. Performance Evaluation Framework
3508 [p44] The experimental evaluation framework evaluates
3509 [p44] performance in imbalanced  classification scenarios
3510 [p44] using precision, recall, and F1-score calculations for
3511 [p44] individual classes. It focuses on recall rates for R2L
3512 [p44] and U2R attack types, which are the most challenging
3513 [p44] detection problems in operational environments.
3514 [p44] Measurements are made on standardized hardware
3515 [p44] configurations for reproducibility, and the analysis of
3516 [p44] training time provides insights into computational
3517 [p44] efficiency. The framework also includes an analysis of
3518 [p44] the confusion matrix to identify misclassification
3519 [p44] patterns and tradeoffs between false positive and false
3520 [p44] negative rates across different attack categories.
3521 [p44] Cross-validation techniques are employed for accurate
3522 [p44] performance evaluations.
3523 [p44] Preprocessing steps:
3524 [p44] ÔÇ∑ Label encode categorical features (protocol_type,
3525 [p44] service, flag);
3526 [p44] ÔÇ∑ Standardize numeric features with zero mean,
3527 [p44] unit variance;
3528 [p44] ÔÇ∑ Map attack names to integer classes.
3529 [p44] 3.6. Ensemble SVM Approaches
3530 [p44] We implemented and benchmarked the following
3531 [p44] architectures:
3532 [p44] ÔÇ∑ OneVsOne SVM: Classic multiclass SVM with
3533 [p44] RBF kernel;
3534 [p44] ÔÇ∑ Pairwise Meta SVM: Train binary SVM for all
3535 [p44] class pairs; merge outputs as meta-features;
3536 [p44] ÔÇ∑ Balanced Meta SVM: A s above, but with
3537 [p44] class-weight balancing in all SVMs;
3538 [p44] ÔÇ∑ Enhanced Meta SVM: Use polynomial or RBF
3539 [p44] kernels and high penalty for minority class
3540 [p44] boundaries;
3541 [p44] ÔÇ∑ Focused Minority SVM: Add explicit minority-
3542 [p44] vs-all classifiers, supplementing original
3543 [p44] features.
3544 [p44] ÔÇ∑ Advanced Minority/Heterogeneous Ensemble:
3545 [p44] Stack feature/kernels, diverse class weights, and
3546 [p44] weighted voting across SVMs;
3547 [p44] ÔÇ∑ Hybrid Ensemble SVM: Combine SMOTE,
3548 [p44] varied kernel SVMs, and weighted soft voting in
3549 [p44] a layered ensemble.
3550 [p44] 4. Experimental Results and Discussion
3551 [p44] 4.1. Comparative Performance Analysis
3552 [p44] The study reveals significant performance gains in
3553 [p44] meta-learning ensemble approaches compared to
3554 [p44] traditional single-model configurations. The Focused
3555 [p44] Minority SVM outperformed the OneVsOne baseline
3556 [p44] by 3.5 %, achieving an accuracy of 77.52 %. The
3557 [p44] Enhanced Meta SVM configuration showed an ideal
3558 [p44] balance between accura cy and computational
3559 [p44] efficiency, with a training time of 97.24 seconds. The
3560 [p44] Balanced Meta configuration achieved 81.85 %
3561 [p44] precision, compared to 78 .53 % (Table I) for the
3562 [p44] baseline OneVsOne method. The Focused Minority
3563 [p44] SVM showed the fastest training time and highest
3564 [p44] accuracy, indicating effici ency gains from minority
3565 [p44] class optimization.
3566 [p44] 4.2. Minority Class Detection Performance
3567 [p44] Meta-learning ensemble strategies have shown
3568 [p44] significant improvements in minority class detection
3569 [p44] performance, particularly in R2L attack detection. The
3570 [p44] Focused Minority SVM improved the recall rate for
3571 [p44] R2L detection to 10.3 %, while U2R attack detection
3572 [p44] saw a 20-fold increase from 9.0 % to 14.9 %. These
3573 [p44] improvements show progress in minority class
3574 [p44] detection in real-world production environments. The
3575 [p44] precision-recall trade-off analysis shows that ensemble
3576 [p44] methods achieve a more favorable equilibrium
3577 [p44] between false positives and false negatives rates. The
3578 [p44] Enhanced Meta configuration achieved a precision of
3579 [p44] 72 % for R2L detection, but also showed enhanced
3580 [p44] recall performance, making the minor reduction in
3581 [p44] precision justifiable for practical applications. This
3582 [p44] trade-off highlights the importance of detecting critical
3583 [p44] attacks in production security contexts.
3584 [p44] 4.3. Feature Enhancement Impact Analysis
3585 [p44] The probabilistic feature enhancement mechanism
3586 [p44] significantly improves meta-learning ensemble
3587 [p44] methods' performance. It is highly discriminative for
3588 [p44] detecting minority classes and yields significant
3589 [p44] confidence measures, aiding the final ensemble
3590 [p44] classifier in making in formed decisions. The
3591 [p44] effectiveness of feature enhancement varies across
3592 [p44] attack categories, with R2L and U2R detection
3593 [p44] showing the most significant advantages. This aligns
3594 [p44] with the theory that intricate and infrequent attack
3595 [p44] patterns require diverse per spectives and confidence
3596 [p44] assessments. Cross-validation analysis confirms the
3597 [p44] reliability of feature enhancements across various data
3598 [p44] divisions, and the uniformity of enhancements across
3599 [p44] various assessment metrics supports the effectiveness
3600 [p44] of the proposed meta-learning methodology.
3601 [p44] 4.4. Computational Efficiency and Scalability
3602 [p44] Metalearning ensemble methods improve
3603 [p44] performance while maintaini ng practical training and
3604 [p45] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3605 [p45] 25-27 November 2025, Innsbruck, Austria
3606 [p45] 44
3607 [p45] inference durations for production environments. The
3608 [p45] optimal configuration, Focused Minority SVM, takes
3609 [p45] only 90.58 seconds for training on the NSL-KDD
3610 [p45] dataset. Although larger ensemble configurations
3611 [p45] require more memory, performance improvements are
3612 [p45] significant. Ensemble predictions can be generated in
3613 [p45] 5-10 milliseconds per sample, aligning with real-time
3614 [p45] intrusion detection systems.
3615 [p45] 4.5. Statistical Significance and Robustness
3616 [p45] Analysis
3617 [p45] The study uses paired t-tests to test the performance
3618 [p45] enhancements of meta-learning ensemble
3619 [p45] methodologies. The results show statistical
3620 [p45] significance at p < 0.01 confidence levels, and the
3621 [p45] uniformity of enhancements across different train/test
3622 [p45] splits supports their reliability. Bootstrap resampling
3623 [p45] with 1000 iterations yields confidence intervals for
3624 [p45] performance metrics, with the Focused Minority SVM
3625 [p45] showing a 95 % confidence interval from 76.8 % to
3626 [p45] 78.2 %, indicating consistent performance attributes
3627 [p45] suitable for production deployment. The robustness of
3628 [p45] ensemble methodologies is also examined, revealing
3629 [p45] performance advantages despite a decline in input data
3630 [p45] quality. This robustness is crucial in production
3631 [p45] security environments where network monitoring
3632 [p45] systems may face intermittent data quality challenges.
3633 [p45] Table 1. Summary: SVM Variant Performance
3634 [p45] on NSL-KDD Test Set.
3635 [p45] Method Acc. Prec. Recall F1
3636 [p45] OneVsOne 0.749 0.785 0.749 0.701
3637 [p45] Pairwise Meta 0.751 0.801 0.751 0.704
3638 [p45] Balanced Meta 0.754 0.819 0.754 0.726
3639 [p45] Enhanced Meta 0.768 0.787 0.768 0.730
3640 [p45] Focused Minority 0.775 0.794 0.775 0.742
3641 [p45] 4.6. Minority Class Improvement
3642 [p45] The Focused Minority SVM increased the recall of
3643 [p45] R2L from 0. 5 % to 10. 3 % and U2R from 9.0 % to
3644 [p45] 14.9 % over the OneVsOne baseline, demonstrating a
3645 [p45] 20√ó and 65 % improvement, respectively (Fig. 3).
3646 [p45] Fig. 3. Minority class detection improvement showing significant enhancement in R2L and U2R attack detection
3647 [p45] through meta-learning SVM ensemble approaches.
3648 [p45] 4.7. Training Time and Scalability
3649 [p45] The Enhanced Meta SVM re quired only 97.2 s to
3650 [p45] train (Table 2), making regular retraining feasible.
3651 [p45] F o c u s e d  M i n o r i t y  S V M  w a s  f a s t e s t  ( 9 0 . 6  s ) .  T h e
3652 [p45] Balanced Meta, while more intensive, offered
3653 [p45] improved precision at higher computational cost.
3654 [p45] 4.8. Feature Importance and Robustness
3655 [p45] Meta-feature augmentation (pairwise probability
3656 [p45] outputs) consistently ranked high in feature
3657 [p45] importance. The improvements remained robust across
3658 [p45] multiple random seeds and dataset splits.
3659 [p45] Table 2. Training Time by Method.
3660 [p45] Method Time (sec)
3661 [p45] OneVsOne 165.3
3662 [p45] Balanced Meta 284.4
3663 [p45] Enhanced Meta 97.2
3664 [p45] Focused Minority 90.6
3665 [p46] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3666 [p46] 25-27 November 2025, Innsbruck, Austria
3667 [p46] 45
3668 [p46] Fig. 4. Confusion matrix: Focused Minority SVM on NSL-KDD test set.
3669 [p46] 5. Production Deployment Considerations
3670 [p46] 5.1. Real-time Performance Requirements
3671 [p46] The meta-learning ensemble SVM systems are
3672 [p46] being developed for production cybersecurity settings,
3673 [p46] aiming to handle thousands of connections per second
3674 [p46] and maintain response times below 100 milliseconds
3675 [p46] for effective threat mitigation. The proposed ensemble
3676 [p46] approaches have inference times averaging between
3677 [p46] 5 and 10 milliseconds for each classification decision.
3678 [p46] The ensemble models require 2.3 times the memory
3679 [p46] compared to single classifiers, a total of 150 MB for
3680 [p46] the entire model ensemble. The linear scaling
3681 [p46] properties ensure consistent memory demands as the
3682 [p46] model's complexity increases. The system's modular
3683 [p46] architecture allows for seamless integration with
3684 [p46] existing SIEM platforms and network monitoring
3685 [p46] frameworks. The probabilistic output mechanism
3686 [p46] allows security analysts to prioritize investigative
3687 [p46] efforts based on threat probability, particularly for
3688 [p46] minority classes with high false positive rates.
3689 [p46] 6. Conclusion
3690 [p46] The study demonstrates the potential of
3691 [p46] metalearning ensemble SVM frameworks in
3692 [p46] addressing class imbalance issues in network intrusion
3693 [p46] detection systems. Experimental evaluations on the
3694 [p46] NSL-KDD dataset showed significant enhancements
3695 [p46] in minority class detection, with the Focused Minority
3696 [p46] SVM configuration achieving an overall accuracy of
3697 [p46] 77.52 %. The study also introduced eight unique
3698 [p46] meta-learning ensemble architectures, adaptive class
3699 [p46] weighting strategies, and probabilistic feature
3700 [p46] enhancement methods. The probabilistic feature
3701 [p46] enhancement mechanism, which uses decision
3702 [p46] function outputs from specia lized binary classifiers,
3703 [p46] significantly improved the detection of complex attack
3704 [p46] types. The meta-learning ensemble methods are
3705 [p46] suitable for real-time production deployment, with the
3706 [p46] most efficient configuration requiring only
3707 [p46] 90.58 seconds for comprehensive model training.
3708 [p46] Future research should expand the framework to
3709 [p46] include supplementary datas ets and integrate with
3710 [p46] existing SIEM systems for better deployment
3711 [p46] challenges.
3712 [p46] References
3713 [p46] [1]. M. A. I. Mallick, R. Nath, Navigating the cyber security
3714 [p46] landscape: a comprehensive review of cyber-attacks,
3715 [p46] emerging trends, and recent developments, World
3716 [p46] Scientific News, Vol. 190, Issue 1, 2024, pp. 1-69.
3717 [p46] [2]. T. Zaid, S. Garai, Emerging trends in cybersecurity: a
3718 [p46] holistic view on current thr eats, assessing solutions,
3719 [p46] and pioneering new frontiers, Blockchain in Healthcare
3720 [p46] Today, Vol. 7, 2024.
3721 [p46] [3]. M. M. Nair, A. Deshm ukh, A. K. Tyagi, Artificial
3722 [p46] intelligence for cyber security: current trends and future
3723 [p46] challenges, in Automated Secure Computing for
3724 [p46] Next-Generation Systems, Wiley, 2024, pp. 83-114.
3725 [p46] [4]. G. M. ud din, NSL-KDD Dataset, Canadian Institute
3726 [p46] for Cybersecurity, 2018.
3727 [p46] [5]. H. Attou, A. Guezzaz, S. Benkirane, M. Azrour, et al.,
3728 [p46] Cloud-based intrusion detection approach using
3729 [p46] machine learning techniques, Big Data Mining and
3730 [p46] Analytics, Vol. 6, Issue 3, 2023, pp. 311-320.
3731 [p46] [6]. M. Zakariah, S. A. Al Qahtani, A. M. Alawwad,
3732 [p46] A. A. Alotaibi, Intrusi on detection system with
3733 [p46] customized machine learning techniques for
3734 [p46] NSL-KDD dataset, Computers, Materials & Continua,
3735 [p46] Vol. 77, Issue 3, 2023, 109406.
3736 [p47] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3737 [p47] 25-27 November 2025, Innsbruck, Austria
3738 [p47] 46
3739 [p47] [7]. M. N. Chowdhury, K. Ferens, M. Ferens, Network
3740 [p47] intrusion detection usi ng machine learning, in
3741 [p47] Proceedings of the International Conference on
3742 [p47] Security and Management (SAM‚Äô16), 2016, p. 30.
3743 [p47] [8]. K. A. Taher, B. M. Y. Jisan, M. M. Rahman, Network
3744 [p47] intrusion detection using supervised machine learning
3745 [p47] technique with feature selection, in Proceedings of the
3746 [p47] International Conference on Robotics, Electrical and
3747 [p47] Signal Processing Techniques (ICREST‚Äô19) , 2019,
3748 [p47] pp. 643-646.
3749 [p47] [9]. S. Aljawarneh, M. Aldwairi, M. B. Yassein, Anomaly-
3750 [p47] based intrusion detection system through feature
3751 [p47] selection analysis and building hybrid efficient model,
3752 [p47] Journal of Computational Science , Vol. 25, 2018,
3753 [p47] pp. 152-160.
3754 [p47] [10]. N. K. Gyimah, R. Akinie, J. Mwakalonge, B. Izison,
3755 [p47] et al., An automl-based approach for network intrusion
3756 [p47] detection, in Proceedings of the IEEE Region
3757 [p47] Technical, Professional, and Student Conference ,
3758 [p47] (SoutheastCon‚Äô25), 2025, pp. 1177-1183.
3759 [p47] [11]. S. Rastogi, A. Shrotriya, M. K. Singh, R. V. Potukuchi,
3760 [p47] An analysis of intrusion det ection classification using
3761 [p47] supervised machine learning algorithms on NSL-KDD
3762 [p47] dataset, Journal of Computing Research and
3763 [p47] Innovation, Vol. 7, Issue 1, 2022, pp. 124-137.
3764 [p47] [12]. L. Karanam, K. K. Pattanaik, R. Aldmour, Intrusion
3765 [p47] detection mechanism for large scale networks using
3766 [p47] CNN-LSTM, in Proceedings of the 13 th International
3767 [p47] Conference on Developments in eSystems Engineering
3768 [p47] (DeSE‚Äô20), 2020, pp. 323-328.
3769 [p47] [13]. L. Karanam, Continuous a nticipation of acute kidney
3770 [p47] injury in the ICU, Master‚Äôs Thesis, University of
3771 [p47] Missouri-Columbia, 2022.
3772 [p47] [14]. A. S. Ahanger, S. M. Khan, F. Masoodi, A. O. Salau,
3773 [p47] Advanced intrusion detection in internet of things using
3774 [p47] graph attention networks, Scientific Reports, Vol. 15,
3775 [p47] Issue 1, 2025, 9831.
3776 [p47] [15]. R. C. Sachan, R. K. Malviya, et al., Neural transformers
3777 [p47] for zero-day threat detection in real-time cybersecurity
3778 [p47] network traffic analysis, International Journal of
3779 [p47] Global Innovations and Solutions , Vol. 3, Issue 1,
3780 [p47] 2024, pp. 1-9.
3781 [p47] [16]. T. A. Tang, L. Mhamdi, D. McLernon, S. A. R. Zaidi,
3782 [p47] et al., Deep learning approach for network intrusion
3783 [p47] detection in software defined networking, in
3784 [p47] Proceedings of the International Conference on
3785 [p47] Wireless Networks and Mobile Communications
3786 [p47] (WINCOM‚Äô16), 2016, pp. 258-263.
3787 [p47] [17]. M. Al Lail, A. Garcia, S. Olivo, Machine learning for
3788 [p47] network intrusion detecti on‚Äîa comparative study,
3789 [p47] Future Internet, Vol. 15, Issue 7, 2023, 243.
3790 [p47] [18]. M. K. Ngueajio, G. Washington, D. B. Rawat,
3791 [p47] Y. Ngueabou, Intrusion de tection systems using
3792 [p47] support vector machines on the KDDcup‚Äô99 and
3793 [p47] NSL-KDD datasets: a comprehensive survey, in
3794 [p47] Proceedings of the SAI Intelligent Systems Conference,
3795 [p47] 2022, pp. 609-629.
3796 [p47] [19]. P. C. Upadhyay, L. Karanam, J. A. Lory,
3797 [p47] G. N. DeSouza, Classifying cover crop residue from
3798 [p47] RGB images: a simple SVM versus a SVM ensemble,
3799 [p47] in Proceedings of the IEEE  Symposium Series on
3800 [p47] Computational Intelligence (SSCI‚Äô21), 2021, pp. 1-7.
3801 [p47] [20]. A. Yang, C. Lu, J. Li, X. Huang, et al., Application of
3802 [p47] meta-learning in cyberspace security: a survey, Digital
3803 [p47] Communications and Networks, Vol. 9, Issue 1, 2023,
3804 [p47] pp. 67-78.
3805 [p47] [21]. L. -H. Li, R. Ahmad, R . Tanone, A. K. Sharma, STB:
3806 [p47] synthetic minority overs ampling technique for
3807 [p47] tree-boosting models for imbalanced datasets of
3808 [p47] intrusion detection systems, PeerJ Computer Science ,
3809 [p47] Vol. 9, 2023, e1580.
3810 [p47] [22]. T. D. Diwan, S. Choubey, H. Hota, A detailed analysis
3811 [p47] on NSLKDD dataset using various machine learning
3812 [p47] techniques for intrusion detection, Turkish Journal of
3813 [p47] Computer and Mathematics Education , Vol. 12,
3814 [p47] Issue 11, 2021, pp. 2954-2968.
3815 [p47] [23]. M. Alalhareth, S. -C. Hong, Enhancing the internet of
3816 [p47] medical things (IoMT) security with meta-learning: a
3817 [p47] performance-driven approach  for ensemble intrusion
3818 [p47] detection systems, Sensors, Vol. 24, Issue 11, 2024,
3819 [p47] 3519.
3820 [p47] [24]. S. T. Hossain, T. Yigitcanlar, K. Nguyen, Y. Xu,
3821 [p47] Cybersecurity in local gove rnments: a systematic
3822 [p47] review and framework of key challenges, Urban
3823 [p47] Governance, 2025, 100224.
3824 [p47] [25]. Cost of a Data Breach Report 2025,
3825 [p47] https://www.ibm.com/reports/data-breach
3826 [p48] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3827 [p48] 25-27 November 2025, Innsbruck, Austria
3828 [p48] 47
3829 [p48] (017)
3830 [p48] ADAPTE: Multidimensional Academic Data Analytics
3831 [p48] and Student Profiling for Higher Education
3832 [p48] D. Lima and J. Coelho
3833 [p48] Estoril Higher Institute for Hotel and Tourism Studies, Portugal, Av. Condes de Barcelona,
3834 [p48] 2769-510 Estoril, Portugal
3835 [p48] E-mail: diogo.lima@eshte.pt, jose.coelho@eshte.pt
3836 [p48] Summary: The ADAPTE project develops an an alytical platform integrating  OLAP, Data Mining, Machine Learning, and
3837 [p48] interactive visualisation to monitor and predict student perfor mance at the higher educational level. Unlike most Educational
3838 [p48] Data Mining studies, ADAPTE combines pre-university, demographic, socio-economic, and cross-programme data. This paper
3839 [p48] presents a large-scale, data-driven on-going study of students enrolled at Estoril Higher Institute for Hotel and Tourism Studies
3840 [p48] (ESHTE) since 2018, combining descriptive statistics, hypothesis testing, and unsupervised learning to identify performance
3841 [p48] profiles. Results show that significant factors such as nationality and geographic origin influence mean grades, while admission
3842 [p48] grades show negligible predictive power. Unsupervised clusterin g (KMeans) segmented students into distinct profiles, from
3843 [p48] high achievers to persistent strugglers and critical dropout ca ses. The study offers methodologi cal insights and a replicable
3844 [p48] framework for institutional diagnostics, early warning systems, and strategic planning in higher education.
3845 [p48] Keywords: Educational data mining, Machine learning, Academic performance, Data visualisation, Higher education
3846 [p48] 1. Introduction
3847 [p48] Student performance and progression in higher
3848 [p48] education depend on a complex combination of
3849 [p48] academic, demographic, and contextual factors.
3850 [p48] Institutions face increasing pressure to monitor these
3851 [p48] trajectories, not only to improve graduation rates but
3852 [p48] also to anticipate potential dropout cases before they
3853 [p48] become irreversible. Research has consistently shown
3854 [p48] that early identification of at-risk students enables
3855 [p48] targeted interventions that improve retention and
3856 [p48] learning outcomes [1-3]. Within this context, the
3857 [p48] ADAPTE project extends existing work by integrating
3858 [p48] multidimensional data and applying unsupervised
3859 [p48] learning techniques to construct dynamic
3860 [p48] academic profiles.
3861 [p48] ADAPTE‚Äôs approach differs from traditional
3862 [p48] Educational Data Mining (EDM) pipelines by
3863 [p48] combining academic records, geographic and
3864 [p48] demographic features, and inferred behavioural
3865 [p48] indicators derived from course enrolment patterns.
3866 [p48] This enables a holistic understanding of how student
3867 [p48] progress unfolds over time, bridging descriptive
3868 [p48] analytics and predictive intervention models. The
3869 [p48] present paper reports the analytical phase of ADAPTE,
3870 [p48] focusing on data preparation, clustering of student
3871 [p48] profiles, and interpretation of patterns that can support
3872 [p48] institutional decision-making.
3873 [p48] 2. Related Work
3874 [p48] Student retention and success have long been
3875 [p48] central concerns in higher education research. Early
3876 [p48] frameworks such as Tinto‚Äôs model of student
3877 [p48] integration [4] and Kuh‚Äôs evidence-based review of
3878 [p48] student success [5] established the theoretical
3879 [p48] foundations linking institutional engagement to
3880 [p48] academic persistence. Yorke a nd Longden [6] further
3881 [p48] emphasized that institutional strategies for retention
3882 [p48] must address both academic preparedness and the
3883 [p48] socio-contextual realities of students.
3884 [p48] Advances in educational data mining and learning
3885 [p48] analytics have since transformed this field. Kovaƒçiƒá [7]
3886 [p48] demonstrated the potential of mining enrolment data
3887 [p48] for early prediction of academic success, while
3888 [p48] Siemens and Baker [8] highlighted the convergence of
3889 [p48] learning analytics and EDM for institutional
3890 [p48] intelligence. More recent su rveys [9] confirm the
3891 [p48] growing use of AI and machine learning to improve
3892 [p48] student monitoring, especially in large-scale data
3893 [p48] contexts. Neural-network approaches have also been
3894 [p48] applied successfully to predict academic outcomes and
3895 [p48] to identify differential contributions of key
3896 [p48] performance variables [10].
3897 [p48] Recent systematic reviews [1, 2] underscore the
3898 [p48] relevance of integrating predictive modelling and early
3899 [p48] alert systems into institutional practices, showing that
3900 [p48] multi-source data sign ificantly enhances risk
3901 [p48] prediction. These works complement ADAPTE‚Äôs
3902 [p48] contribution by validating the importance of a holistic,
3903 [p48] data-driven perspective that considers not only
3904 [p48] academic metrics but also demographic and contextual
3905 [p48] dimensions.
3906 [p48] 3. Methodology
3907 [p48] The overall methodology workflow of the
3908 [p48] ADAPTE project is illustrated in Fig. 1. The process
3909 [p48] integrates data collection,  preprocessing, feature
3910 [p48] engineering, segmentation, and unsupervised learning
3911 [p48] into a cohesive pipeline designed for interpretability
3912 [p48] and reproducibility.
3913 [p49] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3914 [p49] 25-27 November 2025, Innsbruck, Austria
3915 [p49] 48
3916 [p49] Fig. 1. Overview of the data preprocessing workflow
3917 [p49] and integration process.
3918 [p49] 3.1. Data and Preprocessing
3919 [p49] The dataset comprises academic records from 2018
3920 [p49] to 2024 at ESHTE, covering 5275 students and
3921 [p49] 172916 individual evaluations across 41 nationalities
3922 [p49] and approximately 700 Portuguese municipalities.
3923 [p49] Records were integrated from three primary tables ‚Äì
3924 [p49] INDIVIDUO, ALUNO, and AVALUNO ‚Äì ensuring
3925 [p49] referential consistency between student identifiers,
3926 [p49] course codes, and assessment results. Invalid or
3927 [p49] missing entries (e.g., zero or negative admission
3928 [p49] grades) were excluded, and categories with insufficient
3929 [p49] representation (< 15 students per municipality) were
3930 [p49] filtered out to ensure robust inferential statistics.
3931 [p49] Data were standardized using z-score
3932 [p49] normalization. Variables with mixed data types were
3933 [p49] transformed into numer ical form to ensure
3934 [p49] compatibility with KMeans.  Outliers were identified
3935 [p49] using interquartile range thresholds and retained when
3936 [p49] pedagogically relevant, as they often corresponded to
3937 [p49] atypical but valid academic trajectories.
3938 [p49] 3.2. Feature Engineering
3939 [p49] Derived metrics (Table 1) were created to
3940 [p49] summarize student trajectories, including mean grade,
3941 [p49] grade standard deviation, number of enrolments,
3942 [p49] course duration in distin ct academic years, total
3943 [p49] failures, total approvals, success rate (approvals
3944 [p49] divided by total evaluations), and grade range
3945 [p49] (difference between maximum and minimum grades).
3946 [p49] These engineered features capture academic variability
3947 [p49] and stability, serving as proxies for engagement and
3948 [p49] consistency.
3949 [p49] Table 1. Aggregated variables computed per student
3950 [p49] for clustering.
3951 [p49] 3.3. Clustering Design and Evaluation
3952 [p49] Students were categorized into three broad
3953 [p49] outcome groups: graduates taking three or more years,
3954 [p49] graduates completing in under three years, and
3955 [p49] non-graduates. For each gro up, variables were scaled
3956 [p49] with StandardScaler and clustered using the KMeans
3957 [p49] algorithm [10]. The optimal number of clusters was
3958 [p49] d e t e r m i n e d  v i a  t h e  S i l h o u e t t e  S c o r e  [ 1 1 ] ,  b a l a n c i n g
3959 [p49] cohesion and separation.
3960 [p49] Dimensionality reduction through Principal
3961 [p49] Component Analysis (PCA) provided 2D
3962 [p49] visualizations for interpretability. Clusters were then
3963 [p49] statistically profiled according to key indicators such
3964 [p49] as mean grade, number of failures, and success rate.
3965 [p49] Variable (in
3966 [p49] Portuguese) Description Type Mean Std_Dev
3967 [p49] nr_avalia_mean Mean of all student
3968 [p49] grades Numeric 13,2 1,1
3969 [p49] nr_avalia_std Standard deviation
3970 [p49] of grades Numeric 1,8 0,6
3971 [p49] num_inscricoes Total course
3972 [p49] enrolments Integer 45,6 18,3
3973 [p49] duracao_curso
3974 [p49] Number of distinct
3975 [p49] academic years
3976 [p49] enrolled
3977 [p49] Integer 2,8 0,9
3978 [p49] nr_chumbos Number of failed
3979 [p49] courses (<9.5) Integer 3,2 2,4
3980 [p49] nr_aprovacoes Number of passed
3981 [p49] courses (‚â•9.5) Integer 41,1 17,7
3982 [p49] taxa_sucesso Success rate Float 0,89 0,08
3983 [p49] diferenca_nota
3984 [p49] Difference between
3985 [p49] best and worst
3986 [p49] grade
3987 [p49] Float 6,5 2,1
3988 [p50] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
3989 [p50] 25-27 November 2025, Innsbruck, Austria
3990 [p50] 49
3991 [p50] 4. Results and Discussion
3992 [p50] The clustering process yielded interpretable groups
3993 [p50] that reflect varying academic behaviors (Table 2).
3994 [p50] Among students completing their degrees in three
3995 [p50] years or more, two distinct profiles emerged. The first,
3996 [p50] representing approximat ely one-third of the
3997 [p50] population, consisted of persistent students with lower
3998 [p50] average grades (around 12) and numerous
3999 [p50] re-enrollments. Despite multiple failures, these
4000 [p50] students completed their degrees through sustained
4001 [p50] effort. The second profile included high achievers,
4002 [p50] with mean grades above 14, few failures, and shorter
4003 [p50] completion times.
4004 [p50] Table 2. Summary of cluster statistics (mean grade, success
4005 [p50] rate, and failure count).
4006 [p50] For graduates finishing in under three years,
4007 [p50] clusters divided between excellent students with mean
4008 [p50] grades near 15 and almost no failures, and fast
4009 [p50] completers with moderate difficulties who nonetheless
4010 [p50] achieved completion in less than three years.
4011 [p50] Non-graduates exhibited the most heterogeneous
4012 [p50] distribution. A majority showed partial progress but
4013 [p50] eventually disengaged, while a smaller but critical
4014 [p50] subgroup displayed extremely low averages, minimal
4015 [p50] approvals, and high rates of administrative withdrawal.
4016 [p50] These patterns are statistically coherent with municipal
4017 [p50] disparities: municipalities with higher average
4018 [p50] performance often correspond to regions with stronger
4019 [p50] secondary-education infrastructures, whereas those
4020 [p50] with negative deviations tend to align with
4021 [p50] socio-economically disadvantaged areas.
4022 [p50] The municipality effect, observed across roughly
4023 [p50] 75 localities with sufficient representation, confirms
4024 [p50] that contextual and geographic factors contribute
4025 [p50] measurably to academic out comes. This reinforces
4026 [p50] ADAPTE‚Äôs decision to include geographic data as a
4027 [p50] first-class variable within its analytical architecture.
4028 [p50] Beyond descriptive insight, these clusters provide
4029 [p50] actionable intelligence for institutional management.
4030 [p50] Persistent students with difficulties can benefit from
4031 [p50] early academic advising a nd adaptive learning
4032 [p50] resources. High-performing clusters may inform
4033 [p50] mentorship programs or ped agogical models, while
4034 [p50] critical non-graduate cases demand immediate
4035 [p50] intervention.
4036 [p50] 5. Conclusion and Future Work
4037 [p50] This study demonstrates the potential of combining
4038 [p50] statistical inference and unsupervised learning to
4039 [p50] characterize student profile s and anticipate academic
4040 [p50] risks. By integrating demographic, academic, and
4041 [p50] geographic data, ADAPTE produces interpretable
4042 [p50] clusters that move beyond binary predictions, offering
4043 [p50] a richer understanding of institutional dynamics.
4044 [p50] While the analysis is based on a single institution,
4045 [p50] the methodological framework was designed to be
4046 [p50] transferable. The structur e of the pipeline ‚Äì data
4047 [p50] integration, feature engineering, and clustering ‚Äì can
4048 [p50] be replicated across other higher-education contexts
4049 [p50] with minimal adaptation. However, the initial data
4050 [p50] extraction and mapping processes are inherently
4051 [p50] dependent on the database structure, data models, and
4052 [p50] availability of academic reco rds in each institution,
4053 [p50] which may require specific schema alignment before
4054 [p50] replication. Institutional differences in curriculum
4055 [p50] structure, grading scales, and student demographics
4056 [p50] may affect the relative weight of specific features,
4057 [p50] suggesting the need for external validation.
4058 [p50] Future work will focus on four key directions. First,
4059 [p50] the integration of socio-economic and behavioral data
4060 [p50] (such as attendance and learning-management activity)
4061 [p50] into predictive dashboards for real-time monitoring.
4062 [p50] Second, the validation of these models through
4063 [p50] longitudinal tracking of future cohorts. Third, the
4064 [p50] deployment of ADAPTE as a modular decision-
4065 [p50] support platform, providing interactive visual analytics
4066 [p50] for administrators, program directors, and faculty to
4067 [p50] implement proactive retention strategies. Finally, the
4068 [p50] extension of the current approach to multi-institutional
4069 [p50] environments to benchmark student segmentation
4070 [p50] patterns across diverse academic ecosystems.
4071 [p50] Acknowledgements
4072 [p50] This work was supported by the project ‚ÄúADAPTE
4073 [p50] ‚Äì Academic Data Analytics for Profiling and Tailored
4074 [p50] Education‚Äù (reference 2024.07476.IACDC), funded
4075 [p50] by the Funda√ß√£o para a Ci√™ncia e a Tecnologia (FCT),
4076 [p50] under the DOI https://doi.org/10.54499/
4077 [p50] 2024.07476.IACDC.
4078 [p50] References
4079 [p50] [1]. J. Berens, A. G√§rtig-Daugs, T. Halbherr, J. Stang, Early
4080 [p50] detection of students at risk of failing: a systematic
4081 [p50] review of predictors, methods, and challenges,
4082 [p50] Computers & Education, Vol. 208, 2024, 104882.
4083 [p50] [2]. T. Br√§ndle, S. J√§ckle, S. K√∂nig, Identifying and
4084 [p50] supporting at-risk students in higher education: a
4085 [p50] Group Cluster % Students Mean
4086 [p50] Grade # Failures Success
4087 [p50] Rate Profile Summary
4088 [p50] 0 34.4% 12,3 10,1 85,8
4089 [p50] Persistent, many
4090 [p50] failures, slow
4091 [p50] completion
4092 [p50] 1 65.6% 14,5 1,2 97,9 Regular, efficient
4093 [p50] performers
4094 [p50] 0 67.5% 14,8 0,1 99,4 Excellent, nearly
4095 [p50] perfect completion
4096 [p50] 1 32.5% 12,3 4 85,7 Fast completers
4097 [p50] with difficulties
4098 [p50] 0 84.2% 12,4 4,6 84,3
4099 [p50] Partial
4100 [p50] progression,
4101 [p50] moderate
4102 [p50] disengagement
4103 [p50] 1 15.8% 0,6 0,6 0,3
4104 [p50] Critical cases,
4105 [p50] minimal academic
4106 [p50] progress
4107 [p50] Graduates
4108 [p50] (‚â•3 years)
4109 [p50] Graduates
4110 [p50] (<3 years)
4111 [p50] Non-
4112 [p50] graduates
4113 [p51] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4114 [p51] 25-27 November 2025, Innsbruck, Austria
4115 [p51] 50
4116 [p51] scoping review of learning analytics approaches,
4117 [p51] Education and Information Technologies , Vol. 30,
4118 [p51] 2025, pp. 125-153.
4119 [p51] [3]. M. Yorke, B. Longden, Retention and Student Success
4120 [p51] in Higher Education, McGraw-Hill Education, 2004.
4121 [p51] [4]. V. Tinto, Completing College: Rethinking Institutional
4122 [p51] Action, University of Chicago Press, 2012.
4123 [p51] [5]. G. D. Kuh, J. Kinzie, J. A. Buckley, B. K. Bridges, et
4124 [p51] al., What Matters to Student Success: A Review of the
4125 [p51] Literature, National Postsecondary Education
4126 [p51] Cooperative, 2006.
4127 [p51] [6]. Z. J. Kovaƒçiƒá, Early pre diction of student success:
4128 [p51] mining students‚Äô enrolment data, in Proceedings of the
4129 [p51] Informing Science & IT Education Conference
4130 [p51] (InSITE‚Äô10), 2010, pp. 647-665.
4131 [p51] [7]. G. Siemens, R. S. Baker, Learning analytics and
4132 [p51] educational data mining: t owards communication and
4133 [p51] collaboration, in Proceedings of the 2 nd International
4134 [p51] Conference on Learning Analytics and Knowledge
4135 [p51] (LAK‚Äô12), 2012, pp. 252-254.
4136 [p51] [8]. C. Romero, S. Ventura, Educational data mining and
4137 [p51] learning analytics: an updated survey, Wiley
4138 [p51] Interdisciplinary Reviews: Data Mining and
4139 [p51] Knowledge Discovery, Vol. 10, Issue 3, 2020, e1355.
4140 [p51] [9]. M. Richardson, C. Abraham, R. Bond, Psychological
4141 [p51] correlates of university students‚Äô academic
4142 [p51] performance: a systematic review and meta-analysis,
4143 [p51] Psychological Bulletin , Vol. 138, Issue 2, 2012,
4144 [p51] pp. 353-387.
4145 [p51] [10]. M. F. Musso, E. Kyndt, E. C. Cascallar, F. Dochy,
4146 [p51] Predicting general academic performance and
4147 [p51] identifying the differential contribution of participating
4148 [p51] variables using artificial neural networks, Frontline
4149 [p51] Learning Research, Vol. 1, Issue 1, 2013, pp. 42-71.
4150 [p51] [11]. J. MacQueen, Some methods for classification and
4151 [p51] analysis of multivariate observations, in Proceedings of
4152 [p51] the Fifth Berkeley Symposium on Mathematical
4153 [p51] Statistics and Probability, Vol. 1, 1967, pp. 281-297.
4154 [p51] [12]. P. J. Rousseeuw, Silhouett es: a graphical aid to the
4155 [p51] interpretation and validation of cluster analysis,
4156 [p51] Journal of Computational and Applied Mathematics ,
4157 [p51] Vol. 20, 1987, pp. 53-65.
4158 [p52] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4159 [p52] 25-27 November 2025, Innsbruck, Austria
4160 [p52] 51
4161 [p52] (018)
4162 [p52] Interpreting Tactical Decision-making in Transformer-based Agents
4163 [p52] K. Boeckx and X. Neyt
4164 [p52] Royal Military Academy, Rue Hobbema 8, 1000 Brussels, Belgium
4165 [p52] Tel.: +3224413775
4166 [p52] E-mail: koen.boeckx@rma.ac.be
4167 [p52] Summary: The development of autonomous age nts capable of sophisticated strategic decision- making in complex
4168 [p52] environments is a central goal of artificial intelligence. This  paper proposes a framework for discovering and interpreting
4169 [p52] strategies in a simulated grid-world battlefield environment. We leverage the AlphaZero algorithm, a powerful reinforcement
4170 [p52] learning method that combines Monte Carlo Tree Search (MCTS) wi th deep neural networks, to train agents. Crucially, the
4171 [p52] neural network component incorporates a Transformer architecture. The primary contribution of this work lies in the proposed
4172 [p52] methodology to utilize the self-attention mechanisms within the Transformer to gain insights into the agent‚Äôs decision-making
4173 [p52] process, specifically by visualizing which parts of the battlefield the network pays attention to when selecting an action. This
4174 [p52] approach aims not only to develop high-performing agents but also to enhance the interpretability of their learned strategies.
4175 [p52] Keywords: Autonomous agents, Decision-making, Transformer, Reinforcement learning, Interpretability.
4176 [p52] 1. Introduction
4177 [p52] Battlefield tactics often evolve in unpredictable
4178 [p52] environments where soldiers must navigate obstacles,
4179 [p52] anticipate threats and adapt to evolving objectives.
4180 [p52] Military planners increasingly use simulation games to
4181 [p52] explore and train strategies [1], but these environments
4182 [p52] are often hand -engineered and lack transparency into
4183 [p52] how AI agents learn. This paper proposes a two -part
4184 [p52] research agenda: first, designing a grid -world war
4185 [p52] game that captures key characteristics of battlefield
4186 [p52] maneuvers; second, training a transformer -based
4187 [p52] AlphaZero agent via self -play and analyzing its
4188 [p52] learned policies using mechanistic interpretability [2].
4189 [p52] The goal is to understand how small transformer
4190 [p52] models develop tactical reasoning in environments
4191 [p52] resembling military engagements and to identify
4192 [p52] which network components encode particular
4193 [p52] behaviors.
4194 [p52] 2. Background
4195 [p52] 2.1. AlphaZero
4196 [p52] AlphaZero is a general-purpose reinforcement
4197 [p52] learning algorithm that achieved super-human
4198 [p52] performance in chess, shogi and Go [3] by combining
4199 [p52] a deep neural network with Monte-Carlo Tree Search
4200 [p52] (MCTS) to guide decision-making. The network takes
4201 [p52] the game state ùë† as input and outputs (1) a policy vector
4202 [p52] ùëù‡µå ·à∫ùëù
4203 [p52] ‡Øî·àª which gives the pior probability of each legal
4204 [p52] action ùëé, and a value estimate ùë£‚àà ·àæ‡µÜ1,1·àø that predicts
4205 [p52] the expected outcome from the perspective of the
4206 [p52] current player.
4207 [p52] MCTS uses these outputs in two ways: the priors
4208 [p52] ùëù‡Øî bias the tree search toward promising moves, and
4209 [p52] the value ùë£ replaces traditional evaluation functions
4210 [p52] when a search branch reaches a leaf node.
4211 [p52] Each MCTS iteration selects a path from the root
4212 [p52] state to a leaf by maximizing a score for each action,
4213 [p52] based on its current value estimate ùëÑ·à∫ùë†, ùëé·àª, the number
4214 [p52] of times ùëÅ·à∫ùë†, ùëé·àª it has been visited in the search tree,
4215 [p52] and the prior probability ùëù‡Øî [4]. When the search tree
4216 [p52] reaches a new leaf state ùë†‚Ä≤, the neural network predicts
4217 [p52] its value ùë£·à∫ùë†·á±·àª and this value is then backpropagated
4218 [p52] through the search tree to update ùëÑ and ùëÅ. After a fixed
4219 [p52] number of simulations, the move ùëé in root node ùë† with
4220 [p52] the highest visit count ùëÅ·à∫ùë†, ùëé·àª becomes the
4221 [p52] chosen action.
4222 [p52] Training is fully self-play driven [3]:
4223 [p52] 1. The agent plays games against itself, using
4224 [p52] MCTS to choose actions;
4225 [p52] 2. For each visited state ùë†, the search visit counts
4226 [p52] define a target policy ùúã and the final game
4227 [p52] outcome ùëß ‚àà ·àæ‡µÜ1, 1·àø;
4228 [p52] 3. Based on these target values, the network
4229 [p52] parameters ùúÉ are updated to minimize the loss
4230 [p52] ùêø‡µå ·à∫ùëß‡µÜùë£ ·àª‡¨∂ ‡µÜùúãl o gùëù‡µÖùëê  |ùúÉ|‡¨∂,
4231 [p52] where the last term is a regularization term.
4232 [p52] The success of AlphaZero demonstrated that
4233 [p52] self-play can learn strategic heuristics without
4234 [p52] handcrafted evaluation functions. The original model
4235 [p52] implementation was based on convolutional
4236 [p52] networks [3].
4237 [p52] 2.2. Transformer Architecture
4238 [p52] Transformers, originally  developed for natural
4239 [p52] language processing [5], operate on sequences of
4240 [p52] tokens through a mechanism called self-attention. In
4241 [p52] the context of reinforcement learning, each token can
4242 [p52] represent elements of the state (e.g., obstacles,
4243 [p52] units, ‚Ä¶) [6].
4244 [p53] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4245 [p53] 25-27 November 2025, Innsbruck, Austria
4246 [p53] 52
4247 [p53] The self-attention mechanism computes a weighted
4248 [p53] combination of all other tokens for each token position,
4249 [p53] using learned query ùëÑ, key ùêæ and value ùëâ projections.
4250 [p53] This produces a score matrix indicating how much
4251 [p53] each token should attend to every other token; with a
4252 [p53] SoftMax operation these scores are turned into
4253 [p53] normalized weights. Multi-head attention replicates
4254 [p53] this process in parallel ‚Äúh eads,‚Äù each with its own ùëÑ,
4255 [p53] ùêæ and ùëâ projections, enabling the model to capture
4256 [p53] different types of relationships simultaneously.
4257 [p53] In reinforcement learning, this architecture allows
4258 [p53] the model to dynamically focus on the most relevant
4259 [p53] parts of the state or trajectory. For example, one
4260 [p53] attention head might speci alize in tracking enemy
4261 [p53] positions, while another attends to resource locations
4262 [p53] or the agent‚Äôs own health. Because attention weights
4263 [p53] are explicit, they provide a built-in interpretability
4264 [p53] handle [7]: by inspecting which tokens each head
4265 [p53] attends to during decision-making, we can infer what
4266 [p53] information the model considers important at each
4267 [p53] step. This is particularly useful in military grid-world
4268 [p53] scenarios, where attention maps can be visualized as
4269 [p53] ‚Äúheatmaps‚Äù over the battlefield, revealing whether the
4270 [p53] model prioritizes threats, objectives, or terrain
4271 [p53] features.
4272 [p53] 3. Experiments
4273 [p53] 3.1. Experiment Design
4274 [p53] We design a grid-world environment that simulates
4275 [p53] small-unit combat. The battlefield is a ùëÅ‡µàùëÅ  g r i d
4276 [p53] representing terrain with empty squares, impassable
4277 [p53] obstacles (e.g., buildings), a dversaries, friendly units
4278 [p53] and objectives (e.g., supply depots or enemy
4279 [p53] headquarters), placed in the center of the board. There
4280 [p53] are two players (Blue and Red) that act as squad
4281 [p53] commanders and control the different agents in their
4282 [p53] squad. Agents can move and shoot in the 4 cardinal
4283 [p53] directions. Shooting and hitting an enemy‚Äôs agent
4284 [p53] reduces its health.
4285 [p53] To speed up convergence, the game board shrinks
4286 [p53] at regular time intervals. Agents caught outside the
4287 [p53] remaining game board are eliminated. Not only does
4288 [p53] this decrease convergence time, it also induces the
4289 [p53] agents to move to the middle of the board and hence
4290 [p53] towards the goal square(s).
4291 [p53] Rewards are shaped to align with the military
4292 [p53] objectives of the environment: surviving units and
4293 [p53] eliminated enemies contribute positively to the reward
4294 [p53] signal, while casualties and unnecessary delays result
4295 [p53] in penalties. The episode terminates either when all
4296 [p53] opposing agents have been eliminated or when the
4297 [p53] designated objective has been achieved. To further
4298 [p53] guide learning, we employ potential-based reward
4299 [p53] shaping in the sense of Ng et al. [10], which preserves
4300 [p53] the optimal policy while a ccelerating convergence.
4301 [p53] This shaping incorporates domain-specific heuristics
4302 [p53] about progress toward the objective, allowing the agent
4303 [p53] to receive more informative intermediate feedback
4304 [p53] rather than relying solely on sparse terminal rewards.
4305 [p53] 3.2. Agent Architecture
4306 [p53] W e  a d a p t  t h e  A l p h a Z e r o  f r a m e w o r k  u s i n g  a
4307 [p53] transformer body [8]. The network inputs include the
4308 [p53] player‚Äôs observation of the state ùë† (embedded as a
4309 [p53] sequence of cell tokens). The game is fully-observable,
4310 [p53] so a player also observes all information about the
4311 [p53] enemy‚Äôs agents. A stack of transformer encoder layers
4312 [p53] processes this sequence and outputs both a policy
4313 [p53] vector over the discrete actions (move and shoot N, S,
4314 [p53] E, W) and a scalar value estimate. The architecture
4315 [p53] follows the residual block structure of AlphaZero but
4316 [p53] replaces convolutional layers with multi -head
4317 [p53] self-attention [8]. Training uses self -play: at each
4318 [p53] position, a Monte -Carlo Tree Search guided by the
4319 [p53] transformer‚Äôs policy and value decides actions. Data
4320 [p53] from self -p l a y  g a m e s  a r e  s t o r e d ,  a n d  t h e  n e t w o r k  i s
4321 [p53] updated by minimizing the difference between
4322 [p53] predicted policy/value targets and targets obtained
4323 [p53] from MCTS.
4324 [p53] Once the network is trained and produces non-trivial
4325 [p53] strategies, we use the attention weights to analyze how
4326 [p53] they use the game state to produce the network outputs
4327 [p53] [7]. Fig. 1 provides an overview of the
4328 [p53] experimental setup.
4329 [p53] Fig. 1. Overview of the experimental setup.
4330 [p53] 3.3. Training Implementation Details
4331 [p53] Training proceeds iteratively: self-play generates
4332 [p53] examples that are stored in a replay buffer, from which
4333 [p53] minibatches are drawn for gradient updates on a
4334 [p53] transformer-based neural network. After each training
4335 [p53] phase, candidate models are evaluated in an arena
4336 [p53] against reference opponents. The acceptance strategy
4337 [p53] is a pool-based Sequential Probability Ratio Test
4338 [p53] (SPRT) [11], where candidate s face a hall-of-fame of
4339 [p53] past accepted models. Acceptance or rejection is
4340 [p53] decided using log-likelihood ratio thresholds, with
4341 [p53] fallback to a Wilson confidence bound if SPRT
4342 [p53] remains inconclusive. Accepted models are
4343 [p53] checkpointed and propagated back to worker processes
4344 [p53] to ensure consistent inference in subsequent self-play.
4345 [p53] This combination of parallelized episode generation,
4346 [p53] batched inference, and statistically robust acceptance
4347 [p53] criteria provides scalable research framework for
4348 [p53] AlphaZero-style training.
4349 [p54] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4350 [p54] 25-27 November 2025, Innsbruck, Austria
4351 [p54] 53
4352 [p54] 4. Results
4353 [p54] 4.1. Training
4354 [p54] Fig. 2 shows the training loss over 120k steps for a
4355 [p54] board size of 7-by-7 with 2 agents per team. Each
4356 [p54] training batch was interleaved with data generation via
4357 [p54] the MCTS algorithm. For clarity, the curves were
4358 [p54] smoothed using an Exponential Moving Average
4359 [p54] (EMA) with Œ± = 0.2. The total loss is composed of the
4360 [p54] cross-entropy loss over the policy and the
4361 [p54] mean-squared error loss over the game outcome, with
4362 [p54] the policy loss being the dominant component.
4363 [p54] Overall, the trend is downward; however, in contrast
4364 [p54] to supervised learning, the loss curves exhibit
4365 [p54] additional variability due to the online reinforcement
4366 [p54] learning setting, where data generation and model
4367 [p54] training are interleaved, resulting in a continuously
4368 [p54] shifting training target.
4369 [p54] Fig. 2. Policy, value and total loss curves.
4370 [p54] The use of a transformer does make training less
4371 [p54] stable; Fig. 3 compares the loss functions of
4372 [p54] CNN-based Alphazero with  our version (with a
4373 [p54] Transformer). Not only is the CNN loss smaller, it also
4374 [p54] exhibits less variation. However, experimentation
4375 [p54] showed that there was no clear distinction in the
4376 [p54] learned strategies of CNN‚Äôs versus Transformers
4377 [p54] (when controlling for the number of learnable
4378 [p54] parameters).
4379 [p54] Fig. 3. Loss curves of CNN and Transformer model.
4380 [p54] 4.2. Strategies
4381 [p54] I n  s m a l l ,  s i m p l e  e n v i r o n m e n t s  ‚Äì  f o r  e x a m p l e ,  a
4382 [p54] small grid with only one friendly and one enemy unit
4383 [p54] ‚Äì the transformer-AlphaZero agent learned effective
4384 [p54] strategies very quickly. Within a few hundred self-play
4385 [p54] games, agents consistently navigated directly toward
4386 [p54] objective squares (e.g., the enemy‚Äôs base or a key
4387 [p54] resource point), often taking the shortest path while
4388 [p54] avoiding unnecessary detours. However, as
4389 [p54] environmental complexity i ncreased ‚Äì larger boards,
4390 [p54] more agents on each side, or more obstacles ‚Äì the
4391 [p54] required training duration grew exponentially [9].
4392 [p54] Doubling the number of agents or expanding the board
4393 [p54] size significantly lengthened convergence times, as the
4394 [p54] branching factor of the search and the diversity of
4395 [p54] tactical situations expanded dramatically.
4396 [p54] A typical scenario is shown in Fig. 4, where blue
4397 [p54] and red agents have to navigate the (black) to reach the
4398 [p54] goal state (marked by a yellow cross). Initially (not all
4399 [p54] steps are shown) the agents move to the middle (steps
4400 [p54] 1, 2 and 3), avoiding getting killed by the shrinking
4401 [p54] board (grey squares). Howev er, the red team loses an
4402 [p54] agent along the way (step 4), and in the end (step 5) the
4403 [p54] blue team comes out on top because it occupies the
4404 [p54] central square. Very often though, teams lose one of
4405 [p54] their agents early on the game, such that the end game
4406 [p54] is typically one-on-one.
4407 [p54] 4.3. Analysis
4408 [p54] Analysis of attention weights (see an example in
4409 [p54] Fig. 5) revealed a clear and interpretable pattern. In the
4410 [p54] first transformer layer, most attention heads
4411 [p54] concentrated disproportionately on critical squares in
4412 [p54] the observation space ‚Äì those occupied by allied or
4413 [p54] opposing agents, cells containing impassable
4414 [p54] obstacles, and the designated goal or capture location.
4415 [p54] This early specialization suggests that the initial layer
4416 [p54] of the network rapidly identifies and encodes salient
4417 [p54] tactical features of the battlefield, functioning as a
4418 [p54] filter that prioritizes immediately relevant spatial
4419 [p54] information over background detail. Such behavior is
4420 [p54] consistent with the notion of early-stage ‚Äúsituation
4421 [p54] awareness,‚Äù whereby raw perceptual input is
4422 [p54] transformed into a structured representation of threats,
4423 [p54] opportunities, and constraints.
4424 [p54] Interestingly, this tendency was robust across
4425 [p54] environments of varying complexity: both in
4426 [p54] simplified grid layouts with few obstacles and in more
4427 [p54] cluttered settings with dynamic safe zones, the
4428 [p54] first-layer heads consistently assigned higher weight to
4429 [p54] locations that directly influenced agent survival or
4430 [p54] strategic objectives. This indicates that the model
4431 [p54] develops a stable inductive bias toward recognizing
4432 [p54] battlefield affordances at the earliest stage of
4433 [p54] processing. By contrast, deeper layers appear to
4434 [p54] redistribute attention more broadly, a pattern
4435 [p54] suggestive of integrative planning over longer
4436 [p54] horizons and the coordination of multi-agent
4437 [p55] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4438 [p55] 25-27 November 2025, Innsbruck, Austria
4439 [p55] 54
4440 [p55] strategies. A more systematic exploration of these later
4441 [p55] layers is ongoing, with the aim of disentangling
4442 [p55] whether higher-level heads encode trajectory
4443 [p55] prediction, cooperative role allocation, or anticipation
4444 [p55] of adversarial behavior.
4445 [p55] Fig. 4. Gameplay example.
4446 [p56] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4447 [p56] 25-27 November 2025, Innsbruck, Austria
4448 [p56] 55
4449 [p56] Fig. 5. Example of grid world with heatmap. Friendly agents
4450 [p56] are marked F (blue), enemies E (red), obstacles ‚ñ† (black),
4451 [p56] and the goal square G (green). The red shading indicates
4452 [p56] where the attention head is focusing most strongly.
4453 [p56] 5. Conclusions
4454 [p56] This work introduced a framework for training and
4455 [p56] interpreting autonomous agents in a simulated
4456 [p56] grid-world battlefield using a Transformer-based
4457 [p56] AlphaZero architecture. By embedding battlefield
4458 [p56] states as sequences and analyzing the resulting
4459 [p56] attention distributions, we demonstrated that
4460 [p56] transformer-based agents are not only capable of
4461 [p56] learning effective tactical b ehaviors, but also yield
4462 [p56] interpretable insights into their decision-making
4463 [p56] processes.
4464 [p56] Beyond these interpretability results, our
4465 [p56] experiments highlighted both the strengths and
4466 [p56] limitations of this approach. On the one hand, the
4467 [p56] model reliably discovered sound strategies in simple
4468 [p56] scenarios. On the other hand, training in larger and
4469 [p56] more complex environments proved substantially
4470 [p56] more demanding, underscoring the computational
4471 [p56] challenges of scaling transformer-based AlphaZero
4472 [p56] methods to richer tactical domains. These difficulties
4473 [p56] mirror known scalability issues in multi-agent
4474 [p56] reinforcement learning, where the branching factor of
4475 [p56] possible interactions grows combinatorially with the
4476 [p56] number of agents and state dimensions.
4477 [p56] The introduction of attention-based interpretability
4478 [p56] opens promising avenues for future work. Systematic
4479 [p56] analysis of deeper transformer layers may reveal how
4480 [p56] agents integrate short-horizon tactical cues into
4481 [p56] longer-term strategic planning, cooperative
4482 [p56] coordination, or adversarial anticipation. Such work
4483 [p56] could build on emerging interpretability techniques
4484 [p56] that probe whether specific attention heads specialize
4485 [p56] in role allocation, trajectory prediction, or
4486 [p56] counterfactual reasoning about opponents.
4487 [p56] Taken together, our findings suggest that
4488 [p56] transformer-based AlphaZero agents constitute a
4489 [p56] promising platform for both high-performing and
4490 [p56] interpretable autonomous decision-making in tactical
4491 [p56] environments. By bridging performance with
4492 [p56] transparency, this approach has the potential to inform
4493 [p56] the design of trustworthy AI systems in military
4494 [p56] simulations and beyond, where understanding not only
4495 [p56] what an agent does but also why it acts is critical for
4496 [p56] human oversight, validation, and eventual integration
4497 [p56] into human‚Äìmachine teams.
4498 [p56] References
4499 [p56] [1]. Army University Press, W argaming: the laboratory of
4500 [p56] military planning, Military Review Online Exclusive,
4501 [p56] 2024, https://www.armyupress.army.mil/journals/
4502 [p56] military-review/online-exclusive/2024-ole/
4503 [p56] wargaming-the-laboratory-of-military-planning/
4504 [p56] [2]. C. Olsson, et al., In-context learning and induction
4505 [p56] heads, Transformer Circuits Thread, Anthropic,
4506 [p56] https://transformer-circuits.pub/2022/in-context-
4507 [p56] learning-and-induction-heads/
4508 [p56] [3]. D. Silver, T. Hubert, J. Schrittwieser, et al., A general
4509 [p56] reinforcement learning algorithm that masters chess,
4510 [p56] shogi, and Go through self-play, Science, Vol. 362,
4511 [p56] 2018, pp. 1140-1144.
4512 [p56] [4]. C. B. Browne, E. Powley, D. Whitehouse, et al., A
4513 [p56] survey of Monte Carlo tree search methods, IEEE
4514 [p56] Transactions on Computational Intelligence and AI in
4515 [p56] Games, Vol. 4, Issue 1, 2012, pp. 1-43.
4516 [p56] [5]. A. Vaswani, N. Shazeer, N. Parmar, et al., Attention is
4517 [p56] all you need, in Advances in Neural Information
4518 [p56] Processing Systems, Vol. 30, Curran Associates, Inc.
4519 [p56] 2017, pp. 5998-6008.
4520 [p56] [6]. E. Parisotto, F. Song, R. Salakhutdinov, Stabilizing
4521 [p56] transformers for reinforcement learning, in
4522 [p56] Proceedings of the International Conference on
4523 [p56] Machine Learning, 2020, pp. 7487-7498.
4524 [p56] [7]. H. Chefer, A. Kirillov, R. Lempel, Transformer
4525 [p56] interpretability beyond attention visualization, in
4526 [p56] Proceedings of the IEEE/CVF Conference on
4527 [p56] Computer Vision and Pattern Recognition (CVPR‚Äô21),
4528 [p56] 2021, pp. 782-791.
4529 [p56] [8]. J. Schrittwieser, I. Antonoglou, T. Hubert, et al.,
4530 [p56] Mastering Atari, Go, chess and shogi by planning with
4531 [p56] a learned model, Nature, Vol. 588, Issue 7839, 2020,
4532 [p56] pp. 604-609.
4533 [p56] [9]. Y. Shoham, R. Powers, T. Grenager, If multi-agent
4534 [p56] learning is the answer, what is the question?, Artificial
4535 [p56] Intelligence, Vol. 171, Issue 7, 2007, pp. 365-377.
4536 [p56] [10]. A. Y. Ng, D. Harada, S. Russell, Policy invariance
4537 [p56] under reward transformations: theory and application to
4538 [p56] reward shaping, in Proceedings of the 16th International
4539 [p56] Conference on Machine Learning (ICML‚Äô99) , 1999,
4540 [p56] pp. 278-287.
4541 [p56] [11]. A. Wald, Sequential test s of statistical hypotheses, in
4542 [p56] Breakthroughs in Statistics: Foundations and Basic
4543 [p56] Theory, Springer, 1992, pp. 256-298.
4544 [p57] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4545 [p57] 25-27 November 2025, Innsbruck, Austria
4546 [p57] 56
4547 [p57] (019)
4548 [p57] A Selective Temporal Hamming Distance to Find Patterns
4549 [p57] in State Transition Event Timeseries, at Scale
4550 [p57] Sylvain Mari√© and Pablo Knecht
4551 [p57] AI Hub, Schneider Electric, IntenCity, 160, Avenue des Martyrs, 38000 Grenoble, France
4552 [p57] E-mail: sylvain.marie@se.com, pablo.knecht@se.com
4553 [p57] Summary: Discrete event systems are present both in observations of nat ure, socio economical sciences, and industrial
4554 [p57] systems. Standard analysis appr oaches do not usually exploit th eir dual event / state nature: signals are either modeled as
4555 [p57] transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled
4556 [p57] ‚Äì a distorting and costly operation as the observation period and number of events grow. In this work we define state transition
4557 [p57] event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and
4558 [p57] duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and
4559 [p57] Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validat e
4560 [p57] these benefits on simulated and real-world datasets.
4561 [p57] Keywords: Continuous time, Aperiodic non-uniform sampling, Categorical timeseries, Alarm and state transition sequences,
4562 [p57] Temporal similarity and distance metric, Discrete event systems, Clustering, Kernel.
4563 [p57] 1. Introduction
4564 [p57] Discrete state systems (DSS) are systems with a
4565 [p57] discrete set of states (a.k.a. a discrete state space ).
4566 [p57] They are present in numerous domains from robotics
4567 [p57] to industrial processes, energy, mobility, social
4568 [p57] sciences, games or biology [1-8]. Discrete event
4569 [p57] systems (DES) are DSS where state transition is based
4570 [p57] on instantaneous transition events [9]. Modeling of
4571 [p57] DES has been studied for over 35 years, typically with
4572 [p57] Finite State Automata, Petri Nets, Vector DES, Event
4573 [p57] Graphs, Queuing systems,  Markov Processes [5].
4574 [p57] Techniques such as Hidden Markov models are also
4575 [p57] used to estimate hidden states and transitions [8].
4576 [p57] Data collected from DES‚Äô observation can be
4577 [p57] represented either as a sequence of state transition
4578 [p57] events, or as a timeseries o f categorical states. Two
4579 [p57] families of approaches in the  literature are therefore
4580 [p57] relevant: analysis of event sequences, and analysis of
4581 [p57] categorical timeseries.
4582 [p57] In many statistical and machine learning methods,
4583 [p57] defining a proper similarity or distance between
4584 [p57] samples plays an important role: e.g. in clustering with
4585 [p57] Agglomerative clustering, Spectral clustering,
4586 [p57] DBScan, etc.; in classification with KNN, SVM, etc.;
4587 [p57] in visualization with Isomap, MDS [10]. A known
4588 [p57] difficulty with categorical v ariables as opposed to
4589 [p57] real-valued is the absence of observed magnitude of
4590 [p57] difference. Metrics inclu de association measures,
4591 [p57] Kramer‚Äôs ŒΩ, Kendall Tau, simple matching (SM),
4592 [p57] (inverse) Occurrence Frequency, Elkin, Goodall, LIN
4593 [p57] and derivatives, Total variation distance, Kullback-
4594 [p57] Leibler divergence. A common practice is to binarize
4595 [p57] data with presence/absence indicators and use binary
4596 [p57] metrics, as in the Jaccard index, or in [11, 12].
4597 [p57] Information theory provides interesting similarities
4598 [p57] [12, 13]. See [14] for a review, generalized in [10].
4599 [p57] Analysis of categorical event sequences  refers to
4600 [p57] counts of common states, and edit distances such as
4601 [p57] Levenshtein, Longest Common Subsequence,
4602 [p57] Hamming, Spectrum kernel, MCA, Optimal Matching
4603 [p57] (OM) including MSW and BLAST [15-18]. Correlated
4604 [p57] sequences are also found with association rules mining
4605 [p57] techniques including fuzzy sets, FP-Growth or Apriori
4606 [p57] algorithm [19, 20]. State-aware metrics weight events
4607 [p57] according to specific stat e transitions, such as
4608 [p57] Dynamic Hamming Distance or OM for transitions
4609 [p57] [21, 15]. See [15] and [7] for a status of the field.
4610 [p57] Analysis of categorical timeseries (CTS) refers to
4611 [p57] œá¬≤, Hamming, fuzzy comparison, Cramer‚Äôs ŒΩ, possibly
4612 [p57] extended to support lags, and Pearson correlation
4613 [p57] applied to binarized representations [16, 22]. The case
4614 [p57] of binary series is worth mentioning with metrics such
4615 [p57] as Pearson‚Äôs Phi, Simple Matching coefficient (SMC)
4616 [p57] (a.k.a Rand), Hamming, Jaccard Index [23], with lag
4617 [p57] tolerance [18, 24], or time-depending weigths [25].
4618 [p57] Finally, methods exist for real-valued timeseries such
4619 [p57] as cross-correlation, DTW and its variants [26], metric
4620 [p57] learning [27], and tools such as Matrix Profile [28].
4621 [p57] Time warp edit distance [29] is an interesting step in
4622 [p57] the direction of applying them to categorical
4623 [p57] timeseries.
4624 [p57] 2. Challenge, Related Work
4625 [p57] and Contributions
4626 [p57] Most metrics require timeseries to be uniformly
4627 [p57] sampled. Yet, resampling non-uniform timeseries is a
4628 [p57] computationally intensive task inducing distortion
4629 [p57] [30]. To the best of our knowledge, only two recently
4630 [p57] proposed metrics overcome this critical issue. FTH
4631 [p57] [31] is an edit distance acc ounting for time shifts
4632 [p57] required in mobility data analysis, thanks to
4633 [p58] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4634 [p58] 25-27 November 2025, Innsbruck, Austria
4635 [p58] 57
4636 [p58] fuzzification. It however lacks native symmetry, is a
4637 [p58] semi-metric, requires Fast Fourier Transform, and has
4638 [p58] a complexity of ùí™‡µ´ùëöùëéùë•·à∫ùëõ, ùëö·àª¬≤ ùëôùëúùëî ùëöùëéùë•·à∫ùëõ, ùëö·àª‡µØ (the
4639 [p58] complexity in [31] seem s incorrect as NFFT‚Äôs
4640 [p58] complexity varies with n n o t  T [32]), reducing its
4641 [p58] applicability to large series. While a draft of temporal
4642 [p58] Hamming concept is mentioned as a singular case, it is
4643 [p58] not formalized nor studied, and its complexity analysis
4644 [p58] ùí™·à∫ùëá·àª seems incorrect (see Section 4.1). Temporal
4645 [p58] Similarity [33] is a temporal version of Jaccard
4646 [p58] computed online in linear time. It however restricts to
4647 [p58] binary series, does not address the situation where both
4648 [p58] series are 0, and does not prove metric properties.
4649 [p58] Contributions I n  t h i s  w o r k  w e  s u g g e s t  a  n e w
4650 [p58] formal definition of State Transition Event timeseries
4651 [p58] (STE-ts) and propose a Selective Temporal Hamming
4652 [p58] (STH) similarity and associated distance. STH has the
4653 [p58] following benefits:
4654 [p58] ÔÇ∑ It is a formal generalization of the Hamming and
4655 [p58] Jaccard metrics for continuous time;
4656 [p58] ÔÇ∑ It is equivalent to metrics computed on infinitely
4657 [p58] small sampling periods, avoiding any distortion;
4658 [p58] ÔÇ∑ It generalizes the Jaccard metric to non-binary
4659 [p58] series, including ambiguous states (‚Äúexcluded‚Äù);
4660 [p58] ÔÇ∑ It is a proper metric (incl. triangular inequality)
4661 [p58] in m any cases and ca n thus be easily use d in a
4662 [p58] kernel;
4663 [p58] ÔÇ∑ Its linear complexity ùí™·à∫ùëõ‡µÖùëö ·àª solely depends
4664 [p58] on the number of events, as opposed to resampled
4665 [p58] Hamming and Jaccard ùí™‡µ´ùëõ ‡µÖ ùëö ‡µÖ ùëõ
4666 [p58] ·à∫‡Øâ·àª‡µØ t h a t
4667 [p58] also depend on the number ùëõ·à∫‡Øâ·àª of sampling
4668 [p58] buckets.
4669 [p58] The rest of this paper is organized as follows: in
4670 [p58] Section 3 we remind DES, define state transition event
4671 [p58] timeseries (STE-ts) and remind existing metrics for
4672 [p58] uniformly sampled STE-ts. In Section 4 we introduce
4673 [p58] novel distance metrics and detail a few interesting
4674 [p58] properties. In Section 5 we present experiments on
4675 [p58] simulated and real-world datasets, highlighting the
4676 [p58] benefits. Finally, we conclude in Section 6.
4677 [p58] 3. State Transition Event Timeseries
4678 [p58] 3.1. Discrete Event Systems
4679 [p58] We consider a discrete event system DES with set
4680 [p58] of states ùíÆ ‡µå ·àºùúé‡Øû·àΩ and set ùíØ of possible state
4681 [p58] transitions defined as a set of pairs (before state, after
4682 [p58] state): ùíØ ‡µå ·àºùë°ùëü‡Øú  ‡µå ·à∫ùëè‡Øú,ùëé ‡Øú·àª·àΩ ‚äÇùíÆ‡µàùíÆ . In the following
4683 [p58] work we focus on state-changing transitions , i.e.
4684 [p58] ùëè‡Øú ‡µçùëé ‡Øú ‚àÄùëñ. Note that any system whose state is
4685 [p58] represented by a finite number of categorical variables
4686 [p58] can be represented as such. This includes Markov
4687 [p58] Processes (a.k.a. Markov Chains) and HMMs. Fig. 1
4688 [p58] illustrates two prototypic DES: a simplified DVD
4689 [p58] player system and an industrial alarm system with
4690 [p58] shelving capability. Note: shelving ( a . k . a .  muting)
4691 [p58] means that the true alarm state is unknown and not
4692 [p58] relevant according to the user, for example during a
4693 [p58] maintenance operation.
4694 [p58] Property: ( Simplification) merging some states
4695 [p58] and associated transitions. e.g., merging ‚ÄúDVD
4696 [p58] playing‚Äù and ‚ÄúDVD paused‚Äù, leads to valid DES
4697 [p58] representations.
4698 [p58] Fig. 1. Simple DVD Player (left); Alarm system (right).
4699 [p58] 3.2. State Transition Event Sequences
4700 [p58] and Timeseries
4701 [p58] We define a  sequence  of state transition events
4702 [p58] STE-seq of length n as an ordered collection of n
4703 [p58] state-changing transitions ·àºùë°ùëü‡Øû  ‡µå ·à∫ùëè‡Øû,ùëé ‡Øû·àª·àΩ‡Øû ‡≠Ä ‡¨µ,‚Ä¶,‡Ø° ‚äÇ
4704 [p58] ùíØ‡Ø°, with state-changing constraint ·àºùëè‡Øû ‡µçùëé ‡Øû·àΩ ‚àÄùëò and
4705 [p58] sequence consistency constraint ·àºùëé‡Øû  ‡µå ùëè ‡Øû‡¨æ‡¨µ·àΩ ‚àÄùëò ‡µè
4706 [p58] ùëõ. Such a sequence can be rewritten as a categorical
4707 [p58] sequence o f  ùëõ‡µÖ1  states ·àºùúé‡Øû·àΩ‡Øû ‡≠Ä ‡¨¥‚Ä¶,‡Ø° ‚äÇùíÆ ‡Ø°‡¨æ‡¨µ with
4708 [p58] state changing constraint ·àºùúé‡Øû ‡µç ùúé ‡Øû‡¨æ‡¨µ·àΩ ‚àÄùëò ‡µè ùëõ.
4709 [p58] Let ùõ∫ be the set of all timestamps. We define a
4710 [p58] timeseries of state transition events STE-ts of length
4711 [p58] n, as an ordered collection of n timestamped
4712 [p58] state-changing transitions ·àº·à∫ùë°‡Øû,ùë° ùëü‡Øû·àª·àΩ‡Øû ‡≠Ä ‡¨µ,‚Ä¶,‡Ø° ‚äÇ ·à∫ùõ∫‡µà
4713 [p58] ùíØ·àª‡Ø° complying with the above constraints, associated
4714 [p58] with a start time  ùë°‡¨¥ a n d  a n  end time ùë°‡Ø°‡¨æ‡¨µ. Such a
4715 [p58] timeseries can be rewritten as a categorical timeseries
4716 [p58] with ùëõ‡µÖ1  pairs of state value and timestamp
4717 [p58] ·àº·à∫ùë°‡Øû,ùúé‡Øû·àª·àΩ‡Øû ‡≠Ä ‡¨¥,‚Ä¶,‡Ø° ‚äÇ ·à∫ùõ∫‡µàùíÆ ·àª‡Ø°‡¨æ‡¨µ, associated with an
4718 [p58] end time. A given state ùúé‡Øû is valid for the interval
4719 [p58] ·àæùë°‡Øû,ùë° ‡Øû‡¨æ‡¨µ·àæ.
4720 [p58] Note that the above definition is similar to the
4721 [p58] traditional definition of categorical timeseries (CTS)
4722 [p58] [16], with three key restrictions: (a) a state value is
4723 [p58] valid for the interval following the timestamp, until
4724 [p58] next timestamp; (b) there is an explicit end time; and
4725 [p58] (c) all values differ from previous.
4726 [p58] 3.3. Prior Art ‚Äì Reference Resampled Metrics
4727 [p58] We now consider two STE-ts
4728 [p58] ùë†‡Øú and ùë†‡Øù with n and
4729 [p58] m transition events respectively, with the same start
4730 [p58] and end time and total duration T. We remind below
4731 [p58] the two simplest, most commonly used metrics,
4732 [p58] defined on resampled series. Resampled series
4733 [p58] ùë†‡Øú
4734 [p58] ·à∫‡Øâ·àª,ùë†‡Øù
4735 [p58] ·à∫‡Øâ·àª are derived with sampling period P, sampling
4736 [p58] rate ùêπ ‡µå 1 ùëÉ‚ÅÑ , resulting in (finite) number of samples
4737 [p58] ùëõ·à∫‡Øâ·àª  ‡µå ùëá ùëÉ‚ÅÑ . We note ùúé‡Øú‡Øû
4738 [p58] ·à∫‡Øâ·àª a n d  ùúé‡Øù‡Øû
4739 [p58] ·à∫‡Øâ·àª t h e  r e s p e c t i v e
4740 [p58] resampled values ‚àÄ ùëò ‚àà 1 ..ùëõ·à∫‡Øâ·àª. The Hamming distance
4741 [p58] ùêªùê∑ is obtained as a count of non-matching samples:
4742 [p58] ùêªùê∑ ·âÄùë†‡Øú
4743 [p58] ·à∫‡Øâ·àª,ùë†‡Øù
4744 [p58] ·à∫‡Øâ·àª·âÅ ‡µå ·âö ùëò ‡µå 1 ..ùëõ·à∫‡Øâ·àª | ùúé‡Øú‡Øû
4745 [p58] ·à∫‡Øâ·àª ‡µçùúé ‡Øù‡Øû
4746 [p58] ·à∫‡Øâ·àª·âö (1)
4747 [p58] dvd paused
4748 [p58] no dvd
4749 [p58] dvd playing
4750 [p58] dvd stopped
4751 [p58] tray open
4752 [p58] active inactive
4753 [p58] shelved
4754 [p58] ‚Äúalarm‚Äù
4755 [p58] ‚Äúreset‚Äù
4756 [p58] ‚Äúshelve‚Äù 2
4757 [p58] ‚Äúunshelve‚Äù
4758 [p58] ‚Äúshelve‚Äù 1
4759 [p59] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4760 [p59] 25-27 November 2025, Innsbruck, Austria
4761 [p59] 58
4762 [p59] The normalized Hamming distance ùëõùêªùê∑ is defined
4763 [p59] as ùëõùêªùê∑ ‡µå  ùêªùê∑ ùëõ·à∫‡Øâ·àª‚ÅÑ . It represents the approximate
4764 [p59] proportion of the time during which the two series‚Äô
4765 [p59] values differ. The quality of the approximation
4766 [p59] globally increases with the sampling rate but is subject
4767 [p59] to local distortion (see Section 5.1). HD and nHD are
4768 [p59] proper metrics complying with positivity, symmetry,
4769 [p59] distinguishability, and triangular inequality [34]. We
4770 [p59] note H = n-HD ; nH = 1-nHD  the associated
4771 [p59] similarities.
4772 [p59] The Jaccard similarity index J is defined for a
4773 [p59] binary representation of feature presence/absence (2)
4774 [p59] on static observations [23]. It is also used in practice
4775 [p59] on resampled series as a biased alternative to Hamming
4776 [p59] where value ‚Äú0‚Äù has less interest than ‚Äú1‚Äù [18, 24].
4777 [p59] ùêΩ‡µ´ùë†‡Øú
4778 [p59] ·à∫‡Øâ·àª,ùë†‡Øù
4779 [p59] ·à∫‡Øâ·àª‡µØ‡µå
4780 [p59] ‡∏´ùëò| ùúé‡Øú‡Øû
4781 [p59] ·à∫‡Øâ·àª ‡µåùúé ‡Øù‡Øû
4782 [p59] ·à∫‡Øâ·àª ‡µå1 ‡∏´
4783 [p59] ·âöùëò| ùúé‡Øú‡Øû
4784 [p59] ·à∫‡Øâ·àª ‡µåùúé ‡Øù‡Øû
4785 [p59] ·à∫‡Øâ·àª ‡µå1 ·âö‡µÖ·âö ùëò |ùúé‡Øú‡Øû
4786 [p59] ·à∫‡Øâ·àª ‡µå1 , ùúé‡Øù‡Øû
4787 [p59] ·à∫‡Øâ·àª ‡µå0 ·âö‡µÖ·âö ùëò | ùúé‡Øú‡Øû
4788 [p59] ·à∫‡Øâ·àª ‡µå0 , ùúé‡Øù‡Øû
4789 [p59] ·à∫‡Øâ·àª ‡µå1 ·âö
4790 [p59] (2)
4791 [p59] The Jaccard distance is defined as ùêΩùê∑ ‡µå  1 ‡µÜ ùêΩ with
4792 [p59] ùêΩ·à∫ùüé, ùüé·àª : ‡µå  1. It meets positivity, symmetry,
4793 [p59] distinguishability, and triangular inequality [23, 35].
4794 [p59] Property: ( Linear complexity ) Assuming initial
4795 [p59] ordering, resampling of a single timeseries ùë†‡Øú i s
4796 [p59] ùí™‡µ´ùëõ·à∫‡Øâ·àª ‡µÖùëõ ‡µØ as for each bucket there is a need to find
4797 [p59] the events that fall in this bucket. Therefore H, HD, nH,
4798 [p59] nHD, J, and JD have complexity ùí™‡µ´ùëõ·à∫‡Øâ·àª ‡µÖùëõ‡µÖùëö ‡µØ.
4799 [p59] Note: in this paper we use the simplified notations
4800 [p59] (e.g. ùêªùê∑, ùêΩùê∑) for all resampled metrics except for
4801 [p59] places where it matters to remind the P: ùêªùê∑·à∫‡Øâ·àª, ùêΩùê∑·à∫‡Øâ·àª.
4802 [p59] 4. Temporal Metrics for STE-ts
4803 [p59] We now consider the collection of time intervals
4804 [p59] ‚Ñê‡Øú‡Øù  ‡µå ·àºùúÑ‡Øû  ‡µå ·àæùë°‡Øû,ùë° ‡Øû‡¨æ‡¨µ·àæ·àΩ defined by the union of all
4805 [p59] timestamps in ùë†‡Øú,ùë†‡Øù. Its cardinal depends on the
4806 [p59] number of timestamps that are common to ùë†‡Øú and ùë†‡Øù:
4807 [p59] max·à∫ùëõ, ùëö·àª ‡µÖ2‡µë‡∏´ ‚Ñê‡Øú‡Øù‡∏´‡µëùëõ‡µÖùëö‡µÖ2 . For each interval ùúÑ
4808 [p59] we define Œî‡∞ê its duration, and ùúé‡Øú
4809 [p59] ‡∞ê and ùúé‡Øù
4810 [p59] ‡∞ê the respective
4811 [p59] states of ùë†‡Øú and ùë†‡Øù on ùúÑ. Note that ùëá ‡µå  ‚àë Œî‡∞ê‡Æô‚àà‚Ñêùíæùíø .
4812 [p59] 4.1. Temporal Hamming Similarity and Distance
4813 [p59] We define the Temporal Hamming Similarity TH
4814 [p59] as the sum of durations of all intervals in ‚Ñê‡Øú‡Øù where the
4815 [p59] two series ùë†‡Øú,ùë†‡Øù have the same value (3).
4816 [p59] ùëáùêª‡µ´ùë†‡Øú,ùë†‡Øù‡µØ ‡µå ‚àë Œî‡∞ê‡∞ê‚àà‚Ñêùëñùëó | ‡∞ô‡≥î
4817 [p59] ‡¥à ‡≠Ä ‡∞ô‡≥ï
4818 [p59] ‡¥à   (3)
4819 [p59] The Normalized Temporal Hamming  similarity
4820 [p59] nTH is obtained by dividing TH by the total duration:
4821 [p59] ùëõùëáùêª‡µ´ùë†‡Øú,ùë†‡Øù‡µØ ‡µå ùëáùêª‡µ´ùë†‡Øú,ùë†‡Øù‡µØ
4822 [p59] ùëá  ‡µå
4823 [p59] ‚àë Œî‡∞ê‡∞ê‚àà‚Ñêùëñùëó | ‡∞ô‡≥î
4824 [p59] ‡¥à ‡≠Ä ‡∞ô‡≥ï
4825 [p59] ‡¥à
4826 [p59] ‚àë Œî‡∞ê‡∞ê‚àà‚Ñêùëñùëó
4827 [p59] (4)
4828 [p59] We define for TH a n d  nTH their associated
4829 [p59] distances ùëáùêªùê∑ ‡µå  ùëá ‡µÜ ùëáùêª and ùëõùëáùêªùê∑ ‡µå  1 ‡µÜ ùëõùëáùêª.
4830 [p59] Property: ( Metric) THD a n d  nTHD are proper
4831 [p59] distance metrics. TH and nTH are similarity measures.
4832 [p59] Property: (nH equivalence) when all events have
4833 [p59] uniform timestamps, all interval durations are
4834 [p59] identical. Temporal Hamming metrics equal
4835 [p59] ‚Äòresampled‚Äô Hamming: ùëõùëáùêª ‡µå  ùëõùêª, ùëõùëáùêªùê∑ ‡µå  ùëõùêªùê∑.
4836 [p59] Property: (Limit) nTH (resp. nTHD) is the limit of
4837 [p59] nH(P) (resp. nHD (P)) as sampling period P
4838 [p59] approaches zero:
4839 [p59] ùëõùëáùêª·àæùê∑·àø‡µ´ùë†‡Øú,ùë†‡Øù‡µØ‡µål i m
4840 [p59] ‡Øâ‚Üí‡¨¥
4841 [p59] ùëõùêª·àæùê∑·àø‡µ´ùë†‡Øú
4842 [p59] ·à∫‡Øâ·àª,ùë†‡Øù
4843 [p59] ·à∫‡Øâ·àª‡µØ  (5)
4844 [p59] We similarly define Temporal Jaccard TJ f o r
4845 [p59] binary series (6), associated distance ùëáùêΩùê∑ ‡µå  1 ‡µÜ ùëáùêΩ,
4846 [p59] and note that analogous properties ( J equivalence,
4847 [p59] sampling limit) hold.
4848 [p59] ùëáùêΩ‡µ´ùë†‡Øú,ùë†‡Øù‡µØ‡µå
4849 [p59] ‚àë ‡≠º‡¥à‡¥à‚àà‚Ñêùëñùëó | ‡¥ë‡≥î
4850 [p59] ‡¥à ‡∞∏ ‡¥ë‡≥ï
4851 [p59] ‡¥à  ‡∞∏ ‡∞≠
4852 [p59] ‡Øç‡¨ø‚àë ‡≠º‡¥à‡¥à‚àà‚Ñêùëñùëó | ‡¥ë‡≥î
4853 [p59] ‡¥à ‡∞∏ ‡¥ë‡≥ï
4854 [p59] ‡¥à  ‡∞∏ ‡∞¨
4855 [p59] (6)
4856 [p59] Property: (T-S equivalence) Temporal Jaccard TJ
4857 [p59] equals the temporal similarity as defined in [33] for
4858 [p59] single alarm sets ùê¥ ‡µå  ·àºùë†‡Øú·àΩ, ùêµ ‡µå  ‡µõùë†‡Øù‡µü.
4859 [p59] 4.2. Selective Temporal Hamming metric
4860 [p59] We now consider a state partition: ùíÆ ‡µå ùíÆ ‡ØÇ ‚à™ùíÆ ‡Øà ‚à™
4861 [p59] ùíÆ‡Ææ with
4862 [p59] ÔÇ∑ ùíÆ‡ØÇ a set of states of interest. For example ‚Äúactive‚Äù,
4863 [p59] or {‚ÄúDVD playing‚Äù, ‚ÄúDVD paused‚Äù}. We define
4864 [p59] ùë†ùëñùëö a similarity function between states in ùíÆ‡ØÇ as
4865 [p59] in [31];
4866 [p59] ÔÇ∑ ùíÆ‡Øà a  s e t  o f  other states, e.g. ‚Äúinactive‚Äù, ‚ÄúDVD
4867 [p59] stopped‚Äù;
4868 [p59] ÔÇ∑ ùíÆ‡Ææ a set of excluded (or ‚Äúambiguous‚Äù) states. For
4869 [p59] example ‚Äúshelved‚Äù, or {‚Äútray open‚Äù, ‚Äúno DVD‚Äù}.
4870 [p59] We define the Selective Temporal Hamming (STH)
4871 [p59] s i m i l a r i t y  f o r  t w o  S T E - t s  ùë†‡Øú a n d  ùë†‡Øù, for state sets
4872 [p59] ·àºùíÆ‡ØÇ,ùíÆ ‡Øà·àΩ, as in (7):
4873 [p59] ùëÜùëáùêª·àºùíÆ‡≤∫,ùíÆ‡≥Ä·àΩ‡µ´ùë†‡Øú,ùë†‡Øù‡µØ‡µå
4874 [p59] ‡µå·âê
4875 [p59] ? ·à∫ùë¢ùëõùëëùëíùëì·àª ùëñùëì ‚àÄùúÑ, ùúé‡Øú
4876 [p59] ‡∞ê ‚àà ùíÆ‡Ææ ùëúùëü ùúé‡Øú
4877 [p59] ‡∞ê ‚àà ùíÆ‡Ææ
4878 [p59] 1ùëñ ùëì ‚àÄ ùúÑ , ùúé‡Øú
4879 [p59] ‡∞ê ‚àâ ùíÆ‡ØÇ ùëéùëõùëë ùúé‡Øú
4880 [p59] ‡∞ê ‚àâ ùíÆ‡ØÇ
4881 [p59] ùë•‡µ´ùë†‡Øú,ùë†‡Øù‡µØùëú ùë° ‚Ñé ùëí ùëü ùë§ ùëñ ùë† ùëí
4882 [p59] , (7)
4883 [p59] with
4884 [p59] ùë•‡µ´ùë†‡Øú,ùë†‡Øù‡µØ‡µå
4885 [p59] ‚àë  ‡Ø¶‡Øú‡Ø†·à∫‡∞ô‡≥î
4886 [p59] ‡¥à,‡∞ô‡≥ï
4887 [p59] ‡¥à·àª‚àô‡Ø±‡¥à‡¥à‚àà‚Ñê |‡¥ë ‡≥î
4888 [p59] ‡¥à,‡¥ë‡≥ï
4889 [p59] ‡¥à ‚ààùíÆ‡≤∫
4890 [p59] ‡∞Æ
4891 [p59] ‚àë ‡Ø±‡¥à‡¥à‚àà‚Ñê |‡¥ë ‡≥î
4892 [p59] ‡¥à,‡¥ë‡≥ï
4893 [p59] ‡¥à ‚àà·âÄùíÆ‡≤∫
4894 [p59] ‡∞Æ ‚ãÉ ‡µ´ùíÆ‡≤∫‡µàùíÆ‡≥Ä‡µØ ‚ãÉ ‡µ´ùíÆ‡≥Ä‡µàùíÆ‡≤∫‡µØ·âÅ
4895 [p59] (8)
4896 [p60] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4897 [p60] 25-27 November 2025, Innsbruck, Austria
4898 [p60] 59
4899 [p60] In this paper we restrict our analysis to ùë†ùëñùëö being
4900 [p60] the identity function: 1 when ùúé‡Øú
4901 [p60] ‡∞ê  ‡µå ùúé ‡Øù
4902 [p60] ‡∞ê and 0 otherwise.
4903 [p60] The STH similarity can be interpreted as the ratio
4904 [p60] between the time during which both series have the
4905 [p60] same state of interest and the time during which at least
4906 [p60] one of the series has a state of interest. The excluded
4907 [p60] state discards intervals. We define the Selective
4908 [p60] Temporal Hamming distance as
4909 [p60] ùëÜùëáùêªùê∑ ‡µå  1 ‡µÜ ùëÜùëáùêª.
4910 [p60] Property: (Normalized) STH values are in ·àæ0,1·àø.
4911 [p60] STH = 1 means that on all intervals, either both series
4912 [p60] have a state of interest and it is the same (ùúé‡Øú
4913 [p60] ‡∞ê  ‡µå ùúé ‡Øù
4914 [p60] ‡∞ê), or
4915 [p60] none of them has a state of interest. STH = 0 means
4916 [p60] that there is no interval during which ùë†‡Øú and ùë†‡Øù have the
4917 [p60] same value and this value is of interest.
4918 [p60] Property: (Definition) STH is undefined when for
4919 [p60] each interval ùúÑ‚àà‚Ñê , at least one series has a state in ùíÆ‡Ææ.
4920 [p60] This situation is similar to the one caused by missing
4921 [p60] data in real-valued timeseries. A good fallback value
4922 [p60] in this case is application dependent. The authors
4923 [p60] suggest zero (0) as default.
4924 [p60] Property: (Hamming equivalence) STH with all
4925 [p60] states ‚Äúof interest‚Äù ( ùíÆ‡ØÇ  ‡µå  ùíÆ)  i s  t h e  n o r m a l i z e d
4926 [p60] Temporal Hamming ùëõùëáùêª. As such, all properties of
4927 [p60] ùëõùëáùêª hold.
4928 [p60] Property: ( Jaccard equivalence ) for binary
4929 [p60] STE-ts, STH with ùíÆ‡ØÇ  ‡µå ·àº1·àΩ,ùíÆ ‡Øà  ‡µå ·àº0·àΩ,ùíÆ ‡Ææ  ‡µå  ‚àÖ i s  t h e
4930 [p60] Temporal Jaccard  ùëáùêΩ. A s  s u c h ,  a l l  p r o p e r t i e s  o f
4931 [p60] ùëáùêΩ hold.
4932 [p60] Property: (Metric) When ùíÆ‡Ææ  ‡µå  ‚àÖ and |ùíÆ‡Øà| ‡µë1 , the
4933 [p60] STHD distance satisfies both the positivity, symmetry.
4934 [p60] distinguishability, and triangular inequality. |ùíÆ‡Øà| ‡µë1
4935 [p60] can be relaxed if distinguishability i s  n o t  n e e d e d .  A
4936 [p60] proof is provided in [36].
4937 [p60] Property: (Complexity) Both [n]TH, TJ and STH
4938 [p60] have a linear complexity with respect to the number of
4939 [p60] intervals ‡∏´‚Ñê‡Øú‡Øù‡∏´ induced by ùë†‡Øú and ùë†‡Øù, so are ùí™·à∫ùëõ‡µÖùëö ·àª.
4940 [p60] Table 1 summarizes the various metrics and their
4941 [p60] properties, and the two state-of-the-art metrics without
4942 [p60] resampling, FTH [31] and TS [33], as reference.
4943 [p60] Table 1. Metrics properties, along with speed and precision experiments summary. ‚Äò*‚Äô means ‚Äòunder conditions‚Äô.
4944 [p60] 5. Experiments
4945 [p60] 5.1. Execution Time and Precision Benchmarks
4946 [p60] In this section we perform controlled experiments
4947 [p60] with simulated STE-ts to validate the two main
4948 [p60] benefits of STH over resampled metrics such as
4949 [p60] Hamming or Jaccard: execution time and precision.
4950 [p60] For value comparison purposes we use the Hamming
4951 [p60] configuration (
4952 [p60] ùíÆ‡ØÇ  ‡µå  ùíÆ) for STH, so STH = nTH in this
4953 [p60] section and its values are compared to the resampled
4954 [p60] normalized Hamming nH
4955 [p60] (P). Yet, similar results can be
4956 [p60] observed by choosing a Jaccard configuration
4957 [p60] (ùíÆ‡ØÇ  ‡µå  1, ùíÆ‡Øà  ‡µå  0) and comparing STH( = TJ)  t o
4958 [p60] resampled J(P).
4959 [p60] Results are obtained on a PC with an AMD Ryzen
4960 [p60] 5 pro 5650U 2.3 GHz processor and 16 Gb ram.
4961 [p60] Resampling is done with the pandas library [37, 38].
4962 [p60] Execution time vs. number of events
4963 [p60] We create Rts(n) a timeseries with n randomly
4964 [p60] occurring binary state change events spanning 30 days.
4965 [p60] We also create Tk, a timeseries spanning 30 days with
4966 [p60] 8640 evenly spaced (/5mins) events, with added
4967 [p60] random uniform time lags ranging from 1ms to 200 ms.
4968 [p60] Fig. 2 (left) shows average computation times (over
4969 [p60] 30 runs) of STH and nH(P) with 5 min resampling, for
4970 [p60] pairs Rts(n) vs. Rts(n), Rts(n) vs. Rts(1) and Rts(n) vs.
4971 [p60] Tk. Both metrics execution time grow linearly with the
4972 [p60] number of events in the series, confirming our
4973 [p60] complexity analysis. Fig. 2 (right) shows the execution
4974 [p60] time ratio t(nH
4975 [p60] (P))/t(STH). STH is between 3.5-14 times
4976 [p60] faster than nH(P) depending on the series. The largest
4977 [p60] improvements [7.5x-14x] are obtained when one of the
4978 [p60] series has only one event (Rts(1)).
4979 [p60] Fig. 2. Execution time (left) and ratio (right) for Resampled vs. Temporal Hamming distances for various pairs of series.
4980 [p61] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
4981 [p61] 25-27 November 2025, Innsbruck, Austria
4982 [p61] 60
4983 [p61] Execution time vs resampling period
4984 [p61] We now generate two periodic binary STE-ts
4985 [p61] spanning 1 month (Fig. 3): ùëÉùëÜ‡¨¥ with 14min period and
4986 [p61] 60 % duty cycle; and ùëÉùëÜ‡¨µ/‡¨∑ obtained by adding to ùëÉùëÜ‡¨¥ a
4987 [p61] lag of 1/3 of a period.
4988 [p61] Fig. 3. Two periodic STE-ts with matching
4989 [p61] states highlighted.
4990 [p61] We measure the average computation time over
4991 [p61] 30 runs of ùëõùêª‡µ´ùëÉùëÜ‡¨¥,ùëÉ ùëÜ‡¨µ/‡¨∑‡µØ, for a wide range of
4992 [p61] resampling periods, and compare it with that of
4993 [p61] STH = nTH. Results in Fig. 4 (left) confirm that nH(P)
4994 [p61] is ùí™·à∫ùëá/ùëÉ·àª: as the sampling period P decreases, it is up
4995 [p61] to 4950√ó slower.
4996 [p61] Metric precision
4997 [p61] By design, ùëÉùëÜ‡¨¥ and ùëÉùëÜ‡¨µ/‡¨∑ have the same state 1/3 of
4998 [p61] the time. Therefore, their normalized Hamming
4999 [p61] distance should be 2/3 if measured on an infinite
5000 [p61] number of periods. STHD = nTHD is computed and is
5001 [p61] 0.6666574 as expected. We compute nHD(P) f o r
5002 [p61] various sampling periods P and compare it with STHD.
5003 [p61] Fig. 4 (right) shows the impact of resampling distortion
5004 [p61] on nHD(P). For some sampling periods the series are
5005 [p61] even considered identical by nHD (nHD = 0)! STHD
5006 [p61] always guarantees the most accurate value.
5007 [p61] Table 1 summarizes the results of this section.
5008 [p61] 5.2. Experiments on New Analysis Capabilities
5009 [p61] In this section we illustrate the capability of STH to
5010 [p61] generalize Jaccard to non-binary series. We will use
5011 [p61] Clustering to highlight the impact of various choices of
5012 [p61] states to include in
5013 [p61] ùíÆ‡ØÇ and ùíÆ‡Ææ. For two public datasets
5014 [p61] below, raw data is first transformed to event transitions
5015 [p61] timeseries. We then compute a pairwise distance
5016 [p61] matrix for each pair of ST E-ts, for various distance
5017 [p61] metrics. We finally apply agglomerative clustering on
5018 [p61] resulting distance matrices and comment.
5019 [p61] Leveraging ùì¢
5020 [p61] ùë∞ to focus on specific states
5021 [p61] We can focus STH on specific states of interest ùíÆ‡ØÇ,
5022 [p61] the same way we use Jaccard to focus on the ‚Äú1‚Äù in
5023 [p61] binary series. We illustrate this on the US Weather
5024 [p61] Events dataset, employed in a study to discover
5025 [p61] propagation and influential patterns [39]. It contains a
5026 [p61] collection of weather events data across 2071 US
5027 [p61] locations. Possible states are: Cold, Fog, Snow, Hail,
5028 [p61] Rain, Storm, Precipitation, and Normal , which
5029 [p61] represents the absence of notable weather event. Our
5030 [p61] analysis focuses on 2019, for 1000 random locations.
5031 [p61] Fig. 4. Left: execution time (s) for resampled Hamming distance (blue) vs. STH=nTH (dashed red), for various sampling
5032 [p61] periods (x-axis). Bottom left: zoom on y-axis. Right: precision rate of nHD (1=no distortion) for various sampling periods.
5033 [p61] We run clustering with 3 settings of STH. The
5034 [p61] number of clusters k is selected from the dendrogram
5035 [p61] based on decreasing the optimal number found by
5036 [p61] Silhouette score until an acceptable macroscopic
5037 [p61] geographical view is found. Settings are:
5038 [p61] a)
5039 [p61] ùíÆ‡ØÇ ‡µåùíÆ  so STH = nTH (Hamming); k = 30;
5040 [p61] b) ùíÆ‡ØÇ ‡µåùíÆ \ ·àº ùëÅ ùëú ùëü ùëö ùëé ùëô ·àΩ , ‚Äà ùíÆ‡Øà  ‡µå ·àº ùëÅ ùëú ùëü ùëö ùëé ùëô ·àΩ; k = 30;
5041 [p61] c) ùíÆ‡ØÇ ‡µå ·àºùëÜùëõùëúùë§, ùêªùëéùëñùëô·àΩ,ùíÆ ‡Øà  ‡µå  ùëÜ \·àºùëÜùëõùëúùë§, ùêªùëéùëñùëô·àΩ; k = 30.
5042 [p61] Results are shown in Fig. 5, where each marker in
5043 [p61] the map represents a location, and its color and shape
5044 [p61] represent the cluster id. Whereas Hamming (a) reveals
5045 [p61] a large-size ‚Äòblue‚Äô cluster, in (b) since the Normal (no
5046 [p61] event) state is removed from ùíÆ
5047 [p61] ‡ØÇ, differences between
5048 [p61] abnormal states are highlighted, for example on the US
5049 [p61] east coast; in (c) only snow and hail are in ùíÆ‡ØÇ,
5050 [p61] highlighting differences in north-eastern regions but
5051 [p61] not so much in southern ones anymore.
5052 [p61] Leveraging ùì¢ùë¨ to handle ambiguity
5053 [p61] The new set ùíÆ‡Ææ can be used to deal with ambiguous
5054 [p61] states where it is preferrable to not derive any
5055 [p61] similarity value. We illustrate this on the MASS SS3
5056 [p61] Sleep Annotations  dataset, that contains sleep stages
5057 [p61] annotations for an entire sleep period of 62 patients
5058 [p62] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5059 [p62] 25-27 November 2025, Innsbruck, Austria
5060 [p62] 61
5061 [p62] [40]. The states are {? , W,1,2,3,R}. R (rapid eyes
5062 [p62] movement) is the state of interest, while W (awake),
5063 [p62] and the three levels of sleep depth (1, 2, 3) are not. The
5064 [p62] absence of annotation on an interval is replaced with a
5065 [p62] new Sleep stage ‚ÄúE‚Äù state.
5066 [p62] We compare two STH settings:
5067 [p62] a) ùíÆ‡ØÇ ‡µå·àº ùëÖ ·àΩ a n d ùíÆ‡Ææ ‡µå‚àÖ  s o  STH is equivalent to
5068 [p62] Jaccard on a preprocessed dataset where ùëÖ is
5069 [p62] mapped to 1 and all other states are
5070 [p62] mapped to 0;
5071 [p62] b) ùíÆ‡ØÇ  ‡µå ·àº ùëÖ ·àΩ, ùíÆ‡Øà  ‡µå ·àº ùëä,1 , 2 , 3 ·àΩ and ùíÆ‡Ææ  ‡µå ·àº ?,ùê∏·àΩ.
5072 [p62] Resulting similarities are then used in the
5073 [p62] agglomerative clustering algorithm, with a fixed
5074 [p62] n u m b e r  o f  c l u s t e r s  ( 8 ) .  T h e  p a t i e n t s ‚Äô  S T E - t s  a r e
5075 [p62] displayed in the heatmap of Fig. 6 in the agglomeration
5076 [p62] order. Clusters are delimited by white stripes. We
5077 [p62] observe that clusters in (b) seem purer in terms of
5078 [p62] content, and that some individuals with many missing
5079 [p62] or ambiguous values are better grouped. For example,
5080 [p62] the individual identified by the arrow was isolated in a
5081 [p62] single cluster with Jaccard, and is now in a
5082 [p62] consistent group.
5083 [p62] Fig. 5. US map with one marker per location, STH-based clusters identified by color and shape, for 3 sets of states of
5084 [p62] interest.
5085 [p62] Fig. 6. Patients‚Äô (y axis) sleep state across time (x axis) sorted by aggregation order with 8 clusters (white stripes).
5086 [p62] Left: Jaccard {R vs. all}; right: ùíÆ‡ØÇ ‡µå·àº ùëÖ ·àΩ , ùíÆ‡Ææ·àº? , ùê∏·àΩ (both black) ùíÆ‡Øà ‡µå ·àºùëä, 1,2,3·àΩ (four shades of blue).
5087 [p62] 6. Conclusion and Future Work
5088 [p62] In this paper we formalized state transition event
5089 [p62] timeseries (STE-ts), bridging event sequences  a n d
5090 [p62] categorical timeseries  formalisms in the context of
5091 [p62] Discrete Event Systems. We introduced the Selective
5092 [p62] Temporal Hamming  metric, generalizing Hamming
5093 [p62] and Jaccard for continuous time. As opposed to these
5094 [p62] resampled metrics where a tradeoff between speed and
5095 [p62] precision is required, our experiments on simulated
5096 [p62] datasets confirm that STH avoids distortion and is
5097 [p62] faster to compute, making it particularly suitable for
5098 [p62] large scale data analysis. Moreover, STH also brings
5099 [p62] Jaccard-like capabilities for non-binary series. Our
5100 [p62] clustering experiments on real world datasets
5101 [p62] highlighted the ability to focus on states of interest, and
5102 [p62] to handle ambiguous states ‚Äì both key features to inject
5103 [p62] subject matter expertise in the analysis. These
5104 [p62] properties make STH particularly well suited to
5105 [p62] compare STE-ts while not limiting its applicability to
5106 [p62] any categorical timeseries.
5107 [p62] In the future we plan to study how STH can be used
5108 [p62] in a kernel, e.g. for SVM classification tasks. Also, in
5109 [p62] this paper we restricted the state similarity weights sim
5110 [p62] to the identity matrix; it would be interesting to study
5111 [p62] the conditions on sim under which metric properties of
5112 [p62] STH still hold. Finally, finding a way to tolerate time
5113 [p62] shifts without impacting complexity significantly is
5114 [p62] another interesting challenge.
5115 [p62] References
5116 [p62] [1]. G. Haddeler, The analysis of discrete-event system in
5117 [p62] autonomous package delivery using legged robot and
5118 [p62] conveyor belt, arXiv preprint, 2021, arXiv:2101.12347.
5119 [p62] [2]. P. J. G. Ramadge, W. M. Wonham, The control of
5120 [p62] discrete event systems, Proceedings of the IEEE ,
5121 [p62] Vol. 77, Issue 1, 1989, pp. 81-98.
5122 [p62] [3]. W. Hu, et al., An application of advanced alarm
5123 [p62] management tools to an oil sand extraction plant,
5124 [p62] IFAC-PapersOnLine, Vol. 48, Issue 8, 2015,
5125 [p62] pp. 641-646.
5126 [p63] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5127 [p63] 25-27 November 2025, Innsbruck, Austria
5128 [p63] 62
5129 [p63] [4]. C.-H. Ng, S. Boon-Hee, Queueing Modelling
5130 [p63] Fundamentals: With Applic ations in Communication
5131 [p63] Networks, 2nd Ed., Wiley, 2008.
5132 [p63] [5]. J. Zhao, Y. L. Chen, et al., Modeling and control of
5133 [p63] discrete event systems using finite state machines with
5134 [p63] variables and their applications in power grids, Systems
5135 [p63] & Control Letters, Vol. 61, Issue 1, 2012, pp. 212-222.
5136 [p63] [6]. D. J. N. J. Soemers, et al., Spatial state-action features
5137 [p63] for general games, Artificial Intelligence , Vol. 321,
5138 [p63] 2023, 103937.
5139 [p63] [7]. T. F. Liao, et al., Sequence analysis: its past, present,
5140 [p63] and future, Social Science Research , Vol. 107, 2022,
5141 [p63] 102772.
5142 [p63] [8]. J. Opfer, K.-E. Gottschalk, Identifying discrete states of
5143 [p63] a biological system using a novel step detection
5144 [p63] algorithm, PLoS ONE, Vol. 7, Issue 11, 2012, e45896.
5145 [p63] [9]. C. G. Cassandras, S. Lafortune, Introduction to
5146 [p63] Discrete Event Systems, 2nd Ed., Springer, 2008.
5147 [p63] [10]. M. van de Velden, et al., A general framework for
5148 [p63] implementing distances for categorical variables,
5149 [p63] Pattern Recognition, Vol. 153, 2024, 110547.
5150 [p63] [11]. M. J. Warrens, Similarity  coefficients for binary data,
5151 [p63] PhD Thesis, University of Leiden, 2008.
5152 [p63] [12]. I. Morlini, S. Zani, A new  class of weighted similarity
5153 [p63] indices using polytomous variables, Journal of
5154 [p63] Classification, Vol. 29, 2012, pp. 199-226.
5155 [p63] [13]. T. Rahier, S. Mari√©, F. Forbes, A pre-screening
5156 [p63] approach for faster Bayesian network structure
5157 [p63] learning, in Machine Learning and Knowledge
5158 [p63] Discovery in Databases. Research Track, Springer,
5159 [p63] 2023, pp. 211-227.
5160 [p63] [14]. Z. ≈†ulc, H. ≈òezankov√°, Comparison of similarity
5161 [p63] measures for categorical data in hierarchical clustering,
5162 [p63] Journal of Classification, Vol. 36, 2019, pp. 58-72.
5163 [p63] [15]. M. Studer, G. Ritschard, What matters in differences
5164 [p63] between life trajectories: a comparative review of
5165 [p63] sequence dissimilarity measures, Journal of the Royal
5166 [p63] Statistical Society Series A: Statistics in Society ,
5167 [p63] Vol. 179, Issue 2, 2016, pp. 481-511.
5168 [p63] [16]. √Å. L√≥pez-Oriona, J. A. Vilar, P. D‚ÄôUrso, Hard and soft
5169 [p63] clustering of categorical time series based on two novel
5170 [p63] distances with an applicatio n to biological sequences,
5171 [p63] Information Sciences, Vol. 624, 2023, pp. 467-492.
5172 [p63] [17]. S. Charbonnier, N. Bouchair , P. Gayet, Fault isolation
5173 [p63] b y  c o m p a r i n g  a l a r m  l i s t s  using a symbolic sequence
5174 [p63] matching algorithm, IFAC Proceedings Volumes ,
5175 [p63] Vol. 47, Issue 3, 2014, pp. 7085-7090.
5176 [p63] [18]. M. Lucke, M. Chioua, et a l., Advances in alarm data
5177 [p63] analysis with a practical application to online alarm
5178 [p63] flood classification, Journal of Process Control ,
5179 [p63] Vol. 79, 2019, pp. 56-71.
5180 [p63] [19]. J. Wang, H. Li, J. Hua ng, C. Su, Association rules
5181 [p63] mining based analysis o f consequential alarm
5182 [p63] sequences in chemical processes, Journal of Loss
5183 [p63] Prevention in the Process Industries ,  V o l .  4 1 ,  2 0 1 6 ,
5184 [p63] pp. 178-185.
5185 [p63] [20]. Y. Laumonier, J.-M. Faure, et al., Discovering
5186 [p63] systematic relations between alarms for alarm flows
5187 [p63] reduction, in Proceedings of the 6 th International
5188 [p63] Conference on Control, Decision and Information
5189 [p63] Technologies (CoDIT‚Äô19), 2019, pp. 1055-1060.
5190 [p63] [21]. L. Lesnard, Setting cost in optimal matching to uncover
5191 [p63] contemporaneous socio-temporal patterns,
5192 [p63] Sociological Methods & Research , Vol. 38, Issue 3,
5193 [p63] 2010, pp. 389-419.
5194 [p63] [22]. S. Fr√ºhwirth-Schnatter , C. Pamminger, Model-based
5195 [p63] clustering of categorical time series, Bayesian Analysis,
5196 [p63] Vol. 5, Issue 2, 2010, pp. 345-368.
5197 [p63] [23]. M.-J. Lesot, M. Rifqi, H. Benhadda, Similarity
5198 [p63] measures for binary and numerical data: a survey,
5199 [p63] International Journal of Knowledge Engineering and
5200 [p63] Soft Data Paradigms, Vol. 1, Issue 1, 2009, pp. 63-84.
5201 [p63] [24]. S. R. Kondaveeti, et al., Graphical tools for routine
5202 [p63] assessment of industrial alarm systems, Computers &
5203 [p63] Chemical Engineering, Vol. 46, 2012, pp. 39-47.
5204 [p63] [25]. A. Sadr, M. Zolfaghari-Nejad, Weighted Hamming
5205 [p63] distance for PUF performance evaluation, Electronics
5206 [p63] Letters, Vol. 49, 2013, pp. 1376-1378.
5207 [p63] [26]. P. Montero, J. Vilar, TSclust: an R package for time
5208 [p63] series clustering, Journal of Statistical Software ,
5209 [p63] Vol. 62, Issue 1, 2014, pp. 1-43.
5210 [p63] [27]. C.-T. Do, et al., Multi-modal and multi-scale temporal
5211 [p63] metric learning for a robust time series nearest
5212 [p63] neighbors classification, Information Sciences ,
5213 [p63] Vol. 418-419, 2017, pp. 497-513.
5214 [p63] [28]. C. -C. M. Yeh, et al., Matrix Profile I: all pairs
5215 [p63] similarity joins for time series: a unifying view that
5216 [p63] includes motifs, discords and shapelets, in Proceedings
5217 [p63] of the IEEE 16 th International Conference on Data
5218 [p63] Mining (ICDM‚Äô16), 2016, pp. 1317-1322.
5219 [p63] [29]. P.-F. Marteau, Time warp edit distance with stiffness
5220 [p63] adjustment for time series matching, IEEE
5221 [p63] Transactions on Pattern Analysis and Machine
5222 [p63] Intelligence, Vol. 31, Issue 2, 2009, pp. 306-318.
5223 [p63] [ 3 0 ] .  S .  d e  W a e l e ,  P .  M .  T .  B r o e r s e n ,  E r r o r  m e a s u r e s  f o r
5224 [p63] resampled irregular data, IEEE Transactions on
5225 [p63] Instrumentation and Measurement ,  V o l .  4 9 ,  I s s u e  2 ,
5226 [p63] 2000, pp. 216-222.
5227 [p63] [ 3 1 ] .  C .  M o r e a u ,  e t  a l . ,  A  fuzzy generalisation of the
5228 [p63] Hamming distance for temporal sequences, in
5229 [p63] Proceedings of the IEEE International Conference on
5230 [p63] Fuzzy Systems (FUZZ-IEEE‚Äô21), 2021, pp. 1-8.
5231 [p63] [32]. Q. H. Liu, N. Nguyen, Nonuniform fast Fourier
5232 [p63] transform algorithm and its applications, in
5233 [p63] Proceedings of the IEEE Antennas and Propagation
5234 [p63] Society International Symposium, 1998.
5235 [p63] [33]. H. Reinhardt, J. -P. Bergmann, et al., Temporal analysis
5236 [p63] of event-discrete alarm data for improved
5237 [p63] manufacturing, Procedia CIRP , Vol. 93, 2020,
5238 [p63] pp. 742-746.
5239 [p63] [34]. M. M. Deza, E. Deza, Encyclopedia of Distances, 2 nd
5240 [p63] Ed., Springer, 2013.
5241 [p63] [35]. S. Kosub, A note on the triangle inequality for the
5242 [p63] Jaccard distance, Pattern Recognition Letters ,
5243 [p63] Vol. 120, 2019, pp. 36-38.
5244 [p63] [36]. S. Mari√©, Proof of metric properties for the selective
5245 [p63] temporal Hamming distan ce, HAL open archive
5246 [p63] preprint, 2025, https://hal.science/hal-05328460
5247 [p63] [37]. The pandas development team, pandas-dev/pandas:
5248 [p63] Pandas, Zenodo, 2020, DOI: 10.5281/zenodo.3509134
5249 [p63] [38]. W. McKinney, Data structures for statistical computing
5250 [p63] in Python, in Proceedings of the 9 th Python in Science
5251 [p63] Conference (SciPy‚Äô10), 2010, pp. 56-61.
5252 [p63] [39]. S. Moosavi, et al., Short and long-term pattern
5253 [p63] discovery over large-scale ge o-spatiotemporal data, in
5254 [p63] Proceedings of the 25 th ACM SIGKDD International
5255 [p63] Conference on Knowledge Discovery & Data Mining ,
5256 [p63] 2019, pp. 2727-2735.
5257 [p63] [40]. CEAMS, SS3 Sleep Annotations, Borealis, the
5258 [p63] Canadian Dataverse Repository, V1, 2022. DOI:
5259 [p63] 10.5683/SP3/YD8AYI.
5260 [p64] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5261 [p64] 25-27 November 2025, Innsbruck, Austria
5262 [p64] 63
5263 [p64] (020)
5264 [p64] Above, On, and Below the Surface: Data Services in Large
5265 [p64] Collaborative Projects
5266 [p64] V. Vassilev 1, G. Petkov 1, B. Kraychev 1, S. Haydushki 1, V. Sowinski-Mydlarz 2, S. Nikolov 1,
5267 [p64] N. Shivarov 1 and DiverSea Project Partners
5268 [p64] 1 Sofia University, GATE Institute, 5, James Bourchier Blvd, 1164 Sofia, Bulgaria
5269 [p64] 2 London Metropolitan University, 166-220 Holloway Road, N7 8DB London, UK
5270 [p64] Tel.: + 359 878057265
5271 [p64] E-mail: vassil.vassilev@gate-ai.eu
5272 [p64] Summary: The collaborative projects unde r the HORIZON Europe framework programs of the European Union typically
5273 [p64] involve a large number of partners from different countries. Th e data-centric projects amongst them often require integration
5274 [p64] of multiple data sources, diverse data formats in different modes of data collection, which leads to complex data management
5275 [p64] architectures and policies. This article explores some of the d esign decisions, organisational principles, and technological
5276 [p64] solutions for addressing them by focusing on integration and hy bridization. The research has been conducted while working
5277 [p64] on DiverSea, a project dedicated to the analysis of the biodiversity dynamics along the shores of Europe from the Black Sea,
5278 [p64] along the entire Mediterranean from East to West and all the wa y up to the North Sea, but the  takeaways are important for
5279 [p64] many other collaborative projects, which face similar issues not only in the water, but also on the land and in the air.
5280 [p64] Keywords: Data spaces, Data integration, Data storage and indexing, Visualization and data services, AI technologies.
5281 [p64] 1 Introduction
5282 [p64] Many joint projects funded in the framework of
5283 [p64] Horizon Europe of the EU include significant
5284 [p64] information processing, which requires a proper data
5285 [p64] management policy. This article presents our
5286 [p64] experience in this direction in DiverSea [1], one of the
5287 [p64] three projects dedicated specifically to the biodiversity
5288 [p64] of the coastal seas around Europe, its ecosystem, and
5289 [p64] dynamics (the other two being Marco Bolo [2] and
5290 [p64] OBAMA-NEXT [3]). We believe it applies not only to
5291 [p64] the specific maritime resear ch and innovation topics,
5292 [p64] but to many environmental projects in general as well.
5293 [p64] In data-centric projects, data management includes
5294 [p64] multiple data processing operations that start with the
5295 [p64] collection of raw data and end in the interpretation of
5296 [p64] the consolidated, integrat e d  a n d  p r e - p r o c e s s e d  d a t a
5297 [p64] and its analysis. In DiverSea, for example, the focus is
5298 [p64] on analysis of the dynamics of sea biodiversity along
5299 [p64] the shores of Europe fro m the Black Sea in the
5300 [p64] South-East along the entire Mediterranean coast, all
5301 [p64] the way up to the North Sea in the North-West. The
5302 [p64] data in such projects typically comes from separate
5303 [p64] case studies, conducted by the different project teams
5304 [p64] with catchment areas in close proximity to the partner
5305 [p64] locations. Due to the big diversity of data granularity,
5306 [p64] formats, modes of collection, and communication
5307 [p64] protocols, it is becoming important to organize the data
5308 [p64] management policies around Big Data Technologies,
5309 [p64] even if the volume of data is not big. This leads to the
5310 [p64] necessity to dedicate adequate technical resources
5311 [p64] which in DiverSea project is isolated in three separate
5312 [p64] workpackages (see Fig. 1). GATE Institute of Sofia
5313 [p64] University is responsible for coordination of all data
5314 [p64] management operations (Workpackage 2) with
5315 [p64] additional role in the preparation of the data for
5316 [p64] analysis (workpackages WP3 and WP4).
5317 [p64] 2. Design Considerations
5318 [p64] 2.1. Distributed vs. Centralized Data Management
5319 [p64] There are several different architectural solutions
5320 [p64] for Big Data Management, which lead to different
5321 [p64] organization of the data processing workflows and
5322 [p64] impose different requirements on the technical staff
5323 [p64] involved in data processing on each partner side.
5324 [p64] Centralized Architecture: Based on full
5325 [p64] centralization of the analytical operations and rooted in
5326 [p64] the oldest data warehousing [4]. Heavily used in many
5327 [p64] business projects at the end of the last century, further
5328 [p64] elaborated in the digital twins  [5] with many
5329 [p64] applications outside business. Light technical
5330 [p64] requirements for data providers, heavy expertise in the
5331 [p64] central coordinating site.
5332 [p64] Distributed Architecture: Full decentralization of
5333 [p64] the data processing with an equal role for all data
5334 [p64] providers. Modern solution, which leads to the
5335 [p64] implementation of complex systems such as data
5336 [p64] spaces [ 6 ]  a n d  blockchains [7] require significant
5337 [p64] technical capacity and dedicated resources from each
5338 [p64] participant.
5339 [p64] Hybrid Architecture: As a combination of the
5340 [p64] previous two, it has the advantage of being simpler
5341 [p64] than the distributed and more flexible than the
5342 [p64] centralized architectures, allowing distribution of data
5343 [p64] consumers‚Äô responsibilities while lowering the
5344 [p64] technical requirements of the data providers.
5345 [p65] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5346 [p65] 25-27 November 2025, Innsbruck, Austria
5347 [p65] 64
5348 [p65] The solution implemented in DiverSea is hybrid.
5349 [p65] Although there ar e clear benefits for more modern,
5350 [p65] fully distributed architecture, especially for projects on
5351 [p65] Pan-European level, the lead ing role in such projects
5352 [p65] as a rule is taken by non-technical organisations, and
5353 [p65] this, unfortunately, shifts the focus towards the data
5354 [p65] generation while somewhat neglecting the data
5355 [p65] management and analysis using the recent statistical
5356 [p65] and machine learning methodologies. In the context of
5357 [p65] the sea biodiversity, for example, it would be of
5358 [p65] strategic advantage to hav e one project, which unites
5359 [p65] the three complementing projects ‚Äì DiverSea,
5360 [p65] Obama-Next, and Marco-Bolo, and implement a
5361 [p65] c o m m o n  D a t a  S p a c e  o f  E u r o p e a n  S e a  a n d  O c e a n
5362 [p65] Biodiversity. This would allow combining the
5363 [p65] complementary both the data and the data services to
5364 [p65] implement more elaborate data management
5365 [p65] strategies, including more valuable data
5366 [p65] analytics pipelines.
5367 [p65] Fig. 1. Data Management Structure of DiverSea Project.
5368 [p65] 2.2. Data vs. Metadata
5369 [p65] The data-centric projects start with gathering the
5370 [p65] raw data from the field studies. The most important
5371 [p65] artefact from data managem ent point of view at this
5372 [p65] stage is the meta-data description, which is the entry
5373 [p65] point for developing the data models of the project data
5374 [p65] space. Following the common understanding that the
5375 [p65] meta-data is information about the data, however, it is
5376 [p65] often overlooked that the meta-data is not only about
5377 [p65] the structure and content of the physical data, but also
5378 [p65] a source of additional information to help building the
5379 [p65] data space architecture (see Table 1).
5380 [p65] Depending on the nature of data as specified in the
5381 [p65] metadata the data model can differ substantially ‚Äì it
5382 [p65] can be purely relational, object-relational or
5383 [p65] object-oriented, tree, graph or file-based. For
5384 [p65] well-structured datasets th e most appropriate is the
5385 [p65] purely relational format, since it is easily represented
5386 [p65] in standard relational databases, but when the data
5387 [p65] comes from sensors, drones or satellites more suitable
5388 [p65] is the object-relational, object-oriented or graph
5389 [p65] format. Completely unstructured data, like images and
5390 [p65] videos coming from sound recordings, scanning or
5391 [p65] photographing are naturally k ept in separate files,
5392 [p65] Finally, in the case of very large volume of data
5393 [p65] popular Big Data repositories such as Hadoop or
5394 [p65] Cassandra [8, 9] can be used instead. This data can be
5395 [p65] also complemented by external data, found in public
5396 [p65] repositories such as Copernicus or EmodNet.
5397 [p65] 2.3. Physical vs. Logical Model
5398 [p65] Although the initial efforts triggering the data space
5399 [p65] development belong to the domain specialists
5400 [p65] collecting the data, some input from the data analysts
5401 [p65] can make the meta-data more informative. The
5402 [p66] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5403 [p66] 25-27 November 2025, Innsbruck, Austria
5404 [p66] 65
5405 [p66] metadata can feed directly into the physical data
5406 [p66] model, but it can also help developing the domain
5407 [p66] ontology by providing information about the
5408 [p66] partitioning, taxonomic classification and
5409 [p66] dependencies across datasets. The ontological model
5410 [p66] of the data space allows to add two important additions
5411 [p66] to the data in it: conceptual abstraction, which can
5412 [p66] easily be modeled using taxonomies, and use cases for
5413 [p66] data processing, which can support the data processing
5414 [p66] and form a body of knowledge on its own on a
5415 [p66] conceptual level. A fragment of the ontological model
5416 [p66] of DiverSea presenting the most important EOV and
5417 [p66] EBV factors [10] of the analysis of the biodiversity is
5418 [p66] shown on Fig. 2.
5419 [p66] Table 1. Some important meta-data characteristics.
5420 [p66] Fig. 2. Data ontology (fragment).
5421 [p66] 2.3. Data Management Tasks
5422 [p66] The data space organization starts with the
5423 [p66] metadata obtained from the domain specialists, and the
5424 [p66] raw data generated within the field studies. The raw
5425 [p66] data is archived in its original format. Subsequently it
5426 [p66] is pre-processed and stored in suitable data
5427 [p66] repositories. The metadata is used also to create the
5428 [p66] data ontology which in addition to content information
5429 [p66] and logical structure of the data represents information
5430 [p66] about the datasets and the way they have been
5431 [p66] collected and transmitted (Fig. 3). This information is
5432 [p66] important for both the architecture of the data space
5433 [p66] and the subsequent data analysis. It is also used for
5434 [p66] some of the data services supported within the data
5435 [p66] space of the project.
5436 [p66] 3. DiverSea Data Space
5437 [p66] In this section we will present the core of the data
5438 [p66] space as implemented in DiverSea project.
5439 [p66] 3.1. Data Model
5440 [p66] The data model of DiverSea data space is hybrid.
5441 [p66] The structured data is modelled as purely relational
5442 [p66] (Fig. 4) and is stored in a separate relational database
5443 [p66] for each separate case study (https://datasets-
5444 [p66] diversea.gate-ai.eu/). On the other hand, the large files
5445 [p66] contain sound recordings from underwater drones and
5446 [p66] photogrammetric images from surface drones and
5447 [p66] satellites are stored directly in rge server file system
5448 [p67] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5449 [p67] 25-27 November 2025, Innsbruck, Austria
5450 [p67] 66
5451 [p67] and are accessible over the I nternet (https://datafiles-
5452 [p67] diversea.gate-ai.eu/).
5453 [p67] Fig. 3. Data Management Task Workflow.
5454 [p67] The model is relatively small due to the strict focus
5455 [p67] on sea biodiversity and its dynamics. It consists of only
5456 [p67] 70 tables, structured into 6 groups according to
5457 [p67] different criteria for clustering the information ‚Äì by
5458 [p67] content, technology, location, etc. We have decided to
5459 [p67] implement identical data models across all project case
5460 [p67] studies to enforce unification and support potential
5461 [p67] cross-location analysis. A lthough this creates some
5462 [p67] redundancy in the database implementations across the
5463 [p67] case studies, it also simplifies the maintenance.
5464 [p67] 3.2 Data Repositories
5465 [p67] Since DiverSea project case studies generate only
5466 [p67] well-structured or completely unstructured data, we
5467 [p67] adopted PostgreSQL as a repository for storing the
5468 [p67] structured data after some pre-processing and Internet
5469 [p67] file system for storing the unstructured data in raw
5470 [p67] format. Both repositories are maintained centrally and
5471 [p67] have identical structure which simplifies the
5472 [p67] maintenance.
5473 [p67] Fig. 4. Database for storing the pre-processed data.
5474 [p67] 3.3. Data Ontology
5475 [p67] DiverSea data ontology is a graph model which
5476 [p67] provides higher level model of the concepts and
5477 [p67] relationships between them within the DiverSea data
5478 [p67] space. It supports not only the data sharing but also
5479 [p67] other data services convenient for the subsequent data
5480 [p67] analysis. It has been developed using Prot√©g√© and is
5481 [p67] currently stored as pure RDF graph in the graph
5482 [p67] database GraphDB.
5483 [p67] 3.4. Data Services
5484 [p67] Although the data space is primarily concerned
5485 [p67] with collecting and sharin g data, it can also provide
5486 [p68] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5487 [p68] 25-27 November 2025, Innsbruck, Austria
5488 [p68] 67
5489 [p68] some useful data services. They incorporate expert
5490 [p68] knowledge from the problem domain, information
5491 [p68] about the environment, as well as technical
5492 [p68] information in supports of the data analysis. DiverSea
5493 [p68] data space currently supports five data services which
5494 [p68] allow quick look at the data, the environment in which
5495 [p68] the data has been collected and the context of its use.
5496 [p68] Raw Data Archive
5497 [p68] The raw data obtained from the project is kept in its
5498 [p68] original format in a file repository. It can be browsed
5499 [p68] from standard Web browser for inspection by the data
5500 [p68] providers, for initial review by the data consumers and
5501 [p68] auditing purposes. The repository is implemented as a
5502 [p68] protected file system, accessible over the Internet
5503 [p68] (Fig. 5). It is government by a system of priorities
5504 [p68] agreed by the data providers, but without write
5505 [p68] permission to protect the original data. At the end of
5506 [p68] the project some of this data will be published on open
5507 [p68] repositories such as EnmodNet and Copernicus for use
5508 [p68] by researchers.
5509 [p68] Fig. 5. Internet File System for Storing Raw Data.
5510 [p68] Structured Data Repository
5511 [p68] The raw data in DiverSea case studies does not
5512 [p68] grow very quickly due to the few periodic intakes of
5513 [p68] the fields teams, so no scalability issues were
5514 [p68] encountered by the data man agement team. Since the
5515 [p68] sensor and measurement data produced within the
5516 [p68] separate case studies is either in well-structured format
5517 [p68] (typical for EOV and EBV measurements), or in
5518 [p68] completely unstructured format (for various
5519 [p68] photogrammetric and scan data from cameras, drones
5520 [p68] and satellites), we combined the raw data file
5521 [p68] repository for unstructured data with a relational
5522 [p68] database for the structured data.  Due to the relatively
5523 [p68] small amount of data we have chosen PostgreSQL
5524 [p68] DBMS as a database tool to accommodate the
5525 [p68] structured data after pre liminary processing for
5526 [p68] filtering, completion and unification. The access to the
5527 [p68] databases of the case studies is granted to all project
5528 [p68] partners over the Internet through the PostgreSQL
5529 [p68] command interface in accordance with a flat profile
5530 [p68] model. The partners can search the data and export
5531 [p68] tables to support their analysis using standard SQL
5532 [p68] language (Fig. 6).
5533 [p68] Small problem in this solution is the security issue
5534 [p68] created by the use of database console for accessing the
5535 [p68] data ‚Äì the authorized users can enter the database over
5536 [p68] the Internet, which opens the door for potential
5537 [p68] malicious interventions through the DBMS system.
5538 [p68] This problem can be fixed by the use of VPN, but it
5539 [p68] would complicate the operations. The alternative is tio
5540 [p68] build a separate informati on system frontend with
5541 [p68] strict profile control, but it would be an overkill
5542 [p68] considering the relatively small amount of data and the
5543 [p68] limited project resources.
5544 [p68] Fig. 6. Database Repository for Structured Data.
5545 [p68] Mapping Data Sources
5546 [p68] Geographic localization and mapping of the project
5547 [p68] data sources is important for both external presentation
5548 [p68] of the case studies and for internal preparation of the
5549 [p68] data analysis. We have experimented with several
5550 [p68] m a p p i n g  s e r v i c e s  ( E S R I ,  C e s i u m ,  O p e n  S t r e e t  M a p )
5551 [p68] before selecting our final c hoice, TerriaJS (Fig. 7). It
5552 [p68] has some limitation in comparison with other services,
5553 [p68] but also advantages ‚Äì it is compatible with many
5554 [p68] mapping formats, and provides free maps of the seas,
5555 [p68] including maps from EmodNet which are of particular
5556 [p68] interest for the project.
5557 [p68] Fig. 7. Data Sources on the Map.
5558 [p68] Looking for Answers Outside the Data Space
5559 [p68] The increased competence of the LLM models
5560 [p68] provides new possibilities for expanding the data
5561 [p68] exploration and analysis beyond the limitation of the
5562 [p69] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5563 [p69] 25-27 November 2025, Innsbruck, Austria
5564 [p69] 68
5565 [p69] command languages. Fig. 8 shows a session of
5566 [p69] interaction with DiverSea chatbot, which is integrated
5567 [p69] with the data space. The bot possesses a broad
5568 [p69] knowledge base about the sea, its marine life, and the
5569 [p69] project case studies and provides the end users with an
5570 [p69] immersive experience of the Earth's water basins. Our
5571 [p69] bot supports interaction in most European languages,
5572 [p69] this making it a valuable resource for learning and
5573 [p69] discovery of relevant information in an easy way.
5574 [p69] Semantic Search
5575 [p69] DiverSea data space stores data which can be
5576 [p69] analysed using different methods ‚Äì correlation across
5577 [p69] locations, discovering historical trends, estimating
5578 [p69] impacts of the environment changes and human
5579 [p69] activities, etc. The physical level of the dataspace does
5580 [p69] not support adequately the search and retrieval of data
5581 [p69] relevant to these use cases due to the limited
5582 [p69] information in the metadata and the impossibility to
5583 [p69] establish cross dependencies between datasets. But
5584 [p69] more importantly, for successful analysis of the data it
5585 [p69] is required to have a good knowledge of the data, its
5586 [p69] location and relevance as well as intimate
5587 [p69] understanding of its internal representation within the
5588 [p69] numerous data repositories.
5589 [p69] Fig. 8. Looking for Answers from LLMs.
5590 [p69] Key to address this problem is the utilization of the
5591 [p69] data ontology for searching logically within the
5592 [p69] ontology instead of searching the physical data inside
5593 [p69] the databases. The semantic search service enables
5594 [p69] analysts to explore the data from the perspective of its
5595 [p69] relevance to the analytical use cases, bypassing the use
5596 [p69] of exploratory tools and the knowledge of protocols for
5597 [p69] interaction. This leads to a hybrid search approach in
5598 [p69] which the necessary data is retrieved after conceptual
5599 [p69] search within the data space ontology, which acts as a
5600 [p69] semantic index of the data.
5601 [p69] To implement this concept we expanded the
5602 [p69] ontology with the most common use cases for data
5603 [p69] analysis and stored it in a dedicated graph database,
5604 [p69] GraphDB, which exposes SPARQL as a standard
5605 [p69] query language for searching the knowledge graphs.
5606 [p69] We have implemented a database plugin, which hides
5607 [p69] the command interface behind a graphical UI capable
5608 [p69] of translating the menu-driven request form into free
5609 [p69] format SPARQL queries and execties them against the
5610 [p69] ontology (Fig. 9).
5611 [p69] Currently our plugin allows to make queries
5612 [p69] focused on the datasets needed for executing analytical
5613 [p69] use cases, but we are continuing working on expanding
5614 [p69] the plugin with query templ ates for seeking specific
5615 [p69] descriptions of the parameters, such as location, time,
5616 [p69] specific descriptions and dependencies.
5617 [p69] 4. Current State and Future Development
5618 [p69] The initial version of DiverSea data space has been
5619 [p69] completed and validated by the internal data providers
5620 [p69] and data consumers. All data in the data space is
5621 [p69] available to the project participants over the Internet in
5622 [p69] both raw and structured formats according to the
5623 [p69] agreed access profiles. Curre ntly we are working on
5624 [p69] the second version of the data space, which
5625 [p69] incorporates the additional data services in support of
5626 [p69] the data analysis demonstrated here.
5627 [p69] Fig. 9. Semantic Search for Datasets.
5628 [p69] To make this experience really useful we are in
5629 [p69] conversation with our partners on the extension of the
5630 [p69] data space ontology with mini ontological models of
5631 [p69] the analytic use cases, so that we can search not only
5632 [p69] for datasets which are needed but also for direct and
5633 [p69] indirect links within the ontology. At the final phase of
5634 [p69] the project we will submit curated datasets to be
5635 [p69] published in the public repositories focused on the
5636 [p69] biodiversity such as Copernicus and EmodNet.
5637 [p69] 5. Conclusion
5638 [p69] This article presents the experience of the DiverSea
5639 [p69] project data management team in developing data
5640 [p69] spaces within collaborative projects with multiple data
5641 [p69] providers and data consume rs, real data collected in
5642 [p69] different formats and modes of operation. Although
5643 [p69] focused primarily on DiverSea, we believe that our
5644 [p69] methodology for data management, some of our ideas
5645 [p70] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5646 [p70] 25-27 November 2025, Innsbruck, Austria
5647 [p70] 69
5648 [p70] for organizing the data spaces and very real experience
5649 [p70] are valuable for other d ata-centric collaborative
5650 [p70] projects.
5651 [p70] Acknowledgements
5652 [p70] The DiverSea project is funded by the European
5653 [p70] Union under the Horizon Europe Programme, Grant
5654 [p70] Agreement No. 101082004. Views and opinions
5655 [p70] expressed here are, however, those of the authors only
5656 [p70] and do not necessarily reflect those of the European
5657 [p70] Research Executive Ag ency (REA) nor the
5658 [p70] project partners.
5659 [p70] References
5660 [p70] [1]. DIVERSEA Project, Integ rated observation, mapping,
5661 [p70] monitoring and prediction for functional biodiversity of
5662 [p70] coastal seas, https://www.ntnu.edu/diversea
5663 [p70] [2]. MARCO-BOLO Project, Marine coastal biodiversity
5664 [p70] long-term observations: strengthening biodiversity
5665 [p70] observation in support of decision making,
5666 [p70] https://marcobolo-project.eu/
5667 [p70] [3]. OBAMA-NEXT Project, Observing and mapping
5668 [p70] marine ecosystems ‚Äì next generation tools,
5669 [p70] https://obama-next.eu/
5670 [p70] [4]. R. Kimball, M. Ross, The Data Warehouse Toolkit:
5671 [p70] The Definitive Guide to Dimensional Modeling, 3 rd
5672 [p70] Ed., Wiley, 2013.
5673 [p70] [5]. R. Khan, R. Young, Digital Twin & Digital
5674 [p70] Development's Handbook, Independently published ,
5675 [p70] 2023.
5676 [p70] [6]. International Data Spaces Association, Reference
5677 [p70] Architecture Model, GitHub Repository,
5678 [p70] https://github.com/International-Data-Spaces-
5679 [p70] Association/IDS-RAM_4_0/tree/main/documentation
5680 [p70] [7]. I. Bashir, Mastering Blockchain: Inner workings of
5681 [p70] blockchain, from cryptography and decentralized
5682 [p70] identities, 4th Ed., Packt Publishing, 2023.
5683 [p70] [8]. A. Anjomshoaa, et al., Data platforms for data spaces,
5684 [p70] in Data Spaces: Design, Deployment, and Future
5685 [p70] Directions (E. Curry, et al., Eds.), Springer, 2022,
5686 [p70] pp. 27-39.
5687 [p70] [9]. V. Vassilev, V. Sowinski-Mydlarz, et al., Building a
5688 [p70] big data platform using software without license costs,
5689 [p70] in Open Source Horizons-Challenges and
5690 [p70] Opportunities for Collaboration and Innovation
5691 [p70] (L. Castro, Ed.), IntechOpen, 2024.
5692 [p70] [10]. F. Muller-Karger, et al.,  Advancing marine biological
5693 [p70] observations and data requirements of the
5694 [p70] complementary essential ocean variables (EOVs) and
5695 [p70] essential biodiversity variables (EBVs) frameworks,
5696 [p70] Frontiers in Marine Science, Vol. 5, 2018, 211.
5697 [p71] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5698 [p71] 25-27 November 2025, Innsbruck, Austria
5699 [p71] 70
5700 [p71] (021)
5701 [p71] Quantifying the Unstructured Narrative of Patient Care in EHR Data
5702 [p71] Edward Kim 1,2, Richard Foty 1 and Vicki Seyfert-Margolis 1
5703 [p71] 1 RespondHealth, Bethesda, MD, USA
5704 [p71] 2 Department of Computer Science, Drexel University, Philadelphia, PA, USA
5705 [p71] E-mail: ek826@drexel.edu, rich.foty@respondhealth.net, vicki.seyfert-margolis@respondhealth.net
5706 [p71] Summary: Electronic Health Records (EHR s) contain vast amounts of patie nt information, yet much of their clinically
5707 [p71] relevant content is locked within unstructured narrative text. This case study applies a generative AI-based pipeline to extract,
5708 [p71] link, and verify medical concepts from unstructured clinical notes, evaluating their alignment with structured EHR data. Using
5709 [p71] over 110000 visits from more than 1000 practices, with a focus on 5000 Parkinson‚Äôs disease patients, we quantify information
5710 [p71] volume, novelty, and c onsistency. Findings reveal significant r edundancy, low novelty in long itudinal documentation, and
5711 [p71] persistent gaps between narrative  and coded data. Our approach demonstrates how generative AI can surface high-value
5712 [p71] insights, improve structured and unstructured integration, and reduce the documentation burden in clinical practice.
5713 [p71] Keywords: Generative AI, Named Entity Extraction, Electronic Health Records, Data Mining
5714 [p71] 1. Introduction
5715 [p71] EHR systems are designed to provide a
5716 [p71] comprehensive and up-to-da te account of a patient‚Äôs
5717 [p71] medical history, supporting both clinical
5718 [p71] decision-making and resear ch. In practice, however,
5719 [p71] these records are a heterogeneous mix of structured
5720 [p71] fields and unstructured narrative text, with the latter
5721 [p71] comprising roughly 80 % of the clinically relevant
5722 [p71] content [1]. While narrative documentation allows
5723 [p71] clinicians to capture nuanced details, it also leads to
5724 [p71] challenges in data extraction, clinician burden,
5725 [p71] redundancy, and misalignment with coded data. For
5726 [p71] example, clinicians now spend more time on the
5727 [p71] computer than with patients, i.e. nearly six hours of an
5728 [p71] eleven hour work day is consumed by EHR tasks,
5729 [p71] requiring an additional 1.4 hours of after clinic hour
5730 [p71] time [3]. The growing complexity of EHR content,
5731 [p71] coupled with the time burden placed on clinicians,
5732 [p71] underscores the need for advanced, scalable solutions
5733 [p71] that can efficiently transform unstructured narratives
5734 [p71] into actionable information.
5735 [p71] Generative AI offers a promising path forward.
5736 [p71] Building on recent advances in large language models
5737 [p71] (LLMs), these systems can extract structured concepts,
5738 [p71] perform verification, and reconcile discrepancies
5739 [p71] across data modalities. This study develops and
5740 [p71] evaluates a generative AI p ipeline to characterize
5741 [p71] information volume, identify novel content, and assess
5742 [p71] consistency between narrative notes and structured
5743 [p71] EHR fields.
5744 [p71] 2. Background
5745 [p71] 2.1. What is in an EHR Record?
5746 [p71] EHRs capture a vast and massive array of patient
5747 [p71] data. Structured fields include demographics,
5748 [p71] ICD-coded diagnoses, problem lists, allergies,
5749 [p71] medications, vital signs, laboratory results, imaging,
5750 [p71] and procedure codes. However, approximately 80 % of
5751 [p71] EHR data is unstructured free text, such as clinical
5752 [p71] notes, imaging/procedure reports, and correspondence
5753 [p71] [5]. This imbalance means that most clinical nuance
5754 [p71] and context reside in narr ative form, which is not
5755 [p71] readily computable. For example, a single patient in
5756 [p71] a pediatric ICU can generate over 1400 new data points
5757 [p71] per day, and a physician may be exposed to
5758 [p71] 16000-32000 data points in a single shift [6]. Large
5759 [p71] hospital EHRs may contain over 10000 unique medical
5760 [p71] codes and thousands of lab variables [7]. And despite
5761 [p71] the availability of these structured fields, clinicians
5762 [p71] often prefer narrative documentation for its flexibility
5763 [p71] and ability to capture details such as social
5764 [p71] determinants of health or diagnostic uncertainty [8].
5765 [p71] Given this preference in documentation, a growing
5766 [p71] concern in EHR documentation is the prevalence of
5767 [p71] redundant content, often referred to as ‚Äúnote bloat‚Äù.
5768 [p71] Modern EHRs facilitate copy-paste and auto-import,
5769 [p71] which can reduce typing but also lead to lengthy,
5770 [p71] repetitive notes. A UCSF study of 23000 inpatient
5771 [p71] notes found that only 18 % of note text was newly
5772 [p71] authored, with 82 % copied or imported  [ 9 ] .
5773 [p71] Residents had the lowest proportion of new text
5774 [p71] (12 %), and more than half of their notes were copied
5775 [p71] forward. A 2022 analysis of 104 million notes at Penn
5776 [p71] Medicine found that 50 % of note text was duplicated,
5777 [p71] with duplication split between self and other authors
5778 [p71] [10]. Outpatient note length increased by 60 % from
5779 [p71] 2009 to 2018, and redundancy rose from 48 % to 59 %
5780 [p71] [4]. By 2018, only 29 % of outpatient note text was
5781 [p71] original. This heavy reuse can obscure new
5782 [p71] information, propagate errors, and make it difficult for
5783 [p71] clinicians to identify salient changes. The literature
5784 [p71] highlights a tension between efficiency (via reuse) and
5785 [p71] the risk of clutter and clinical error [10, 11, 5].
5786 [p71] The informational burden is amplified by
5787 [p71] discrepancies between wha t clinicians write and
5788 [p71] what they (or downstream coders) enter as discrete
5789 [p71] structured data . Large-scale concept-coverage
5790 [p71] studies now show that only 13 % of clinical concepts
5791 [p72] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5792 [p72] 25-27 November 2025, Innsbruck, Austria
5793 [p72] 71
5794 [p72] described in free-text have a corresponding structured
5795 [p72] code, and just 7 % of note-level concepts surface in
5796 [p72] structured form at the encounter level [2]. For example,
5797 [p72] a diagnosis may be mentioned in a note but not coded,
5798 [p72] or vice versa. Integrated workflows that link note
5799 [p72] writing and coding improve concordance (up to 88 %
5800 [p72] match), but perfect alignment is rare [11]. Essential
5801 [p72] details are often ‚Äúhidden‚Äù in unstructured notes,
5802 [p72] especially when no appropriate code exists or when
5803 [p72] expressing uncertainty. Conversely, nearly one-quarter
5804 [p72] of medications listed in progress notes fail to reconcile
5805 [p72] with the formal EHR medication list, exposing patients
5806 [p72] to safety risks when decision-support logic relies
5807 [p72] solely on coded inputs [12].
5808 [p72] 2.2. How is AI Used to Improved EHR
5809 [p72] Documentation?
5810 [p72] Given the dominance of unstructured text, natural
5811 [p72] language processing (NLP) and machine learning are
5812 [p72] essential for extracting clinical information from notes.
5813 [p72] Early systems used keyword and rule-based
5814 [p72] approaches, but recent a dvances leverage deep
5815 [p72] learning and transformer models (e.g., ClinicalBERT,
5816 [p72] GatorTron) trained on massive corpora of clinical text
5817 [p72] [1, 9]. Applications include computational
5818 [p72] phenotyping, adverse event detection, cohort
5819 [p72] identification, and automated chart review. For
5820 [p72] example, GatorTron was trained on 82 billion words of
5821 [p72] de-identified clinical notes and achieved state-of-the-
5822 [p72] art performance on multiple NLP tasks [8]. Integrating
5823 [p72] NLP-derived features with structured data improves
5824 [p72] predictive modeling and research [1]. New
5825 [p72] interventions such as medical scribes, voice
5826 [p72] recognition, team documentation, and novel note
5827 [p72] formats (e.g., APSO) have been explored to improve
5828 [p72] efficiency and satisfaction [13]. Integrated workflows,
5829 [p72] where coding and note writing are combined, improve
5830 [p72] accuracy and reduce redu ndancy [11]. However,
5831 [p72] challenges remain in accuracy, generalizability,
5832 [p72] interpretability, and privacy.
5833 [p72] Traditional NLP approaches have attempted to
5834 [p72] bridge this gap, but often require intensive annotation
5835 [p72] and task-specific model training. Recent advances in
5836 [p72] Large Language Models (LLMs) and other generative
5837 [p72] AI provides an opportunity to address these limitations
5838 [p72] but require careful attention to data quality (especially
5839 [p72] LLM hallucinations), determinism of outputs, privacy,
5840 [p72] and interpretability. The relationship between
5841 [p72] narrative notes and structured data is an ongoing area
5842 [p72] of focus, where claims require support and alignment,
5843 [p72] yet are often lacking, with implications for both
5844 [p72] clinical care and research . Additionally, with the
5845 [p72] exponential improvement in generative AI towards
5846 [p72] generalizability, modular and trusted frameworks are
5847 [p72] needed to leverage these capabilities for clinical data
5848 [p72] extraction and verification [15, 16]. In this work, we
5849 [p72] present a generative AI-based pipeline to extract, link,
5850 [p72] and verify medical concepts from unstructured clinical
5851 [p72] notes, evaluating their alignment with structured EHR
5852 [p72] data. Using over 110000 visits from more than
5853 [p72] 1000 practices, with a focus on 5000 Parkinson‚Äôs
5854 [p72] disease patients, we quantify information volume,
5855 [p72] novelty, and consistency of the data utilizing
5856 [p72] generative AI.
5857 [p72] 3. Methodology
5858 [p72] In this case study, we utilized generative AI to
5859 [p72] process unstructured clinical notes from over
5860 [p72] 110000 encounters across three commercial EHR
5861 [p72] platforms. A Parkinson‚Äôs disease cohort of
5862 [p72] 5000 patients was selected based on ICD-10 codes
5863 [p72] G20‚ÄìG22, yielding 11250 encounters for detailed
5864 [p72] analysis. Our goal was three-fold. First, we wanted to
5865 [p72] quantify how computationally intensive it would be to
5866 [p72] use Large Language Models (LLMs) to temporally
5867 [p72] process, extract, and veri fy EHR data. Second, we
5868 [p72] wanted to quantify the amount of copy & paste in the
5869 [p72] record to see if we can automatically identify ‚Äònew‚Äô
5870 [p72] and relevant information. Third, our goal was to
5871 [p72] quantify the concordance (and discrepancy) between
5872 [p72] the coded data and unstructured clinical notes.
5873 [p72] The first stage of the pipeline consisted of a
5874 [p72] structured JSON Extraction of clinical entities. We
5875 [p72] built a named entity recognition (NER) LLM extractor
5876 [p72] via prompting to identify key clinical entities,
5877 [p72] including medications, family history, disease status,
5878 [p72] adherence, phenotypes, and self-reported symptoms.
5879 [p72] Due to the fact that this is structured extraction, most
5880 [p72] off the shelf open source and cloud LLM APIs are
5881 [p72] usable [14]. There are two major issues around the use
5882 [p72] of LLMs for entity extraction. First are around the
5883 [p72] problems of trust and accuracy. We extensively
5884 [p72] address this issue in our previous work, see Kim et al.
5885 [p72] [15]. The second issue is around the efficiency of these
5886 [p72] methods, i.e. quantity, cost, and time. Here we quantify
5887 [p72] the total number of tokens that our processes take when
5888 [p72] extracting entities and validating these entities,
5889 [p72] see Fig. 1.
5890 [p72] We note that these token totals processed are across
5891 [p72] all categories that we choose to extract and also
5892 [p72] account for the verification of these extractions via
5893 [p72] another LLM extraction loop. Thus, the total number
5894 [p72] of words in the EHR are si gnificantly fewer, but the
5895 [p72] proportions and relative growth year over year are
5896 [p72] maintained. For the total breakdown of the tokens per
5897 [p72] category and verification, see Fig. 2. In our extraction,
5898 [p72] we ask for JSON categories such as the entity name,
5899 [p72] status, is_new_information, additional_information,
5900 [p72] and atomic_statment  (for verification). Notably, the
5901 [p72] verification of extractions consume the greatest
5902 [p72] number of tokens, but are necessary for generative AI
5903 [p72] process. As noted by the relative increase in the size of
5904 [p72] the notes, there is a fairly significant jump in the past
5905 [p72] couple years, presumably around the time of the
5906 [p72] introduction of AI tools (like ambient listening and
5907 [p72] scribing tools); however, to confirm, more analysis
5908 [p72] would be required.
5909 [p72] Information novelty was assessed longitudinally by
5910 [p72] comparing sequential visits for each patient, see Fig. 3.
5911 [p72] New information is quantified according to the entities
5912 [p73] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5913 [p73] 25-27 November 2025, Innsbruck, Austria
5914 [p73] 72
5915 [p73] extracted at each visit that was not present in previous
5916 [p73] visits. For patients with 4 or more visits in the history,
5917 [p73] our data shows that only 13 % of each clinical note
5918 [p73] is actually new. New information is defined as entities
5919 [p73] that did not exist in previous visits. Entities that
5920 [p73] changed status are considered new information. While
5921 [p73] this does not directly indicate copy-paste forwarding,
5922 [p73] it is indicative and support s the research that shows
5923 [p73] that only 18 % of the clinical note is newly
5924 [p73] authored [9].
5925 [p73] Fig. 1. Average input, output, and total tokens per clinical visit by year. The plot shows a steady increase in the average
5926 [p73] number of tokens per visit, with a marked acceleration after 2015 and again in 2023. This trend highlights the expanding
5927 [p73] volume of unstructured data in EHRs.
5928 [p73] Fig. 2. Token distribution by extraction category. We break down the t otal number of input and output tokens processed
5929 [p73] by each extraction module, incl uding both regular and verificat ion extractions. Verification extractions account
5930 [p73] for the largest share of tokens, reflecting the resource intens ity of consistency checks across diagnoses and procedures.
5931 [p73] The figure highlights the diversity of extraction tasks and the substantial computational load associated with large-scale EHR
5932 [p73] narrative analysis.
5933 [p73] Finally, we built consistency verifiers and checks
5934 [p73] to compare the diagnoses and procedures described in
5935 [p73] the clinical note to the coded diagnosis and procedure
5936 [p73] data. The formal diagnoses in the clinical visit are
5937 [p73] captured by ICD10 codes and the procedures are
5938 [p73] captured by the CPT codes. We look at the diagnosis
5939 [p73] and procedure and run another LLM call that rates
5940 [p73] whether or not the code is, 3 = fully supported by the
5941 [p73] unstructured note, 2 = partially supported,
5942 [p73] 1 = potentially inferable but not partially or directly
5943 [p74] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
5944 [p74] 25-27 November 2025, Innsbruck, Austria
5945 [p74] 73
5946 [p74] mentioned, and 0 = not supported at all. We discovered
5947 [p74] low average verification scores for diagnoses (1.01 out
5948 [p74] of 3) and procedures (0.88 out of 3) indicating that, on
5949 [p74] average, most codes are only implied or partially
5950 [p74] supported by the clinical t ext, rather than being
5951 [p74] explicitly documented, see Table 3. Again, this
5952 [p74] supports the literature stating that only 13 % of clinical
5953 [p74] concepts described in free-text have a corresponding
5954 [p74] structured code [2].
5955 [p74] Fig. 3. Temporal visit distribution: Avera ge items per visit, average n ew items per visit, and percentage of new information
5956 [p74] by visit number. Bar plots show t he average number of extracted  items (blue) and average number of new items (orange)
5957 [p74] for each visit, while the gold line indicates the percentage of  new information contributed per visit. Extraction counts are
5958 [p74] annotated below each bar. The first visit yields the highest pr oportion of new information (61 %), with subsequent visits
5959 [p74] showing a marked decline in novelty (13‚Äì 21 %), reflecting the prevalence of redundant docum entation and copy-forward
5960 [p74] practices in longitudinal EHR records.
5961 [p74] Table 1.  Consistency verification for diagnoses
5962 [p74] and procedures. ‚ÄúTotal Items‚Äù is the number of extracted
5963 [p74] codes; ‚ÄúTotal Items %‚Äù is th e proportion of all extracted
5964 [p74] statements; ‚ÄúNew Information Items‚Äù and ‚ÄúNew Information
5965 [p74] %‚Äù indicate the number and proportion of codes representing
5966 [p74] new information; ‚ÄúAvg. Verification Score‚Äù is the average
5967 [p74] consistency score per code.
5968 [p74] Category Total
5969 [p74] Items
5970 [p74] Total
5971 [p74] Items (%)
5972 [p74] Avg Verification
5973 [p74] Score
5974 [p74] Diagnoses 469446 19.24 % 1.01
5975 [p74] Procedures 213472 8.75 % 0.88
5976 [p74] 4. Conclusions
5977 [p74] This study reinforces that EHRs remain dominated
5978 [p74] by unstructured, often redundant content, with
5979 [p74] substantial gaps between narrative documentation and
5980 [p74] structured coding. Careful construction and utilization
5981 [p74] o f  g e n e r a t i v e  A I  o f f e r s  a  s c a l a b l e  s o l u t i o n  t o  t h e s e
5982 [p74] challenges, enabling precise extraction,
5983 [p74] standardization, and verification of clinical concepts.
5984 [p74] Implementing such systems can reduce the
5985 [p74] documentation burden, improve structured‚Äì
5986 [p74] unstructured integration, and enhance the fidelity of
5987 [p74] EHR data for both clinical care and research.
5988 [p74] As a primary goal of our work, we were able to
5989 [p74] quantify the content and concordance
5990 [p74] programmatically in EHR records. This groundwork
5991 [p74] enables us to focus on optimizing AI workflows to
5992 [p74] maximize the signal to noise ratio within the digital
5993 [p74] record and minimize clinician disruption, with the
5994 [p74] overall goal of enhancing patient care.
5995 [p74] References
5996 [p74] [1]. Z. Zeng, Y. Deng, X. Li, T. Naumann, et al., Natural
5997 [p74] language processing for EHR-based computational
5998 [p74] phenotyping, IEEE/ACM Transactions on
5999 [p74] Computational Biology and Bioinformatics , Vol. 16,
6000 [p74] Issue 1, 2019, pp. 139-153.
6001 [p74] [2]. T. Seinen, et al., Using structured codes and free-text
6002 [p74] notes to measure information complementarity in
6003 [p74] EHRs, Journal of Medical Internet Research , Vol. 27,
6004 [p74] 2025, e66910.
6005 [p74] [3]. B. G. Arndt, J. W. Beasley, M. D. Watkinson,
6006 [p74] J. L. Temte, et al., Tethered to the EHR: primary care
6007 [p74] physician workload assessment using EHR event log
6008 [p74] data and time-motion observations, Annals of Family
6009 [p74] Medicine, Vol. 15, Issue 5, 2017, pp. 419-426.
6010 [p74] [4]. A. Rule, S. Bedrick, M. F. Chiang, M. R. Hribar,
6011 [p74] Length and redundancy of outpatient progress notes
6012 [p74] across a decade at an academic medical center, JAMA
6013 [p74] Network Open, Vol. 4, Issue 7, 2021, e2115334.
6014 [p74] [5]. H.-J. Kong, Managing unstructured big data in
6015 [p74] healthcare system, Healthcare Informatics Research ,
6016 [p74] Vol. 25, Issue 1, 2019, pp. 1-2.
6017 [p74] [6]. L. Jalilian, S. Khairat, T he next-generation electronic
6018 [p74] health record in the ICU: a focus on user-technology
6019 [p74] interface to optimize patient safety and quality,
6020 [p74] Perspectives in Health Information Management ,
6021 [p74] Vol. 19, Issue 1, 2022, 1g.
6022 [p74] [7]. B. Theodorou, C. Xiao, J. Sun, Synthesize
6023 [p74] high-dimensional longitudinal electronic health records
6024 [p74] via hierarchical autoregressive language model, Nature
6025 [p74] Communications, Vol. 14, Issue 1, 2023, 5305.
6026 [p74] [8]. X. Yang, A. Chen, N. PourNejatian, H. C. Shin, et al.,
6027 [p74] A large language model for el ectronic health records,
6028 [p74] NPJ Digital Medicine, Vol. 5, Issue 1, 2022, 194.
6029 [p75] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6030 [p75] 25-27 November 2025, Innsbruck, Austria
6031 [p75] 74
6032 [p75] [9]. M. D. Wang, R. Khanna, N. Najafi, Characterizing the
6033 [p75] source of text in electronic health record progress notes,
6034 [p75] JAMA Internal Medicine , Vol. 177, Issue 8, 2017,
6035 [p75] pp. 1212-1213.
6036 [p75] [10]. J. Steinkamp, J. J. Kantrowitz, S. Airan-Javia,
6037 [p75] Prevalence and sources of duplicate information in the
6038 [p75] electronic medical record, JAMA Network Open ,
6039 [p75] Vol. 5, Issue 9, 2022, e2233348.
6040 [p75] [11]. T. S. Hwang, M. Thomas, M. Hribar, A. Chen, et al.,
6041 [p75] The impact of documentation workflow on the
6042 [p75] accuracy of the coded diagnoses in the electronic health
6043 [p75] record, Ophthalmology Science, Vol. 4, Issue 1, 2024,
6044 [p75] 100409.
6045 [p75] [12]. A. A. Monte, P. Anderson, J. A. Hoppe,
6046 [p75] R. M. Weinshilboum, et al., Accuracy of electronic
6047 [p75] medical record medication reconciliation in emergency
6048 [p75] department patients, The Journal of Emergency
6049 [p75] Medicine, Vol. 49, Issue 1, 2015, pp. 78-84.
6050 [p75] [13]. A. J. Holmgren, C. A. Sinsky, L. Rotenstein,
6051 [p75] N. C. Apathy, National comparison of ambulatory
6052 [p75] physician electronic health record use across
6053 [p75] specialties, Journal of General Internal Medicine ,
6054 [p75] Vol. 39, Issue 14, 2024, pp. 2868-2870.
6055 [p75] [ 1 4 ] .  E .  K i m ,  M .  S h r e s t h a ,  R .  F o t y ,  T .  D e L a y ,  e t  a l . ,
6056 [p75] Structured extraction of real world medical knowledge
6057 [p75] using LLMs for summarization and search, in
6058 [p75] Proceedings of the IEEE International Conference on
6059 [p75] Big Data (BigData‚Äô24), 2024, pp. 3421-3430.
6060 [p75] [15]. E. Kim, R. Foty, M. Shrestha, V. Seyfert-Margolis,
6061 [p75] Conformal prediction and verification of large
6062 [p75] language model extractions in EHR data, in
6063 [p75] Proceedings of the SECURE-AI4H Symposium, AAAI
6064 [p75] Fall Symposium, 2025.
6065 [p76] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6066 [p76] 25-27 November 2025, Innsbruck, Austria
6067 [p76] 75
6068 [p76] (024)
6069 [p76] Autonomous, Self-learning Cisco Digital Adoption Platform (CDAP)
6070 [p76] for Personalized, Proactive Campaign Creation and Targeted
6071 [p76] User Engagement
6072 [p76] N. Kale
6073 [p76] Cisco Systems Inc., 3700 Cisco Way, San Jose, CA 95134, USA
6074 [p76] Tel.: +1 408 902 4609
6075 [p76] E-mail: nikkal@cisco.com
6076 [p76] Summary: This research introduces an Autonomous, Self-Learning Cisco Digital Adoption Platform (CDAP) that addresses
6077 [p76] critical limitations in traditional user engagement systems thr ough advanced AI-driven personalization. Unlike conventional
6078 [p76] platforms relying on static segmentation, CDAP employs real-tim e behavioral analytics, federa ted learning with differential
6079 [p76] privacy (Œµ = 1.0), and sentiment-driven engagement optimization . The system implements a novel ‚Äúcohort of one‚Äù approach
6080 [p76] using LSTM context encoding and Adam-optimized weight updates ( Œ∑ = 1e ‚àí3), analyzing micro-interactions to optimize
6081 [p76] overlay placement and engagement  timing. Through comprehensive experimental validation involving 66000+ participants
6082 [p76] across five industry domains ove r 8 weeks, CDAP demonstrates si gnificant improvements: task completion rates increased
6083 [p76] from 72.3 % to 89.7 % (p < 0.001, Cohen‚Äôs d = 0.85), user satis faction improved by 40.3 %, time-to-proficiency reduced by
6084 [p76] 39.9 %, and support ticket volumes decreased by 148 %. The plat form maintains less than 50ms inference latency while
6085 [p76] consuming 5627 CPU-hours total wi th federated coordination repr esenting approximately 34 % of computational load,
6086 [p76] demonstrating practical scalability for enterprise deployment.
6087 [p76] Keywords: Federated learning, Privacy-preserving analytics, Real-time pe rsonalization, Behavioral analytics, Sentiment
6088 [p76] analysis, Digital adoption, Cross-tenant optimization.
6089 [p76] 1. Introduction
6090 [p76] The digital transformation landscape has witnessed
6091 [p76] unprecedented inte gration of complex enterprise
6092 [p76] software systems, creating substantial challenges for
6093 [p76] user adoption and proficiency development.
6094 [p76] Traditional Digital Adoption Platforms (DAPs)
6095 [p76] typically rely on static demographic segmentation and
6096 [p76] predefined content delivery models, failing to capture
6097 [p76] nuanced, real-time user interactions and contextual
6098 [p76] needs [1, 2]. This static approach results in delayed
6099 [p76] content delivery, irrelevant interventions, and
6100 [p76] suboptimal user experiences, leading to reduced
6101 [p76] engagement effectiveness and increased support
6102 [p76] burden [3].
6103 [p76] Recent advances in machine learning and
6104 [p76] privacy-preserving technologies have opened new
6105 [p76] possibilities for intelligent, adaptive user engagement
6106 [p76] systems. Modern recommender systems demonstrate
6107 [p76] the effectiveness of perso nalized approaches at scale
6108 [p76] [4, 5], while federated lear ning frameworks enable
6109 [p76] collaborative learning across organizational
6110 [p76] boundaries while maintaining data sovereignty [6].
6111 [p76] However, existing enterprise solutions have not
6112 [p76] successfully integrated these capabilities to address the
6113 [p76] specific challenges of digital adoption.
6114 [p76] Contemporary research in user experience
6115 [p76] personalization emphasizes the importance of
6116 [p76] real-time behavioral analy tics and sentiment-aware
6117 [p76] engagement optimization [7, 8]. Studies by Abbas et
6118 [p76] al. (2021) demonstrate sign ificant improvements in
6119 [p76] user engagement through AI-driven behavioral
6120 [p76] analysis, while Kim & Kim (2021) show substantial
6121 [p76] benefits of personalization in digital banking
6122 [p76] environments [9]. However, these approaches have not
6123 [p76] been systematically applied to enterprise digital
6124 [p76] adoption with formal privacy guarantees.
6125 [p76] The Cisco Digital Adoption Platform (CDAP)
6126 [p76] addresses these fundamenta l limitations through an
6127 [p76] autonomous, self-learning system that delivers
6128 [p76] personalized, proactive campaigns tailored to
6129 [p76] individual user behavior in real-time. This research
6130 [p76] presents comprehensive experimental validation
6131 [p76] demonstrating CDAP‚Äôs superiority over traditional
6132 [p76] approaches across multiple performance dimensions
6133 [p76] through rigorous randomized controlled trial
6134 [p76] methodology.
6135 [p76] 2. Mathematical Framework
6136 [p76] 2.1. Adaptive Personalization Model
6137 [p76] The core of CDAP‚Äôs personalization system
6138 [p76] employs a sophisticated mathematical framework
6139 [p76] modeling user behavior, context, and historical
6140 [p76] patterns. The user behavior vector at time ùë° captures
6141 [p76] multi-dimensional interaction signals:
6142 [p76] ùêî·à∫ùë¢, ùë°·àª ‡µå
6143 [p76] ‚é£
6144 [p76] ‚é¢
6145 [p76] ‚é¢
6146 [p76] ‚é° click_rate·à∫ùë¢, ùë°·àª
6147 [p76] dwell_time·à∫ùë¢, ùë°·àª
6148 [p76] scroll_depth·à∫ùë¢, ùë°·àª
6149 [p76] task_completion·à∫ùë¢, ùë°·àª‚é¶
6150 [p76] ‚é•
6151 [p76] ‚é•
6152 [p76] ‚é§
6153 [p76] Context encoding utilizes a 128-unit LSTM
6154 [p76] network to capture sequential interaction patterns:
6155 [p77] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6156 [p77] 25-27 November 2025, Innsbruck, Austria
6157 [p77] 76
6158 [p77] ùêÇ·à∫ùë¢, ùë°·àª  ‡µå  LSTM·à∫sequence,ùê° ‡Øß‡¨ø‡¨µ,ùêú ‡Øß‡¨ø‡¨µ·àª
6159 [p77] The adaptive personalization score integrates
6160 [p77] multiple components through learned weights:
6161 [p77] ùëÉ·à∫ùë¢, ùë°·àª  ‡µå  ‚Äâ ùë§‡¨µùêî·à∫ùë¢, ùë°·àª ‡µÖùë§ ‡¨∂ùêÇ·à∫ùë¢, ùë°·àª ‡µÖùë§ ‡¨∑ùêá·à∫ùë¢, ùë°·àª ‡µÖ
6162 [p77] ‡µÖùë§‡¨∏ùëí‡¨ø‡∞í‡Øß ‡µÖùë§ ‡¨π ln·à∫ùë°‡µÖ1 ·àª ,
6163 [p77] where ùêá·à∫ùë¢, ùë°·àª captures historical patterns using
6164 [p77] exponential decay w eighting, and ùë§‡¨µ ‚Ä¶ùë§ ‡¨π a r e
6165 [p77] parameters optimized for engagement effectiveness.
6166 [p77] 2.2. Dynamic Weight Update Mechanism
6167 [p77] Weights are adapted online using the Adam
6168 [p77] optimizer with learning rate ùúÇ ‡µå 1e‡¨ø‡¨∑, responding to
6169 [p77] interaction-level feedback:
6170 [p77] Fig. 1. Dynamic Weight Update Algorithm.
6171 [p77] This online learning approach enables continuous
6172 [p77] adaptation to evolving user preferences and behavioral
6173 [p77] patterns, addressing the cold-start problem through
6174 [p77] rapid parameter convergence typically achieved within
6175 [p77] 3‚Äì5 days of interaction.
6176 [p77] 3. Cross-tenant Learning Optimization
6177 [p77] 3.1. Federated Learning Framework
6178 [p77] The federated learning framework aggregates
6179 [p77] knowledge across tenants while preserving privacy
6180 [p77] through differential privacy mechanisms. The
6181 [p77] optimization objective maxi mizes cumulative reward
6182 [p77] across all tenants and time steps:
6183 [p77] ùõâ
6184 [p77] ‚àó  ‡µå  a r g m a x
6185 [p77] ùõâ
6186 [p77] ‚àë‚àë ùõæ‡Øß‡Øç
6187 [p77] ‡Øß ‡≠Ä ‡¨µ
6188 [p77] ‡Ø°
6189 [p77] ‡Øú ‡≠Ä ‡¨µ ùëÖ·à∫ùëá‡Øú·à∫ùë°·àª,ùõâ ·àª,
6190 [p77] subject to privacy constraints with ùúÄ ‡µå  1.0 a n d
6191 [p77] ùõø ‡µå 10 ‡¨ø‡¨π, ensuring formal privacy guarantees while
6192 [p77] enabling knowledge transfer across organizational
6193 [p77] boundaries.
6194 [p77] 3.2. Privacy-preserving Aggregation
6195 [p77] Local model updates are protected through
6196 [p77] calibrated Gaussian noise injection, with privacy
6197 [p77] budget allocation proportional to observed
6198 [p77] data quality:
6199 [p77] Fig. 2. Privacy-Preserving Aggregation Algorithm.
6200 [p77] The noise variance ùúé‡¨∂ follows standard differential
6201 [p77] privacy calibration, balancing utility preservation with
6202 [p77] privacy protection. Empirical analysis reveals a 5‚Äì8 %
6203 [p77] utility reduction compared to non-private baselines,
6204 [p77] representing an acceptable trade-off for enterprise
6205 [p77] privacy requirements [10, 11].
6206 [p77] 3.3. Bias Mitigation and Heterogeneity
6207 [p77] Management
6208 [p77] Statistical heterogeneity across tenant populations
6209 [p77] can induce client drift and performance degradation.
6210 [p77] CDAP implements adaptive learning rates and
6211 [p77] participation weighting to address these challenges,
6212 [p77] monitoring client-specific performance metrics and
6213 [p77] adjusting aggregation weights accordingly.
6214 [p77] Fairness-aware training mechanisms detect and
6215 [p77] mitigate bias in sentiment analysis, particularly
6216 [p77] addressing observed appr oximately 12 % accuracy
6217 [p77] degradation for non-native English speakers.
6218 [p77] 4. Experimental Design and Results
6219 [p77] 4.1. Study Design and Participants
6220 [p77] This research employed a large-scale randomized
6221 [p77] controlled trial involving 66000+ participants across
6222 [p77] five industry domains: healthcare (n = 15200),
6223 [p77] financial services (n = 13800), enterprise software
6224 [p77] (n = 14500), technology (n = 12200), and
6225 [p77] manufacturing (n = 10300). Sample size calculations
6226 [p77] utilized power analysis with 80 % power, ùõº ‡µå  0.05,
6227 [p77] and expected effect size Cohen‚Äôs ùëë ‡µå  0.5.
6228 [p77] Four experimental conditions were implemented
6229 [p77] through block randomization stratified by industry
6230 [p77] domain and user experience level:
6231 [p77] ÔÇ∑ Control Group : Traditional DAP with static
6232 [p77] segmentation;
6233 [p77] ÔÇ∑ Treatment Group 1 : CDAP with adaptive
6234 [p77] personalization only;
6235 [p77] ÔÇ∑ Treatment Group 2 : CDAP with cross-tenant
6236 [p77] learning only;
6237 [p77] ÔÇ∑ Treatment Group 3 : Full CDAP system with
6238 [p77] integrated features.
6239 [p77] 4.2. Statistical Analysis
6240 [p77] Primary analyses employed mixed-effects
6241 [p77] modeling accounting for ne sted data structure and
6242 [p77] repeated measures design. Intention-to-treat principles
6243 [p78] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6244 [p78] 25-27 November 2025, Innsbruck, Austria
6245 [p78] 77
6246 [p78] were applied with Benjamini‚ÄìHochberg false
6247 [p78] discovery rate correction for multiple comparisons.
6248 [p78] Effect sizes were calculated using Cohen‚Äôs ùëë with
6249 [p78] 95 % confidence intervals [12, 13].
6250 [p78] 4.3. Primary Outcomes
6251 [p78] The comprehensive evaluation demonstrates
6252 [p78] significant improvements across all primary metrics.
6253 [p78] Fig. 3. Primary Outcomes Results Table.
6254 [p78] 4.4. Cross-industry Performance
6255 [p78] Cross-industry analysis reveals consistent benefits
6256 [p78] across all sectors.
6257 [p78] Fig. 4. Cross-Industry Performance Table.
6258 [p78] Healthcare organizations showed the largest task
6259 [p78] completion improvements (+27.3 %), while financial
6260 [p78] services demonstrated the greatest gains in user
6261 [p78] satisfaction (+43.1 %). Technology sector
6262 [p78] organizations exhibited the most substantial reductions
6263 [p78] in support ticket volumes (156 % decrease).
6264 [p78] 4.5. Computational Performance Analysis
6265 [p78] O v e r  t h e  8 - w e e k  e v a l u a t i o n  p e r i o d ,  C D A P
6266 [p78] demonstrated practical scalability with the following
6267 [p78] computational profile:
6268 [p78] ÔÇ∑ Total compute requirement: 5627 CPU-hours;
6269 [p78] ÔÇ∑ Federated learning coordination:
6270 [p78] approximately 34 % of total computational load;
6271 [p78] ÔÇ∑ Inference latency: < 45-50 ms (95
6272 [p78] th percentile);
6273 [p78] ÔÇ∑ Memory usage: Peak 2.3‚ÄÜGB per tenant during
6274 [p78] model updates;
6275 [p78] ÔÇ∑ Network efficiency: 89 % reduction in data
6276 [p78] transfer compared to centralized approaches.
6277 [p78] 4.6. Comparison with State-of-the-art Systems
6278 [p78] Benchmark comparisons against leading enterprise
6279 [p78] personalization platforms demonstrated CDAP‚Äôs
6280 [p78] superiority.
6281 [p78] Fig. 5. State-of-the-Art Systems Comparison Table.
6282 [p78] 5. Challenges and Limitations
6283 [p78] 5.1. Cold Start and Meta-learning
6284 [p78] Initial personalization effectiveness is limited
6285 [p78] during the first 3‚Äì5 days of user interaction, with
6286 [p78] optimal performance typically emerging after
6287 [p78] sufficient behavioral data accumulation. Meta-learning
6288 [p78] approaches show promise for rapid adaptation,
6289 [p78] utilizing prior tenant knowledge to accelerate new user
6290 [p78] onboarding. Current research explores few-shot
6291 [p78] learning techniques to reduce cold-start duration to less
6292 [p78] than 24 hours.
6293 [p78] 5.2. Privacy-utility Trade-offs
6294 [p78] Differential privacy implementation introduces
6295 [p78] measurable utility degradation (5‚Äì8 % compared to
6296 [p78] non-private baselines). While acceptable for enterprise
6297 [p78] requirements, this represents a fundamental constraint
6298 [p78] on system performance. Advanced privacy
6299 [p78] mechanisms, including local differential privacy and
6300 [p78] secure multi-party computation, are under
6301 [p78] investigation to minimize this trade-off.
6302 [p78] 5.3. Bias and Fairness Considerations
6303 [p78] Language diversity and acc essibility differences
6304 [p78] impact sentiment analysis  accuracy, with observed
6305 [p78] approximately 12 % degradation for non-native
6306 [p78] English speakers. Demographic bias in behavioral
6307 [p78] pattern recognition affects personalization
6308 [p78] effectiveness across user  populations. Ongoing
6309 [p78] development focuses on fairness-aware training
6310 [p78] algorithms and multilingual model adaptation to
6311 [p78] address these disparities.
6312 [p78] 5.4. Operational Complexity and Scalability
6313 [p78] Enterprise deployment requires substantial
6314 [p78] infrastructure: 16-core/64‚ÄÜGB compute resources per
6315 [p78] tenant, 24/7 monitoring systems, and continuous drift
6316 [p78] detection with retraining consuming approximately
6317 [p78] 15 % of total computational budget. Current federated
6318 [p78] coordination supports approximately 50 concurrent
6319 [p78] tenants, with network latency constraints limiting
6320 [p78] global distribution for real-time inference
6321 [p78] requirements.
6322 [p79] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6323 [p79] 25-27 November 2025, Innsbruck, Austria
6324 [p79] 78
6325 [p79] 5.5. Long-term Adaptation and Sustainability
6326 [p79] While 8-week evaluation demonstrates immediate
6327 [p79] effectiveness, long-term deployment implications
6328 [p79] remain partially understood. Projected 12‚Äì24 month
6329 [p79] studies suggest potential model drift requiring periodic
6330 [p79] retraining cycles. Sustained user engagement patterns
6331 [p79] may evolve, necessitating continuous algorithm
6332 [p79] adaptation and performance monitoring strategies.
6333 [p79] 5. Conclusions and Future Work
6334 [p79] This comprehensive experimental validation of the
6335 [p79] Autonomous, Self-Learning Cisco Digital Adoption
6336 [p79] Platform demonstrates significant advances in
6337 [p79] personalized user engagement through rigorous
6338 [p79] methodology involving 66000+ participants across
6339 [p79] five industry domains. The integration of adaptive
6340 [p79] personalization, privacy-preserving cross-tenant
6341 [p79] learning, and sentiment-driven optimization represents
6342 [p79] meaningful contributions to digital adoption
6343 [p79] technology.
6344 [p79] Key innovations including ‚Äúcohort of one‚Äù
6345 [p79] personalization, federated learning with differential
6346 [p79] privacy, and predictive engagement optimization
6347 [p79] achieve substantial improvements across all metrics
6348 [p79] (15‚Äì196 % gains) with large to very large effect sizes
6349 [p79] (Cohen‚Äôs ùëë ‡µå  0.65 t o  1.67), demonstrating both
6350 [p79] statistical significance and practical meaningfulness.
6351 [p79] The consistency of resu lts across healthcare,
6352 [p79] financial services, enterprise software, technology, and
6353 [p79] manufacturing sectors supports broad applicability,
6354 [p79] while computational performance analysis confirms
6355 [p79] practical scalability for enterprise deployment with
6356 [p79] less than 50‚ÄÜms inference latency and efficient resource
6357 [p79] utilization.
6358 [p79] Future research directions include: (1) longitudinal
6359 [p79] studies extending to 12‚Äì24 months for sustained
6360 [p79] impact assessment; (2) fairness-aware and multilingual
6361 [p79] model development; (3) meta-learning approaches for
6362 [p79] rapid cold-start mitigation; (4) integration with
6363 [p79] emerging technologies including AR/VR and voice
6364 [p79] interfaces; (5) exploration of quantum-secure
6365 [p79] federated protocols for enhanced privacy protection;
6366 [p79] and (6) advanced bias detection and mitigation
6367 [p79] strategies.
6368 [p79] Acknowledgements
6369 [p79] The authors thank Cisco Systems for providing
6370 [p79] computational resources and access to enterprise
6371 [p79] deployments. We acknowledge the participating
6372 [p79] organizations across healthcare, financial services,
6373 [p79] enterprise software, technology, and manufacturing
6374 [p79] sectors for enabling this comprehensive validation
6375 [p79] study. Special recognition to the federated learning
6376 [p79] research community for foundational algorithmic
6377 [p79] contributions.
6378 [p79] References
6379 [p79] [1]. J. R. Anderson, C. Lebier e, The Atomic Components of
6380 [p79] Thought, Psychology Press, 1998.
6381 [p79] [2]. F. D. Davis, Perceived usefulness, perceived ease of
6382 [p79] use, and user acceptance of information technology,
6383 [p79] MIS Quarterly, Vol. 13, Issue 3, 1989, pp. 319-340.
6384 [p79] [3]. T. Z. Sana, S. Abdulla, A. Das, A. Nag, et al.,
6385 [p79] Advancing federated learning: a systematic literature
6386 [p79] review of methods, challenges, and applications, IEEE
6387 [p79] Access, Vol. 13, 2025, pp. 153817-153844.
6388 [p79] [4]. H. B. McMahan, E. Moore, D. Ramage, S. Hampson,
6389 [p79] et al., Communication-efficient learning of deep
6390 [p79] networks from decentralized data, in Proceedings of the
6391 [p79] 20th International Conference on Artificial Intelligence
6392 [p79] and Statistics (AISTATS‚Äô17), Vol. 54, 2017, pp. 1273-
6393 [p79] 1282.
6394 [p79] [5]. A. Vaswani, et al., Attention is all you need, in
6395 [p79] Advances in Neural Information Processing Systems,
6396 [p79] Vol. 30, Curran Associates, Inc., 2017, pp. 5998-6008.
6397 [p79] [6]. C. Dwork, A. Roth, The algorithmic foundations of
6398 [p79] differential privacy, Foundations and Trends in
6399 [p79] Theoretical Computer Science , Vol. 9, Issues 3-4,
6400 [p79] 2014, pp. 211-407.
6401 [p79] [7]. O. Abbas, A. Fialho, P. Cesar, A survey on user
6402 [p79] engagement modeling in online systems, ACM
6403 [p79] Computing Surveys, Vol. 54, Issue 7, 2021, pp. 1-34.
6404 [p79] [8]. B. P. Knijnenburg, A. Kobsa, Inferring and explaining
6405 [p79] recommender system preferences, User Modeling and
6406 [p79] User-Adapted Interaction , Vol. 23, Issues 5-6, 2013,
6407 [p79] pp. 441-472.
6408 [p79] [9]. H. J. Kim, M. Kim, AI-driven personalization in digital
6409 [p79] financial services, IEEE Access , Vol. 9, 2021,
6410 [p79] pp. 154418-154430.
6411 [p79] [10]. P. Kairouz, et al., A dvances and open problems in
6412 [p79] federated learning, Foundations and Trends in
6413 [p79] Machine Learning , Vol. 14, Issues 1-2, 2021,
6414 [p79] pp. 1-210.
6415 [p79] [11]. Q. Yang, Y. Liu, T. Chen, Y. Tong, Federated machine
6416 [p79] learning: concept and applications, ACM Transactions
6417 [p79] on Intelligent Systems and Technology , Vol. 10,
6418 [p79] Issue 2, 2019, 12.
6419 [p79] [12]. Y. Benjamini, Y. Hochberg, Controlling the false
6420 [p79] discovery rate: a practical and powerful approach to
6421 [p79] multiple testing, Journal of the Royal Statistical
6422 [p79] Society: Series B (Methodological) , Vol. 57, Issue 1,
6423 [p79] 1995, pp. 289-300.
6424 [p79] [13]. J. Cohen, Statistical Power Analysis for the Behavioral
6425 [p79] Sciences, 2nd Ed., Lawrence Erlbaum Associates, 1988.
6426 [p80] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6427 [p80] 25-27 November 2025, Innsbruck, Austria
6428 [p80] 79
6429 [p80] (027)
6430 [p80] Anytime Rule Compression and Rectified Logistic Modeling
6431 [p80] for Longitudinal Signals
6432 [p80] J. Orender, J. Sun and M. Zubair
6433 [p80] Old Dominion University, 5115 Hampton Blvd., Norfolk, VA, USA
6434 [p80] Tel.: + 0016192005721
6435 [p80] E-mail: joren001@odu.edu
6436 [p80] Summary: Interpretable models are essent ial in longitudinal sensor anal ytics where end-users must understand why a
6437 [p80] prediction was made. We present  an anytime ‚Äúlogic-polishing‚Äù fr amework that compresses a sparse, L1-regularized logistic
6438 [p80] model of continuous features rectified (¬±1) and trained to produce a compact m-of-K rule list tuned to maximize Youden‚Äôs J.
6439 [p80] On synthetic longitudinal datasets with known ground-truth rules, the approach reduces model complexity by up to ~50√ó (e.g.,
6440 [p80] 344 non-zero coefficients ‚Üí 7 rules at N = 5000; 349 ‚Üí 7 at N = 9000; 257 ‚Üí 8 at N = 10000) while matching or slightly
6441 [p80] improving J and maintaining AUC ‚âà logistic baselines. AUC diffe rences were negligible at th e 0.1‚Äì0.3 % level. A custom
6442 [p80] solver exploiting binarized inputs trained 1.5‚Äì2.3√ó faster than scikit-learn on the largest sets, and the polishing step added only
6443 [p80] fractions of a second. The method consistently achieved full adoption (no loss in J) under global K-policies.
6444 [p80] Keywords: Interpretable machine learning , Rule compression, Longitudinal signals, L1 logistic regression, Binarization,
6445 [p80] Model distillation.
6446 [p80] 1. Introduction
6447 [p80] In high-stakes sensor m onitoring, stakeholders
6448 [p80] require transparent models with balanced sensitivity
6449 [p80] and specificity [1, 2]. While L1-regularized logistic
6450 [p80] regression provides sparsity, even the resulting models
6451 [p80] can involve hundreds of small-magnitude weights that
6452 [p80] obscure the underlying decision logic for discretized
6453 [p80] longitudinal features. We address this gap with an
6454 [p80] anytime rule compression  pipeline that (i) rectifies
6455 [p80] features to ¬±1 for direct logical semantics, (ii) trains an
6456 [p80] L1 logistic baseline (custom solver exploiting binary
6457 [p80] inputs), and (iii) ‚Äúpolishes‚Äù the model into a short
6458 [p80] m-of-K rule list by maximizing Youden‚Äôs J at a chosen
6459 [p80] operating point.
6460 [p80] 1.1. Contributions
6461 [p80] An anytime, J-preservi ng rule-compression
6462 [p80] algorithm that converts a rectified logistic model into
6463 [p80] a concise rule set; users can halt at any point to trade
6464 [p80] simplicity for accuracy. 2) A binarized (¬±1) feature set
6465 [p80] that yields human-readable atomic conditions and
6466 [p80] enables efficient coordi nate-descent training.
6467 [p80] 3) Empirical evidence on synthetic longitudinal data
6468 [p80] with known ground truth: up to ~50√ó reduction in
6469 [p80] complexity with J preserved (or modestly improved)
6470 [p80] and AUC essentially unchanged for the complete set of
6471 [p80] relevant features. 4) Analysis of the vote magnitude K
6472 [p80] and threshold k (m-of-K) showing robustness across
6473 [p80] K‚àà{3,5,10} and consistent full adoption. 5) Speedups
6474 [p80] of ~1.5‚Äì2.3√ó vs. scikit-learn on large rectified models.
6475 [p80] 1.2. Approach
6476 [p80] Our approach begins by transforming raw
6477 [p80] longitudinal sensor data into rectified features  t h a t
6478 [p80] enable logical interpretation. Given M sensor signals
6479 [p80] measured over time for each instance (e.g., a patient‚Äôs
6480 [p80] longitudinal vital signs), we avoid relying on raw
6481 [p80] time-series values or handcrafted temporal features.
6482 [p80] Instead, we apply a simple rectification: each sensor
6483 [p80] reading is compared against a predefined threshold
6484 [p80] derived from its value at the time of a recorded event
6485 [p80] [3]. That is to say, the thresholds are derived from the
6486 [p80] data itself rather than supplied by an outside source,
6487 [p80] like a subject matter expert (SME). The resulting
6488 [p80] feature is encoded as +1 if the reading exceeds the
6489 [p80] threshold (high) and ‚àí1 if it falls below (low). For
6490 [p80] naturally binary or categorical sensors, this
6491 [p80] transformation simply preserves their form by
6492 [p80] mapping categories into the ¬±1 domain in a trivial
6493 [p80] transformation. This rectifi cation provides a uniform
6494 [p80] binary input space, serving a s the foundation for both
6495 [p80] efficient model training and the extraction of
6496 [p80] interpretable logical rules [4].
6497 [p80] In addition, we use a mean-matching intercept for
6498 [p80] the rectified logistic model via the LASSO [5, 6]:
6499 [p80] ùëè‡∑† ‡µål o g ·âÄ
6500 [p80] ‡Ø£‚àó
6501 [p80] ‡¨µ‡¨ø‡Ø£‚àó·âÅ‡µÜùê∞ ‡≠Éùõç, (1)
6502 [p80] where ùëù‚àó =
6503 [p80] ‡¨µ
6504 [p80] ‡Øá ‚àë ùë¶‡Øú
6505 [p80] ‡Øá
6506 [p80] ‡Øú ‡≠Ä ‡¨µ  is the empirical prevalence,
6507 [p80] ùõç‡Øù  ‡µå
6508 [p80] ‡¨µ
6509 [p80] ‡Øá ‚àë ùëã‡Øú‡Øù
6510 [p80] ‡Øá
6511 [p80] ‡Øú ‡≠Ä ‡¨µ  are feature means for rectified inputs
6512 [p80] ùëã‡Øú‡Øù ‚àà·àº ‡µÜ 1 , ‡µÖ 1 ·àΩ, and ùê∞ is the learned sparse coefficient
6513 [p80] vector. Eq. (1) anchors the model‚Äôs logit at the mean
6514 [p81] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6515 [p81] 25-27 November 2025, Innsbruck, Austria
6516 [p81] 80
6517 [p81] feature vector to the empirical class log-odds and
6518 [p81] integrates cleanly with the subsequent m-of-K rule
6519 [p81] construction.
6520 [p81] 1.3. Relationship to Prior Work
6521 [p81] While the previous work [3] demonstrates that
6522 [p81] binarization itself is a powerful tool for reducing the
6523 [p81] obfuscating effect of multiple highly correlated
6524 [p81] features, and demonstrates this with several engineered
6525 [p81] (synthetic) data sets as well as complex real-world
6526 [p81] open source data sets, this short paper takes the
6527 [p81] additional step of collapsing the remaining small value
6528 [p81] irrelevant coefficients and presenting a clean, sparse
6529 [p81] function which accurately describes the logical
6530 [p81] relationship to the relevant input features.
6531 [p81] This relationship comes at near zero cost if the
6532 [p81] relevant input features are related by a logical rule (e.g.
6533 [p81] a go/no-go relationship between combinations of input
6534 [p81] variables).
6535 [p81] 2. Method
6536 [p81] Binarization of the input data and subsequent
6537 [p81] logistic regression fitting with L1-regularization
6538 [p81] (LASSO) is a crucial step in this method and makes the
6539 [p81] follow-on logical polishing possible. Notably, while
6540 [p81] this is not the only possible binarization method, this
6541 [p81] one is simple to implement and its successful usage has
6542 [p81] been empirically demonstrated in our previous
6543 [p81] work [3].
6544 [p81] Algorithm 1. Binarization (adapted from [3]).
6545 [p81] Require: X, y (training set only)
6546 [p81] Output: A, rj[b, c]
6547 [p81] 1: Let rj[b, c] be the critical range for feature vector
6548 [p81] Xj, where b is the minimum and c is maximum
6549 [p81] defining that range.
6550 [p81] 2: procedure BINARIZATION(X, y)
6551 [p81] 3: Let Z be the rows of X where y = 1.
6552 [p81] Z ‚äÜ X, where Z = {X | y = TRUE}
6553 [p81] 4: Compute rj = 1..d = [min(Zj), max(Zj)].
6554 [p81] Note: If the min / max calculations induce
6555 [p81] brittleness in the solution (e.g. if there are
6556 [p81] outliers in the data set), using a robust quantile
6557 [p81] can provide a remedy.
6558 [p81] 5: Compute A, the set of transformed features,
6559 [p81] such that:
6560 [p81] aij = +1 when xij ‚â• rj[b] and xij ‚â§ rj[c]
6561 [p81] aij = ‚àí1 when xij < rj[b] or xij > rj[c]
6562 [p81] 6: end procedure
6563 [p81] Important: The critical ranges are only calculated using the
6564 [p81] training set, not the set-aside test set. The critical ranges are
6565 [p81] retained and used again when processing the test set. This
6566 [p81] prevents information leakage and maintains the integrity of
6567 [p81] the data.
6568 [p81] When binarization and model fitting are complete.
6569 [p81] The following algorithm implements the logical
6570 [p81] polishing step used to collapse the low magnitude
6571 [p81] coefficients after the LASSO fit of the binarized data.
6572 [p81] Algorithm 2. Logical Polish.
6573 [p81] Require: ùëã ‚àà ·àº‡µÜ1, ‡µÖ1·àΩ‡Ø°‡µà‡Øó , y ‚àà ·àº0,1·àΩ‡Ø°,
6574 [p81] ùë§‚àà‚Ñù ‡Øó, ùëè‡¨¥ ‚àà‚Ñù  (from LASSO fit),
6575 [p81] J0: Youden‚Äôs J for baseline model,
6576 [p81] K: Vote magnitude,
6577 [p81] rt: Relative tolerance to J required
6578 [p81] Output: Rule Model (w*, b*)
6579 [p81] 1: Collect active features  and sort by importance.
6580 [p81] ÔÇ∑ Let ùí•‡µå‡µõ j : ùë§‡Øù ‡µç0 ‡µü , ‚Ñì  ‡µå  |ùí•|
6581 [p81] ÔÇ∑ Sort ùí• by descending ‡∏´ùë§‡Øù‡∏´ to get an
6582 [p81] index
6583 [p81] order ùúã ‡µå  ·à∫ùúã‡¨µ,‚Ä¶,ùúã ‚Ñì·àª
6584 [p81] ÔÇ∑ Define signs ùë†‡Øù  ‡µå  ùë† ùëñ ùëî ùëõ ‡µ´ ùë§‡Øù‡µØ‚àà
6585 [p81] ·àº‡µÜ1, ‡µÖ1·àΩ
6586 [p81] for ùëó‚ààùí• .
6587 [p81] 2: Precompute per-feature signed contributions.
6588 [p81] ÔÇ∑ Build: ùëÄ ‚àà ·àº‡µÜ1, ‡µÖ1·àΩ‡Ø°‡µà‚Ñì
6589 [p81] where ùëÄ‡Øú,‡Øû  ‡µå ùë† ‡∞ó‡≥ñ ùëã‡Øú,‡∞ó‡≥ñ
6590 [p81] ÔÇ∑ Compute cumulative votes ùëâ‚àà‚Ñ§ ‡Ø°‡µà‚Ñì
6591 [p81] with
6592 [p81] ùëâ‡Øú,‡Øû  ‡µå ‚àë ùëÄ‡Øú,‡Øû
6593 [p81] ‡Øû
6594 [p81] ‡Øß ‡≠Ä ‡¨µ  for ùëò ‡µå  1, ‚Ä¶ , ‚Ñì
6595 [p81] ÔÇ∑ So, ùëâ‡Øú,‡Øû ‡µå# ·à∫ùëéùëîùëüùëíùëíùëöùëíùëõùë°ùë†·àª ‡µÜ
6596 [p81] #·à∫ùëëùëñùë†ùëéùëîùëüùëíùëíùëöùëíùëõùë°ùë†·àª among the top-k.
6597 [p81] 3: Initialize incumbent (anytime state).
6598 [p81] ÔÇ∑ Set ·à∫ùë§‚àó,ùëè ‚àó,ùëò ‚àó, ùêΩ‚àó·àª‚Üê
6599 [p81] ·à∫ùë§, ùëè‡¨¥,0 ,‡µÜ ‚àû ·àª
6600 [p81] ÔÇ∑ ùëá‚Üê·à∫ 1‡µÜùëü ùë° ·àª‚àôùêΩ‡¨¥
6601 [p81] 4: Main scan over rule size  k.
6602 [p81] FOR k = 1 to ‚Ñì
6603 [p81] a. Construct the rule weight vector for
6604 [p81] top-k.
6605 [p81] ùë§‡∑•‡Øù
6606 [p81] ·à∫‡Øû·àª  ‡µå ‡µú ùêæ‚àôùë† ‡Øù,
6607 [p81] 0,   ùëó ‚àà·àºùúã‡¨µ,‚Ä¶,ùúã ‡Øû·àΩ
6608 [p81] ùëúùë°‚Ñéùëíùëüùë§ùëñùë†ùëí
6609 [p81] b. Choose intercept ùëè·à∫‡Øû·àª per policy.
6610 [p81] ùëè·à∫‡Øû·àª  ‡µå  ùëô ùëú ùëî·âÄ
6611 [p81] ‡Ø£
6612 [p81] ‡¨µ‡¨ø‡Ø£·âÅ‡µÜ ‚àë ùêæ‡Ø¶‡¥è‡≥ü‡∞ì‡¥è‡≥ü
6613 [p81] ‡Øû
6614 [p81] ‡Øß ‡≠Ä ‡¨µ
6615 [p81] where:
6616 [p81] ùúá‡Øù  ‡µå
6617 [p81] ‡¨µ
6618 [p81] ‡Ø° ‚àë ùëã‡Øú,‡Øù‡Øú  and ùëù ‡µå
6619 [p81] ‡¨µ
6620 [p81] ‡Ø° ‚àë ùë¶‡Øú‡Øú
6621 [p81] c. Update incumbent (for anytime).
6622 [p81] if ùêΩ‡Øû ‡µêùêΩ ‚àó:
6623 [p81] update ·à∫ùë§‚àó,ùëè ‚àó,ùëò ‚àó, ùêΩ‚àó·àª‚Üê
6624 [p81] ·à∫ùë§‡∑• ·à∫‡Øû·àª,ùëè ·à∫‡Øû·àª,ùëò ,ùêΩ‡Øû·àª
6625 [p81] 5: Adoption decision.
6626 [p81] if ùêΩ‚àó ‡µêùëá , adopt new coefficient set, otherwise
6627 [p81] ·à∫ùë§‚àó,ùëè ‚àó,ùëò ‚àó·àª‚Üê·à∫ ùë§ , ùëè‡¨¥,‚Ñì ·àª.
6628 [p81] 6: Finalize outputs.
6629 [p81] Return Rule Model ·à∫ùë§‚àó,ùëè ‚àó·àª with ùëò‚àó non-zeros,
6630 [p81] each ‡µáùêæ if the new coefficient set was adopted.
6631 [p81] 7: end procedure
6632 [p81] 3. Results
6633 [p81] The custom solver consistently outperformed
6634 [p81] scikit-learn in both speed and scalability, running
6635 [p81] 1.5‚Äì2.3√ó faster on large rectified datasets while also
6636 [p81] using memory more efficiently through sparse binary
6637 [p81] feature representations [3]. The rule models showed no
6638 [p81] evidence of overfitting and in some cases generalized
6639 [p81] slightly better than their logistic counterparts,
6640 [p82] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6641 [p82] 25-27 November 2025, Innsbruck, Austria
6642 [p82] 81
6643 [p82] underscoring that compression not only enhances
6644 [p82] interpretability but can a l s o  a c t  a s  a n  i m p l i c i t
6645 [p82] regularizer (Fig. 1). These findings highlight the
6646 [p82] practicality of the approach for scaling to larger
6647 [p82] datasets without sacrificing performance.
6648 [p82] Fig. 1.  Magnitudes for (top) L1-logistic on raw features,
6649 [p82] (middle) L1-logistic on rect ified features (no polish),
6650 [p82] and (bottom) rectified L1-logi stic after logic polishing.
6651 [p82] The polishing step collapses numerous tiny contributions
6652 [p82] into a handful of rules, achie ving maximal sparsity without
6653 [p82] degrading J/AUC (adapted from [3]).
6654 [p82] Taken together, these results demonstrate that the
6655 [p82] proposed rule-compression framework not only
6656 [p82] preserves predictive accuracy but also delivers
6657 [p82] scalable, interpretable models (Fig. 2), setting the stage
6658 [p82] for our concluding discussion of its broader
6659 [p82] implications.
6660 [p82] 3.1. Quantifying Similarites
6661 [p82] Across 36 paired simulation runs with differing
6662 [p82] seeds and data set sizes, all four AUC measures were
6663 [p82] above 0.97, differing by no more than ~0.03.
6664 [p82] Pairwise paired t-tests [7] indicated statistically
6665 [p82] significant differences (p < 0.001 ‚Äì see Table 1), but
6666 [p82] effect sizes were small (|Cohen‚Äôs d| ‚âà 1.0 for the largest
6667 [p82] contrast, typically < 0.3 for most).
6668 [p82] Equivalence testing with a tolerance of ¬± 0.01 AUC
6669 [p82] confirmed that the base and rule variants are practically
6670 [p82] indistinguishable, implying that all methods converge
6671 [p82] to essentially the same predictive performance despite
6672 [p82] minor systematic offsets.
6673 [p82] 4. Conclusion
6674 [p82] The proposed anytime logic-polishing framework
6675 [p82] converts sparse rectified logistic models into short rule
6676 [p82] sets that preserve the best attainable balance of
6677 [p82] sensitivity and specificity (via Youden‚Äôs J) while
6678 [p82] retaining AUC performance. On synthetic longitudinal
6679 [p82] signals with known ground truth, we observed
6680 [p82] up to ~50√ó  complexity reduction (hundreds of
6681 [p82] coefficients ‚Üí single-di git rules) with equal or
6682 [p82] marginally better J and negligible AUC change,
6683 [p82] consistent full adoption, and 1.5‚Äì2.3√ó faster training
6684 [p82] using a custom solver for binary inputs. These results
6685 [p82] suggest a practical pathway to deploy interpretable
6686 [p82] models for time-series monitoring in domains where
6687 [p82] clarity and verification by experts are essential.
6688 [p82] Fig. 2.  Youden‚Äôs J v s .  r u l e  c o u n t  (k) curve shows how J
6689 [p82] on validation/test changes as the rule threshold requirement
6690 [p82] varies from 1 up to K (or total rules). The peak of the curve
6691 [p82] indicates the optimal ‚Äúk chosen‚Äù.
6692 [p82] Table 1. Paired t-test AUC P-value Comparison.
6693 [p82] Run Bin‚Äôzed/
6694 [p82] New
6695 [p82] Rule
6696 [p82] Model
6697 [p82] Bin‚Äôzed/
6698 [p82] Scikit
6699 [p82] Raw/
6700 [p82] Scikit
6701 [p82] Bin‚Äôzed/
6702 [p82] New NA 1.6E-6* 1.5E-6* 7.3E-8
6703 [p82] Rule
6704 [p82] Model 1.6E-6* NA 9.7E-10* 6.6E-7
6705 [p82] Bin‚Äôzed/
6706 [p82] Scikit 1.5E-6* 9.7E-10* NA 7.7E-9
6707 [p82] Raw/
6708 [p82] Scikit 7.3E-8 6.6E-7 7.7E-9 NA
6709 [p82] * These models also passed the ‚ÄúTwo One-Sided Tests‚Äù (TOST)
6710 [p82] [8] criteria to consider these results statistically equivalent
6711 [p82] with 90 % CI within ¬±0.01 AUC.
6712 [p82] References
6713 [p82] [1]. C. Rudin, Stop explaining black box machine learning
6714 [p82] models for high stakes decis ions and use interpretable
6715 [p82] models instead, Nature Machine Intelligence , Vol. 1,
6716 [p82] Issue 5, 2019, pp. 206-215.
6717 [p82] [2]. W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl,
6718 [p82] et al., Definitions, met hods, and applications in
6719 [p82] interpretable machine learning, Proceedings of the
6720 [p82] National Academy of Sciences , Vol. 116, Issue 44,
6721 [p82] 2019, pp. 22071-22080.
6722 [p82] [3]. J. Orender, M. Zubair, J. Sun, LASSO logic engine:
6723 [p82] harnessing the logic parsing capabilities of the LASSO
6724 [p82] algorithm for longitudinal feature learning, in
6725 [p83] 1st International Conference on Big Data Analytics and Applications (BDAA' 2025),
6726 [p83] 25-27 November 2025, Innsbruck, Austria
6727 [p83] 82
6728 [p83] Proceedings of the IEEE International Conference on
6729 [p83] Big Data (Big Data‚Äô22), 2022, pp. 309-318.
6730 [p83] [4]. E. Angelino, N. Larus-Stone, D. Alabi, M. Seltzer,
6731 [p83] et al., Learning certifiably optimal rule lists for
6732 [p83] categorical data, Journal of Machine Learning
6733 [p83] Research, Vol. 18, 2018, pp. 1-78.
6734 [p83] [5]. A. Y. Ng, Feature selection, L1 vs. L2 regularization,
6735 [p83] and rotational invariance, in Proceedings of the
6736 [p83] Twenty-First International Conference on Machine
6737 [p83] Learning, 2004, p. 78.
6738 [p83] [6]. R. Tibshirani, Regression shrinkage and selection via
6739 [p83] the lasso, Journal of the Royal Statistical Society Series
6740 [p83] B: Statistical Methodology , Vol. 58, Issue 1, 1996,
6741 [p83] pp. 267-288.
6742 [p83] [7]. "Student" (pseudonim), The probable error of a mean,
6743 [p83] Biometrika, Vol. 6, Issue 1, 1908, pp. 1-25.
6744 [p83] [8]. D. J. Schuirmann, A comparison of the two one-sided
6745 [p83] tests procedure and the power approach for assessing
6746 [p83] the equivalence of average bioavailability, Journal of
6747 [p83] Pharmacokinetics and Biopharmaceutics , Vol. 15,
6748 [p83] Issue 6, 1987, pp. 657-680.
