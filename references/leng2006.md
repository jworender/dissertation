# A Note on the LASSO and Related Procedures in Model Selection (Leng, Lin, and Wahba, 2006)

## Dissertation Alignment Context
The dissertation proposal uses a three-stage longitudinal pipeline: critical-range rectification of lagged signals into {-1,+1} indicators, L1-regularized logistic feature-and-lag selection, and anytime rule compression that converts sparse coefficients into compact m-of-K rules.

## Outline Summary of the Paper
1. **Problem focus and claim (Section 1):** The paper studies whether LASSO, Forward Stagewise (FSW), and LARS are reliable for variable-selection consistency when their tuning is chosen by prediction accuracy.
2. **Motivating distinction (Section 1):** It separates two goals often conflated in practice: strong prediction performance versus correct identification of the true active variable set.
3. **Method setup and notation (Section 2):** The authors review LASSO, FSW, and LARS formulations and emphasize their close solution-path relationships, especially under orthogonal design.
4. **How tuning is treated (Sections 2 and 3):** The analysis assumes common practice: selecting the tuning parameter/model along the path by minimizing squared prediction loss (or equivalent prediction-oriented criteria).
5. **Two-variable analytical counterexample (Section 3):** For a model with one true and one noise predictor, the paper derives finite-sample probabilities showing prediction-tuned procedures fail to recover the true model with nonzero probability bounded away from zero.
6. **Extension to higher dimensions (Section 4):** Under orthogonal designs with superfluous variables, a theorem shows the probability of exact model recovery remains bounded by a constant below 1, independent of sample size \(n\).
7. **Implication for related procedures (Sections 3 and 4):** Because of path equivalence, the inconsistency conclusion extends from LASSO to FSW and LARS (with noted implementation distinctions for discrete LARS step models).
8. **Simulation evidence (Section 5):** Correlated-design simulations across increasing sample sizes show low percentages of perfectly selected models despite improved relative prediction loss, reinforcing the theory.
9. **Interpretive takeaway (Section 6):** The paper does not reject LASSO-family methods for prediction; instead it argues prediction-based tuning alone is generally insufficient when exact variable recovery is the primary objective.
10. **Adjustment strategies (Section 6):** It discusses paths to consistency, including stronger-than-prediction tuning choices, post-selection thresholding of small coefficients, and alternative criteria targeted at selection error rather than prediction risk.

## Relevance to the Dissertation
A Note on the LASSO and Related Procedures in Model Selection (Leng, Lin, and Wahba, 2006) is directly relevant because it offers a sparse-selection strategy that competes with the proposal's rectification-first approach under multicollinearity.

## Elements from This Paper to Use in the Dissertation
1. Include this method as an explicit baseline on both raw lag-expanded and rectified features.
2. Track support stability, false positives, and lag attribution quality, not only AUC/F1.
3. Reuse discussion around statistica, sinica, note to motivate when penalty-only methods are sufficient.
4. Compare runtime and memory against the rectification + L1 + anytime-rule pipeline.

## Competitive Method Assessment
This paper describes a genuine competing method family. Relative to the dissertation pipeline, it can fall short when raw lag-expanded correlation is so high that support selection remains unstable or when explicit threshold/rule semantics are required. It can excel when linear signal is strong, penalty tuning is mature, and compact logical rules are not the primary requirement.


## Dissertation Citation Traceability

- No direct citation occurrences were found in the current dissertation chapter files.
