# Anytime Rule Compression for Interpretable Sparse Longitudinal Models (Orender et al., 2025)

## Dissertation Alignment Context
The dissertation proposal uses a three-stage longitudinal pipeline: critical-range rectification of lagged signals into {-1,+1} indicators, L1-regularized logistic feature-and-lag selection, and anytime rule compression that converts sparse coefficients into compact m-of-K rules.

## Outline Summary of the Paper
1. **Problem framing and motivation (Section 1):** The paper targets high-stakes longitudinal sensing settings where sparse logistic models remain too complex for direct human interpretation despite L1 regularization.
2. **Core pipeline definition (Sections 1 and 1.2):** It proposes a three-part process: rectification of features to \(\{-1,+1\}\), L1-logistic fitting, and an anytime logic-polishing step that converts coefficients into compact m-of-K style rule behavior.
3. **Contribution claims (Section 1.1):** The paper claims large complexity reduction (up to about 50x), preservation of Youden's J, near-unchanged AUC, and practical training-time gains from a custom binary-input solver.
4. **Rectification design (Section 1.2 and Algorithm 1):** Features are transformed using class-conditional critical ranges from training data only, with explicit mention of leakage prevention and optional robust quantile handling for outlier sensitivity.
5. **Model anchoring and baseline fit (Section 1.2):** After LASSO fitting on rectified inputs, the intercept is mean-matched to empirical class prevalence so the baseline logit is centered consistently before rule compression.
6. **Link to prior work (Section 1.3):** Relative to earlier binarization-focused work, this paper emphasizes an added coefficient-collapse stage to produce a cleaner logical function from remaining nonzero terms.
7. **Anytime logical polishing algorithm (Section 2, Algorithm 2):** Active features are sorted by magnitude, converted to signed vote contributions, scanned over rule sizes \(k\), and updated with the best observed J so the process can stop early with a valid incumbent model.
8. **Adoption policy and thresholding (Algorithm 2):** A relative-tolerance criterion against baseline J determines whether compressed coefficients are adopted, formalizing the accuracy-versus-simplicity tradeoff.
9. **Empirical findings (Section 3 and 3.1):** Results report faster training than scikit-learn on large rectified sets, major coefficient-to-rule compression, high AUC across runs, and equivalence-style evidence that predictive differences are practically small.
10. **Conclusions and implications (Section 4):** The paper concludes that logic polishing can yield compact, interpretable rule models for longitudinal signals without meaningful discrimination loss, supporting deployment where clarity and expert verification are required.

## Relevance to the Dissertation
Anytime Rule Compression for Interpretable Sparse Longitudinal Models (Orender et al., 2025) is directly relevant as prior work in the same method lineage, and it should be treated as a foundation that the dissertation extends and unifies.

## Elements from This Paper to Use in the Dissertation
1. Use this paper as direct prior-work grounding for dissertation method continuity.
2. Explicitly separate what this paper established from what the dissertation newly contributes.
3. Reuse technical details around analytics, applications, proceedings to avoid redefining stable components.
4. Extend this paper's validation with broader baselines, stronger ablations, and deeper statistical testing.

## Competitive Method Assessment
This is not an external competitor; it is direct predecessor work. The dissertation comparison should emphasize extension points (broader validation, stronger theory, tighter reproducibility, and integration across pipeline stages) rather than replacement.


## Dissertation Citation Traceability

- Chapter: `Introduction`; Section: `Chapter context (no explicit section)`; Line: `Chapters/01_introduction.tex:19`; Relevance: Cited to support the statement that The proposed approach builds from prior work in this research line: a rectification-first longitudinal feature-selection method, proof-of-concept theory linking binarized transformation to improved irrepresentable-condition (IC) behavior, and an anytime rule-compression method that converts sparse models into compact logic-like forms . The dissertation unifies these components into one framework, strengthens the supporting analysis, broadens empirical evaluation, and emphasizes reproducible implementation.
- Chapter: `Introduction`; Section: `Problem`; Line: `Chapters/01_introduction.tex:32`; Relevance: Cited to support the statement that Thesis statement: critical-range rectification improves reliability of sparse longitudinal feature recovery by contracting harmful dependence structures in lag-expanded data, and anytime rule compression converts resulting sparse models into compact, operationally usable rule forms with minimal loss in discriminative performance . The scope emphasizes inherently interpretable sparse models with explicit attribution; deep learning appears only as contextual baselines where needed.
- Chapter: `Introduction`; Section: `Contributions`; Line: `Chapters/01_introduction.tex:40`; Relevance: Cited to support the statement that item Anytime compression to interpretable m-of-K style rules. Sparse coefficient models are converted into compact rule forms that can be audited and deployed under time and complexity constraints, extending recent rule-compression results.
- Chapter: `Related Work`; Section: `Method Lineage and Dissertation Positioning`; Line: `Chapters/03_relatedwork.tex:71`; Relevance: Cited to support the statement that The companion 2025 anytime rule-compression paper addressed the remaining interpretability gap: sparse coefficients are often still too numerous for direct human use. The anytime compression stage converts sparse rectified models into compact m-of-K style rule behavior with controlled discrimination tradeoffs and early-stop practicality . This contribution aligns the pipeline with interpretable-model deployment requirements discussed earlier in this chapter.
- Chapter: `Related Work`; Section: `Summary of Gaps in Prior Work`; Line: `Chapters/03_relatedwork.tex:83`; Relevance: Cited to support the statement that item Prior work in this dissertation line introduced the key pieces, but an end-to-end, reproducible, and extensively benchmarked synthesis is still needed.
- Chapter: `Research Questions`; Section: `Why RQ3 matters`; Line: `Chapters/04_resquestions.tex:36`; Relevance: Cited to support the statement that Rule-oriented model families and LAD-style traditions demonstrate the value of explicit logic structures for decision support . However, direct combinatorial search can be expensive in high-dimensional longitudinal spaces. The dissertation's question is whether an anytime compression stage can deliver much of the same interpretability benefit while preserving most of the discriminative value of the sparse baseline.
- Chapter: `Research Questions`; Section: `Significance of the Chapter`; Line: `Chapters/04_resquestions.tex:55`; Relevance: Cited to support the statement that This chapter establishes the scope and rationale of the research program before technical detail. RQ1 asks whether the approach works empirically in the intended problem class. RQ2 asks whether the observed behavior is theoretically credible and generalizable. RQ3 asks whether the resulting models are usable in real decision workflows. Taken together, the three questions define the dissertation's central claim that rectification-first sparse longitudinal learning, followed by anytime rule compression, can provide a practical middle ground between unstable raw sparse fitting and computationally heavy direct rule search.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Chapter context (no explicit section)`; Line: `Chapters/07_rq3.tex:5`; Relevance: Cited to support the statement that Research Question 3 asks whether a sparse, rectified linear model can be compressed into a compact rule form while preserving practical discrimination quality. In this dissertation, the target is not just sparsity in coefficient space, but operational interpretability: a model that can be read, explained, and validated as an explicit decision rule under realistic constraints. The anytime rule compression framework was proposed to address this requirement by converting a fitted sparse model into an ordered sequence of candidate logic rules and allowing compression to stop as soon as performance is good enough for the application context.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Why RQ3 Matters After RQ1 and RQ2`; Line: `Chapters/07_rq3.tex:9`; Relevance: Cited to support the statement that RQ1 and RQ2 establish two foundations: first, binarization plus sparse learning can recover relevant structure more reliably in threshold-driven settings; second, the theoretical conditions for support recovery can improve when feature interactions are reframed through the binarized representation. RQ3 addresses the remaining translational gap: whether those improvements can be turned into human-auditable, low-complexity rules without giving back the predictive benefit.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `From Rectified Sparse Models to Rule Space`; Line: `Chapters/07_rq3.tex:21`; Relevance: Cited to support the statement that The compression idea is to map the active coefficients to a shared magnitude (logic polishing), keep their signs, and evaluate truncated models along an ordered path. Ordering is by absolute effect size from the trained sparse model so that early steps prioritize the most influential terms.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Anytime Compression Objective`; Line: `Chapters/07_rq3.tex:29`; Relevance: Cited to support the statement that where is Youden's statistic ( ), and complexity is represented by the number of retained conditions (and optionally the vote threshold in an -of- rule) . Rather than commit to a single fixed complexity in advance, the anytime procedure scans candidate compressions and can stop at any prefix as soon as the achieved is within an application-defined tolerance of the baseline.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Anytime Compression Objective`; Line: `Chapters/07_rq3.tex:31`; Relevance: Cited to support the statement that This aligns with a deployment reality: in some environments, a 1--2 % relative loss may be acceptable if complexity falls by an order of magnitude; in others, compression is only accepted at near-zero loss. The framework supports either case by explicitly parameterizing the tolerance.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Algorithmic Pipeline`; Line: `Chapters/07_rq3.tex:35`; Relevance: Cited to support the statement that The compression process can be summarized in four stages.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Algorithmic Pipeline > 1. Train Baseline Sparse Rectified Model`; Line: `Chapters/07_rq3.tex:39`; Relevance: Cited to support the statement that Fit L1-regularized logistic regression on the rectified matrix and compute baseline operating metrics (AUC, , sensitivity, specificity) at the chosen operating threshold. This baseline defines the reference quality floor for compression.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Algorithmic Pipeline > 2. Logic Polishing and Ordered Prefix Construction`; Line: `Chapters/07_rq3.tex:43`; Relevance: Cited to support the statement that Restrict to active features and sort them by descending. For prefix length , keep the top- signed indicators and assign common magnitude (or equivalently use signed votes). This yields candidate rule families of increasing complexity, each nested in the next.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Algorithmic Pipeline > 3. Vote Threshold Optimization`; Line: `Chapters/07_rq3.tex:47`; Relevance: Cited to support the statement that For each prefix, evaluate an -of- decision threshold. Intuitively, controls how many supportive conditions are required before predicting the positive class. Sweeping gives a local complexity-performance frontier at fixed ; sweeping gives the global anytime frontier.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Algorithmic Pipeline > 4. Adoption Rule with Relative Tolerance`; Line: `Chapters/07_rq3.tex:55`; Relevance: Cited to support the statement that for configured tolerance . Among accepted candidates, one can choose the smallest (maximal simplification) or the best under a complexity cap. This makes compression policy explicit instead of ad hoc.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Why the Method Is ``Anytime''`; Line: `Chapters/07_rq3.tex:59`; Relevance: Cited to support the statement that The method is anytime in the algorithmic sense: each additional step (larger or alternative ) refines quality, but every intermediate rule is already a valid deployable model. If computation must stop early, the current incumbent can still be used. If more budget is available, scanning continues to improve operating characteristics. This property is practical for iterative model governance and constrained environments.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Empirical Evidence to Date`; Line: `Chapters/07_rq3.tex:63`; Relevance: Cited to support the statement that In the prior study that introduced this framework, compression often reduced model complexity by large factors while preserving discrimination closely. Reported results showed substantial complexity drops (including cases near 50x reduction) with negligible AUC change under a practical equivalence margin, and frequently with stable or slightly improved at the selected operating point . Runtime behavior was also favorable relative to standard sparse solvers in high-dimensional rectified settings, supporting use as a post-fit compression stage.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Empirical Evidence to Date`; Line: `Chapters/07_rq3.tex:63`; Relevance: Cited to support the statement that In the prior study that introduced this framework, compression often reduced model complexity by large factors while preserving discrimination closely. Reported results showed substantial complexity drops (including cases near 50x reduction) with negligible AUC change under a practical equivalence margin, and frequently with stable or slightly improved at the selected operating point . Runtime behavior was also favorable relative to standard sparse solvers in high-dimensional rectified settings, supporting use as a post-fit compression stage.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Statistical Framing of ``No Material Degradation''`; Line: `Chapters/07_rq3.tex:76`; Relevance: Cited to support the statement that RQ3 uses ``no material degradation'' in a practical, decision-oriented sense rather than a literal requirement of zero difference. Classical null-hypothesis difference tests are not sufficient to show retained utility, because failure to reject a difference is not evidence of equivalence. Accordingly, the prior work used an equivalence framing (TOST-style logic) with a predeclared margin (for example, AUC) to justify practical non-loss claims . This is methodologically aligned with the chapter objective: demonstrate that simplified rules remain fit for purpose under explicit tolerance.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Motivation and Application Context`; Line: `Chapters/07_rq3.tex:93`; Relevance: Cited to support the statement that Across these settings, the benefit is not only readability. Compact rules also reduce implementation burden, simplify drift monitoring, and support deterministic replay during audits. The anytime mechanism then provides a tunable point on the complexity-performance frontier for each deployment constraint.
- Chapter: `Anytime Rule Compression (RQ3)`; Section: `Interim Answer to RQ3`; Line: `Chapters/07_rq3.tex:101`; Relevance: Cited to support the statement that The accumulated evidence supports a positive interim answer: sparse rectified models can often be compressed into substantially smaller -of- rule representations with little practical degradation in discrimination, while improving interpretability and deployability. The key contribution is the anytime formulation itself: it makes compression controllable, auditable, and explicitly tied to operational tolerances rather than fixed model-size heuristics.
- Chapter: `Future Work`; Section: `Chapter context (no explicit section)`; Line: `Chapters/88_futurework.tex:5`; Relevance: Cited to support the statement that This chapter defines the work that must be completed before the final formal dissertation defense. The goal is not to introduce a new research direction, but to close remaining validity gaps in a controlled, auditable way and convert the current proof-of-concept contributions into a defense-ready body of evidence. The plan extends the method lineage established in prior work while preserving the same three-stage architecture: critical-range rectification, sparse fitting, and anytime rule compression.
- Chapter: `Future Work`; Section: `Defense-Readiness Objective`; Line: `Chapters/88_futurework.tex:13`; Relevance: Cited to support the statement that item Operational interpretability: RQ3 compression yields compact rules with documented complexity/performance tradeoffs and practical non-inferiority checks.
- Chapter: `Future Work`; Section: `Workstream C: RQ3 Anytime Compression Validation > C1. Real-data anytime curves and operating-point policy`; Line: `Chapters/88_futurework.tex:76`; Relevance: Cited to support the statement that RQ3 will be extended with full -versus- compression curves on real data and a prespecified adoption policy for practical deployment. The policy will explicitly encode acceptable complexity/performance tradeoffs instead of selecting rule size post hoc.
- Chapter: `Future Work`; Section: `Cross-Cutting Ablation Program`; Line: `Chapters/88_futurework.tex:106`; Relevance: Cited to support the statement that This program is the main mechanism for demonstrating that each stage contributes measurable value and for preventing confounding between preprocessing, fitting, and post-processing choices.
- Chapter: `Future Work`; Section: `Risks and Mitigation Prior to Defense`; Line: `Chapters/88_futurework.tex:125`; Relevance: Cited to support the statement that item Risk: Compression appears accurate but changes operating behavior. Mitigation: operating-point diagnostics plus equivalence-margin reporting.
- Chapter: `Conclusion`; Section: `Chapter context (no explicit section)`; Line: `Chapters/89_conclusion.tex:5`; Relevance: Cited to support the statement that This dissertation examined longitudinal feature learning under three simultaneous constraints: dependence induced by lag expansion, the need for reliable feature-lag attribution, and the requirement for compact, human-auditable model outputs. The central claim is that a representation-first pipeline, followed by sparse fitting and anytime rule compression, provides a practical middle ground between unstable raw sparse selection and computationally heavy direct rule search.
- Chapter: `Conclusion`; Section: `Conclusions by Research Question > RQ3 conclusion: Anytime compression makes interpretability operational`; Line: `Chapters/89_conclusion.tex:34`; Relevance: Cited to support the statement that For RQ3, this work concludes that sparse rectified models can often be compressed into substantially smaller rule representations while preserving practical discrimination quality under predefined tolerance policies . This directly addresses deployment requirements in settings where explanation, auditability, and compact decision logic are non-negotiable.
- Chapter: `Conclusion`; Section: `Primary Dissertation Contributions`; Line: `Chapters/89_conclusion.tex:44`; Relevance: Cited to support the statement that item An anytime rule-compression stage that converts sparse coefficients into compact -of- -style logic with tunable performance-complexity tradeoffs.
- Chapter: `Conclusion`; Section: `Final Statement`; Line: `Chapters/89_conclusion.tex:73`; Relevance: Cited to support the statement that This work concludes that rectification-first sparse longitudinal learning with anytime rule compression is a credible and useful framework for interpretable event modeling under dependence. Its value lies in integration: empirical support behavior (RQ1), scoped mechanistic theory (RQ2), and operational rule simplification (RQ3) are addressed as a single pipeline rather than isolated techniques . Within its stated scope, this provides a defensible contribution to interpretable machine learning for longitudinal data.
